// -*- mode: adoc; fill-column: 160; -*-
// suppress inspection "AsciiDocLinkResolve" for whole file
= Jdbi 3 Developer Guide
:doctype: book
:toc: left
:toclevels: 3
:sectanchors:
:sectlinks:
:sectnums:
:linkattrs:
:icons: font
:source-highlighter: coderay
:source-language: asciidoc
:imagesdir: images
:docinfo: private

:jdbidocs: ./apidocs/org/jdbi/v3
:kotlindocs: ./apidocs-kotlin/jdbi3-kotlin/jdbi3-kotlin/org.jdbi.v3.
:jdkdocs: https://docs.oracle.com/en/java/javase/11/docs/api
:jakartadocs: https://jakarta.ee/specifications/platform/10/apidocs

:projecthome: https://github.com/jdbi/jdbi
:exampledir: ../test/java/jdbi/doc
:kotlinexampledir: ../test/kotlin/jdbi/doc
:exampleresourcedir: ../test/resources
:coreexampledir: ../../../core/src/test/java/org/jdbi/v3/core/mapper
:guavaexampledir: ../../../guava/src/test/java/org/jdbi/v3/guava
:sqlobjectexampledir: ../../../sqlobject/src/test/java/org/jdbi/v3/sqlobject

[preface]
image::logo.svg[Jdbi logo]

////
Style guidelines:

* Refer to the project in prose as simply Jdbi, with no adornment or
  formatting. Enclose the class name `Jdbi` in back ticks so readers can
  distinguish references to the `Jdbi` class from references to the Jdbi
  project as a whole.
* 80 characters per line, except when you can't break it up e.g. links or
  asciidoc directives
* Avoid JUnit boilerplate in code examples. Assertions are ok if they
  complement the example.
* External links should use a caret at the end of the link title e.g.
  link:path/to/doc[the title^] so they open in separate tabs. See
  https://asciidoctor.org/docs/asciidoc-writers-guide/#target-window-and-role-attributes-for-links
* Be funny. Nobody like reading dry documentation.
* Be inclusive: keep usage of male and female names equal in code examples.
* Best edited while drunk

////


ifndef::release[]
[preface]
== Development documentation ({revnumber})

This is the documentation for the current development state of Jdbi. All information in here reflects the current state of development on the `master` branch and is subject to change until it has been released as a numbered version.

* https://jdbi.org/[Permalink to this document]
* https://jdbi.org/apidocs/[Jdbi Javadoc (API Docs)^]
* https://github.com/jdbi/jdbi/blob/master/RELEASE_NOTES.md[Current release notes^]
* https://github.com/jdbi/jdbi/[Development source tree^]

=== Release documentation

* https://jdbi.org/releases/3.43.0[Release 3.43.0 - 2024-01-02^]
* https://jdbi.org/releases/3.42.0[Release 3.42.0 - 2023-11-29^]
* https://jdbi.org/releases/3.41.3[Release 3.41.3 - 2023-10-02^]
* https://jdbi.org/releases/3.41.2[Release 3.41.2 - 2023-09-21^]
* https://jdbi.org/releases/3.41.1[Release 3.41.1 - 2023-09-08^]
* https://jdbi.org/releases/3.41.0[Release 3.41.0 - 2023-08-15^]
* https://jdbi.org/releases/3.40.0[Release 3.40.0 - 2023-08-02^]
* https://jdbi.org/releases/3.39.1[Release 3.39.1 - 2023-07-17^] - *This is the last release of Jdbi to support Java 8!*
* https://jdbi.org/releases/3.39.0[Release 3.39.0 - 2023-07-17^]
* https://jdbi.org/releases/3.38.3[Release 3.38.3 - 2023-06-05^]
* https://jdbi.org/releases/3.38.2[Release 3.38.2 - 2023-05-04^]
* https://jdbi.org/releases/3.38.1[Release 3.38.1 - 2023-05-02^]
* https://jdbi.org/releases/3.38.0[Release 3.38.0 - 2023-04-25^]
* https://jdbi.org/releases/3.37.1[Release 3.37.1 - 2023-02-08^]
* https://jdbi.org/releases/3.37.0[Release 3.37.0 - 2023-02-03^]
* https://jdbi.org/releases/3.36.0[Release 3.36.0 - 2022-12-31^]
* https://jdbi.org/releases/3.35.0[Release 3.35.0 - 2022-12-03^]
* https://jdbi.org/releases/3.34.0[Release 3.34.0 - 2022-10-05^]
* https://jdbi.org/releases/3.33.0[Release 3.33.0 - 2022-09-28^]
* https://jdbi.org/releases/3.32.0[Release 3.32.0 - 2022-07-25^]
* https://jdbi.org/releases/3.31.0[Release 3.31.0 - 2022-07-17^]
* https://jdbi.org/releases/3.30.0[Release 3.30.0 - 2022-06-02^]
* https://jdbi.org/releases/3.29.0[Release 3.29.0 - 2022-05-21^]
* https://jdbi.org/releases/3.28.0[Release 3.28.0 - 2022-03-08^]
* https://jdbi.org/releases/3.27.2[Release 3.27.2 - 2022-02-18^]
* https://jdbi.org/releases/3.27.1[Release 3.27.1 - 2022-01-25^]
* https://jdbi.org/releases/3.27.0[Release 3.27.0 - 2022-01-06^]

endif::[]

== Introduction to Jdbi 3

*Jdbi provides convenient, idiomatic, access to relational data in Java.* Jdbi 3 is the third major release, which introduces enhanced support for modern Java, countless refinements to the design and implementation, and enhanced support for modular development through plugins and extensions.

*Jdbi is built on top of JDBC.* If your data source has a JDBC driver, you can use it with Jdbi. It improves JDBC's low-level interface, providing a more natural API that is easy to bind to your domain data types.

*Jdbi is not an ORM.* It is a convenience library to make Java database operations simpler and more pleasant to program than raw JDBC. While there is some ORM-like functionality, Jdbi goes to great length to ensure that there is no hidden magic that makes it hard to understand what is going on.

*Jdbi does not hide SQL away.* One of the design principles of Jdbi is that SQL is the native language of the database, and it is unnecessary to wrap it into code, deconstruct it, or hide it away. Being able to express a query in raw SQL makes it possible for programmers and data engineers to speak the same language and not fight translation layers.

*Jdbi does not aim to provide a complete database management framework.* It provides the building blocks that allow constructing the mapping between data and objects as appropriate for your application and the necessary primitives to execute SQL code against your database.


=== Quick Links

ifndef::release[]
* https://jdbi.org/apidocs/[Jdbi Javadoc (API Docs)^]
* https://github.com/jdbi/jdbi/blob/master/examples/README.md[Jdbi sample code^]
endif::[]
ifdef::release[]
* https://jdbi.org/releases/{revnumber}[Jdbi {revnumber} documentation]
* https://jdbi.org/releases/{revnumber}/apidocs[Jdbi {revnumber} Javadoc (API Docs)^]
* https://github.com/jdbi/jdbi/tree/v{revnumber}[Jdbi {revnumber} source code^]
* https://github.com/jdbi/jdbi/tree/v{revnumber}/examples/README.md[Jdbi sample code^]
endif::[]
* https://github.com/jdbi/jdbi[GitHub Jdbi repository^]

* https://github.com/jdbi/jdbi/discussions[Discussion groups for Jdbi^]
* https://groups.google.com/group/jdbi[Mailing list^]
* https://stackoverflow.com/questions/tagged/jdbi[Stack Overflow^]

=== JDBI v2 (legacy version)

[WARNING]
*JDBI v2 is no longer under active development!*

* link:/jdbi2/[Jdbi v2 documentation^]

[TIP]
Already using Jdbi v2? See <<Upgrading from v2 to v3>>

=== Getting involved

Jdbi uses https://github.com/jdbi/jdbi[GitHub^] as the central development hub. https://github.com/jdbi/jdbi/issues[Issues^], https://github.com/jdbi/jdbi/pulls[Pull Requests^] and https://github.com/jdbi/jdbi/discussions[Discussions^] all happen here.

Please see our https://github.com/jdbi/jdbi/blob/master/CONTRIBUTING.md[Contribution guide^] for more information on how to contribute to Jdbi.

=== Acknowledgements and Funding

* image:spotify_logo.svg[Spotify logo,30,30] https://engineering.atspotify.com/2023/10/announcing-the-recipients-of-the-2023-spotify-foss-fund/[Jdbi is a recipient of the Spotify FOSS 2023 Fund^]
* image:tidelift_logo.png[Tidelift logo, 30, 30]https://tidelift.com/funding/github/maven/org.jdbi:jdbi3-core[Jdbi is supported by Tidelift^]


== Using Jdbi in your projects


=== License, Dependencies and availability

Jdbi is licensed under the commercial friendly https://www.apache.org/licenses/LICENSE-2.0.html[Apache 2.0^] license.

The core Jdbi module which offers programmatic access uses only https://slf4j.org/[slf4j^] and https://github.com/leangen/geantyref[geantyref^] as hard dependencies.

All Jdbi modules are available through https://search.maven.org[Maven Central^]. Jdbi also offers a BOM (Bill of materials) module for easy dependency management.


=== JVM version compatibility

Jdbi runs on all Java versions 11 or later. All releases are built with the latest LTS version of Java using Java 11 bytecode compatibility.

[IMPORTANT]
Jdbi ended support for Java 8 with version 3.39. There are occasional backports of security relevant things or major bugs but as of version 3.40.0, JDK 11+ is required.


=== Getting started

Jdbi has a flexible plugin architecture, which makes it easy to fold in support for your favorite libraries (Guava, JodaTime, Spring, Vavr) or database vendors (Oracle, Postgres, H2).

Jdbi is not an ORM. There is no session cache, change tracking, "open session in view", or cajoling the library to understand your schema.

Jdbi provides straightforward mapping between SQL and data accessible through a JDBC driver. You bring your own SQL, and Jdbi executes it.

Jdbi provides several other modules, which enhance the core API with additional
features.


==== Jdbi modules overview

Jdbi consists of a large number of modules. Not all are required when writing database code. This is a quick overview of the existing modules and their function:


===== Common modules

[glossary]
jdbi3-core::
    The core Jdbi library. Required by all other components.
jdbi3-sqlobject::
    SQL Object extension for declarative database access.


===== Testing support

[glossary]
jdbi3-testing::
    Testing framework support. Currently, only supports JUnit4 and JUnit5.

jdbi3-testcontainers::
    Support for arbitrary databases running in https://testcontainers.org/[Testcontainers^]. Currently, only supports JUnit 5.


===== External data types and libraries

The core module contains support for the https://immutables.github.io/[Immutables^] and https://github.com/inferred/FreeBuilder[Freebuilder^] libraries.

[glossary]
jdbi3-guava::
    Support for https://guava.dev/[Google Guava^] collection and Optional types.
jdbi3-jodatime2::
    Support for https://www.joda.org/joda-time/[JodaTime v2^] data types.
jdbi3-vavr::
    Support for https://www.vavr.io/[Vavr^] Tuples, Collections and Value arguments.


===== JSON Mapping

Support for various JSON libraries to map data from the database onto JSON types and vice versa.

[glossary]
jdbi3-jackson2::
  Support for https://github.com/FasterXML/jackson[Jackson v2^].
jdbi3-gson::
  Support for https://github.com/google/gson[Google Gson^].
jdbi3-moshi::
  Support for https://github.com/square/moshi[Square Moshi^].


===== Frameworks

[glossary]
jdbi3-guice::
    Support dependency injection and modules with https://github.com/google/guice[Google Guice^].
jdbi3-spring5::
    Provides a https://spring.io/[Spring Framework^] factory bean to set up Jdbi singleton.
jdbi3-jpa::
    Some support for https://www.oracle.com/java/technologies/persistence-jsp.html[JPA^] annotations.


===== Database specific types and functions

While Jdbi supports _any_ data source that has a `JDBC` driver "out of the box", its support is limited to the standard JDBC types and mappings. Some databases have additional data types and mappings, and support is added using the following modules:

[glossary]
jdbi3-postgres::
    Support for https://www.postgresql.org/[Postgres^] data types.
jdbi3-sqlite::
    Support for https://www.sqlite.org/index.html[sqlite^] data types.
jdbi3-oracle12::
    Support Oracle returning DML statements.
jdbi3-postgis::
    Support for https://postgis.net/[PostGIS^] types.

[NOTE]
While Oracle support is considered part of Jdbi, the actual library is developed and shipped as a separate component for historic reasons.


===== SQL rendering

SQL statements can be rendered before they are sent to the database driver. Unless explicitly configured, Jdbi uses a simple render engine that replaces `<...>` placeholders. It is possible to replace this engine with other template engines.

[glossary]
jdbi3-stringtemplate4::
    Use the https://www.stringtemplate.org/[StringTemplate 4^] template engine to render SQL statements.
jdbi3-commons-text::
    Use https://commons.apache.org/proper/commons-text/[Apache Commons Text^] to render SQL statements.
jdbi3-freemarker::
    Use https://freemarker.apache.org/[Apache Freemarker^] to render SQL statements.


===== Cache support

[glossary]
jdbi3-caffeine-cache::
    Use the https://github.com/ben-manes/caffeine[Caffeine^] caching library for SQL template and parse caching.
jdbi3-noop-cache::
    Turn off SQL template and parse caching for testing and debugging.
jdbi3-guava-cache::
    Use the https://github.com/google/guava/wiki/CachesExplained[Guava Cache^] caching library for SQL template and parse caching.


[NOTE]
The guava caching module is considered experimental.


===== Additional Language support

Jdbi can be used from any language and technology running on the JVM that can use Java code (Kotlin, Scala, Clojure, JRuby etc).

While Java is a first class citizen (and will be for the foreseeable future), we provide modules for some languages that allow more idiomatic access to Jdbi functionality.

[glossary]
jdbi3-kotlin::
    Automatically map Kotlin data classes.
jdbi3-kotlin-sqlobject::
    Kotlin support for the SQL Object extension.

==== External modules

The following modules are maintained outside the main Jdbi tree:

[%header, cols="<1, ^1, ^1, ^1, <3", stripe=none]
|===
| Module | Source | Javadoc | Site | Description
| jdbi3-oracle12 | https://github.com/jdbi/jdbi3-oracle12/[Github^]
ifndef::release[]
| https://jdbi.org/modules/jdbi3-oracle12/apidocs/[Javadoc^]
| https://jdbi.org/modules/jdbi3-oracle12/[Site^]
endif::[]
ifdef::release[]
| https://jdbi.org/modules/jdbi3-oracle12/releases/{revnumber}/apidocs/[Javadoc^]
| https://jdbi.org/modules/jdbi3-oracle12/releases/{revnumber}/[Site^]
endif::[]
| Support for Oracle 12 and beyond.
| jdbi3-guava-cache | https://github.com/jdbi/jdbi3-guava-cache/[Github^]
ifndef::release[]
| https://jdbi.org/modules/jdbi3-guava-cache/apidocs/[Javadoc^]
| https://jdbi.org/modules/jdbi3-guava-cache/[Site^]
endif::[]
ifdef::release[]
| https://jdbi.org/modules/jdbi3-guava-cache/releases/{revnumber}/apidocs/[Javadoc^]
| https://jdbi.org/modules/jdbi3-guava-cache/releases/{revnumber}/[Site^]
endif::[]
| Experimental support for the Guava cache library.
|===

[NOTE]
The additional modules are usually released in sync with the main release. If any of the links above for a release version do not resolve, it may be possible that a release was omitted by accident. In that case, please file an issue on the https://github.com/jdbi/jdbi/issues[Bug Tracker^].


==== Build tools

All Jdbi modules are available through https://search.maven.org[Maven Central^], so any project that uses a dependency management tool (Apache Maven, Gradle, sbt, leiningen, Apache Ivy etc.) can access these.

For Apache Maven:

[source,xml,indent=0,subs="attributes,specialchars"]
----
<dependencies>
    <dependency>
        <groupId>org.jdbi</groupId>
        <artifactId>jdbi3-core</artifactId>
        <version>{project_version}</version>
    </dependency>
</dependencies>
----

For Gradle:

[source,groovy,subs="attributes,specialchars"]
----
dependencies {
    implementation("org.jdbi:jdbi3-core:{project_version}")
}
----

When using multiple Jdbi modules, it is important that all modules use the same version. There is no guarantee that mixing versions will work.

Jdbi offers a BOM (Bill of Materials) that can be used to provide a consistent version for all Jdbi components.

For Apache Maven:

[source,xml,indent=0,subs="attributes,specialchars"]
----
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.jdbi</groupId>
            <artifactId>jdbi3-bom</artifactId>
            <type>pom</type>
            <version>{project_version}</version>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
----

adds the Jdbi BOM module into the `dependencyManagement` section.

Jdbi components in use are declared in the `<dependencies>` section *without a version*:

[source,xml,indent=0,subs="specialchars"]
----
<dependencies>
    <dependency>
        <groupId>org.jdbi</groupId>
        <artifactId>jdbi3-core</artifactId>
    </dependency>
</dependencies>
----

For Gradle:

[source,groovy,subs="attributes,specialchars"]
----
dependencies {
    // Load bill of materials (BOM) for Jdbi.
    implementation(platform("org.jdbi:jdbi3-bom:{project_version}"))
}
----

adds the BOM as dependency constraints to Gradle.

Jdbi components are declared without versions:

[source,groovy,subs="attributes,specialchars"]
----
dependencies {
    implementation("org.jdbi:jdbi3-core")
}
----


==== @Alpha and @Beta Annotations

The link:{jdbidocs}/meta/Alpha.html[@Alpha^] and link:{jdbidocs}/meta/Beta.html[@Beta^] annotations mark APIs as unstable. Each of these annotations signifies that a public API (public class, method or field) is subject to incompatible changes, or even removal, in a future release. Any API bearing these annotations is exempt from any compatibility guarantees.

* `Alpha` -- Alpha APIs are intended as early preview of features that might eventually get promoted.

* `Beta` -- It is generally safe for applications to depend on beta APIs, at the cost of some extra work during upgrades. However, libraries (which get included on an application classpath) should not depend on Beta APIs as the classpath is outside the control of the library.

Note that the presence of this annotation implies nothing about the quality or performance of the API in question, only the fact that it is not "API-frozen."

[TIP]
Add `Alpha` and `Beta` to your IDE's "unstable API usage" blacklist.


==== Internal packages

Any class in a package that is marked as `internal` (contains the word "internal") is not a part of the public API and may change in a backwards incompatible way. These classes and interfaces may be used across the Jdbi code base and can change (or be removed) without deprecation or announcement.


==== Mixing Jdbi component versions

There is no guarantee that Jdbi components of different versions (e.g. `jdbi3-core` version 1.2.3 and `jdbi-sqlobject` version 1.3.1) work together. Jdbi versioning is the *public API* exposed to consumers. All Jdbi components used in a project or service should use the same version. See the section on <<Build tools>> on how to use the BOM module to provide consistent versions for all components.


== API Overview

Jdbi's API comes in two flavors:


=== Fluent API

The Core API provides a fluent, imperative interface. Use Builder style objects to wire up your SQL to rich Java data types.

[source,java,indent=0]
----
include::{exampledir}/IntroductionTest.java[tags=core]
----

See the <<Core API concepts, chapter introducing the core API>> for details about Jdbi's fluent API.


=== Declarative API

The <<SQL Objects, SQL Object extension>> is an additional module, which provides a declarative API.

Define the SQL to execute and the shape of the results by creating  an annotated Java interface.

[source,java,indent=0]
----
include::{exampledir}/IntroductionTest.java[tags=sqlobject-declaration]
----

Then attach the interface to a Jdbi instance and execute the methods on the resuling class to execute the SQL queries.

[source,java,indent=0]
----
include::{exampledir}/IntroductionTest.java[tags=sqlobject-usage]
----

See the <<SQL Objects, chapter on SQL objects>> for more details about the declarative API. The declarative API uses the <<Core API concepts, fluent API>> "under the hood" and the two styles can be mixed.


== Core API concepts


=== The Jdbi class

The link:{jdbidocs}/core/Jdbi.html[Jdbi^] class is the main entry point into the library.

Each link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance maintains a set of configuration settings and wraps a JDBC link:{jdkdocs}/java.sql/javax/sql/DataSource.html[DataSource^].

link:{jdbidocs}/core/Jdbi.html[Jdbi^] instances are thread-safe and do not own any database resources.

There are a few ways to create a link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance:

- use a JDBC URL:

[source,java,indent=0]
----
include::{exampledir}/FiveMinuteTourTest.java[tags=createJdbi]
----

- directly use a `DataSource` object which was created outside Jdbi.

[source,java,indent=0]
----
DataSource ds = ...
Jdbi jdbi = Jdbi.create(ds);
----

- from a custom class that implements link:{jdbidocs}/core/ConnectionFactory.html[ConnectionFactory^].

This allows for custom implementations of connection providers such as HA failover, proxy solutions etc.

- from a single link:{jdkdocs}/java.sql/java/sql/Connection.html[JDBC Connection^].

Please note that there is no magic. Any Handle or operation will use this one connection provided. If the connection is thread-safe, then multiple threads accessing the database will work properly, if the connection object is not thread-safe, then Jdbi will not be able to do anything about it.

[TIP]
Production code rarely provides a connection object directly to a link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance. It is useful for testing and debugging.

Applications create a single, shared link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance per data source, and set up any common configuration there.  See <<Configuration>> for more details.

Jdbi does not provide connection pooling or other <<High Availability>> features, but it can be combined with other software that does.


=== Handle

A link:{jdbidocs}/core/Handle.html[Handle^] wraps an active link:{jdkdocs}/java.sql/java/sql/Connection.html[database connection^].

Handle instances are created by a link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance to provide a database connection e.g. for a single HTTP request or event callback). Handles are intended to be short-lived and must be closed to release the database connection and possible other resources.

A link:{jdbidocs}/core/Handle.html[Handle^] is used to prepare and run SQL statements against the database, and manage database transactions. It provides  access to fluent statement APIs that can bind arguments, execute the statement,
and then map any results into Java objects.

A link:{jdbidocs}/core/Handle.html[Handle^] inherits configuration from the link:{jdbidocs}/core/Jdbi.html[Jdbi^] at the time it is created. See <<Configuration>> for more details.

Handles and all attached query objects such as link:{jdbidocs}/core/statement/Batch.html[Batch^], link:{jdbidocs}/core/statement/Call.html[Call^], link:{jdbidocs}/core/statement/Query.html[Query^], link:{jdbidocs}/core/statement/Script.html[Script^] and link:{jdbidocs}/core/statement/Update.html[Update^] should be used by a single thread and are *not thread-safe*.

They may be used by multiple threads as long as there is coordination that only one thread at a time is accessing them. Managing Handles and query objects across threads is error-prone and should be avoided.


==== Obtaining a managed handle

The most convenient way to get access to a handle is by using the link:{jdbidocs}/core/Jdbi.html#withHandle(org.jdbi.v3.core.HandleCallback)[withHandle^] or link:{jdbidocs}/core/Jdbi.html#useHandle(org.jdbi.v3.core.HandleConsumer)[useHandle^] methods on the link:{jdbidocs}/core/Jdbi.html[Jdbi^] class. These methods use callbacks and provide a fully managed handle that is correctly closed and all related resources are released. `withHandle` allows the callback to return a result while `useHandle` is just executing operations that do not need to return any value.

Providing a return value from a query using the link:{jdbidocs}/core/Jdbi.html#withHandle(org.jdbi.v3.core.HandleCallback)[Jdbi#withHandle()^] method:
[source,java,indent=0]
----
include::{exampledir}/FiveMinuteTourTest.java[tags=withHandle]
----

Executing an operation using the link:{jdbidocs}/core/Jdbi.html#useHandle(org.jdbi.v3.core.HandleConsumer)[Jdbi#useHandle()^] method:
[source,java,indent=0]
----
include::{exampledir}/FiveMinuteTourTest.java[tags=useHandle]
----

[TIP]
You may notice the "consumer" vs "callback" naming pattern in a few  places in Jdbi. Callbacks return a value, and are coupled to `with-` methods. Consumers do not return a value, and are coupled to `use-` methods.


==== Managing the Handle lifecycle manually

The link:{jdbidocs}/core/Jdbi.html#open()[Jdbi#open()^] method returns an unmanaged handle.

The Java _try-with-resources_ construct can be used to manage the lifecycle of the handle:
[source,java,indent=0]
----
include::{exampledir}/FiveMinuteTourTest.java[tags=openHandle]
----

An unmanaged handle must be used when a stateful object should be passed to the calling code. Stateful objects are iterators and streams that do not collect data ahead of time in memory but provide a data stream from the database through the link:{jdkdocs}/java.sql/java/sql/Connection.html[JDBC Connection^] to the calling code. Using a callback does not work here because the connection would be closed before the calling code can consume the data.

[source,java,indent=0]
----
include::{exampledir}/FiveMinuteTourTest.java[tags=streamData]
----

[CAUTION]
When using link:{jdbidocs}/core/Jdbi.html#open()[Jdbi#open()^], you should consider using _try-with-resource_ or a _try-finally_ block to ensure the handle is closed and the database connection is released. Failing to release the handle will leak connections. It is recommended to use a managed handle whenever possible.


=== Statement types

Any database operation within Jdbi uses a statement. Multiple types of statements exist:

* link:{jdbidocs}/core/statement/Query.html[Query^] - SQL statements that return results, e.g. a `SELECT` or any statement with a `RETURNING` clause. See link:{jdbidocs}/core/Handle.html#createQuery(java.lang.CharSequence)[createQuery^]
* link:{jdbidocs}/core/statement/Update.html[Update^] - SQL statements that return no value such as `INSERT`, `UPDATE`, `DELETE` or a DDL operation. See link:{jdbidocs}/core/Handle.html#createUpdate(java.lang.CharSequence)[createUpdate^]
* link:{jdbidocs}/core/statement/Batch.html[Batch^] - a set of operations that are executed as a batch. See link:{jdbidocs}/core/Handle.html#createBatch()[createBatch^]
* link:{jdbidocs}/core/statement/Call.html[Call^] - execute a stored procedure. See link:{jdbidocs}/core/Handle.html#createCall(java.lang.CharSequence)[createCall^]
* link:{jdbidocs}/core/statement/Script.html[Script^] - a SQL script containing multiple statements separated by `;` that is executed as a batch. See also link:{jdbidocs}/core/Handle.html#createScript(java.lang.CharSequence)[createScript^]
* link:{jdbidocs}/core/statement/Metadata.html[Metadata^] - SQL Metadata access.


==== Queries

A link:{jdbidocs}/core/statement/Query.html[Query^] is a
link:{jdbidocs}/core/result/ResultBearing.html[result-bearing^] SQL statement
that returns a result set from the database.

[source,java,indent=0]
----
include::{exampledir}/StatementsTest.java[tags=query]
----

There are many different methods to collect results from a query.


Use the link:{jdbidocs}/core/result/ResultIterable.html#one()[ResultIterable#one()^] method returns when you expect the result to contain exactly one row. This method returns
`null` only if the returned row maps to `null` and throws an exception if the result has zero or multiple rows.

[source,java,indent=0]
----
String name = handle.select("SELECT name FROM users WHERE id = ?", 3)
    .mapTo(String.class)
    .one();
----

Use the link:{jdbidocs}/core/result/ResultIterable.html#findOne()[ResultIterable#findOne()^] method when you expect the result to contain zero or one row. Returns
link:{jdkdocs}/java.base/java/util/Optional.html#empty--[Optional.empty()^] if there are no rows, or one row that maps to `null` and throws  an exception if the result has multiple rows.

[source,java,indent=0]
----
Optional<String> name = handle.select(...)
    .mapTo(String.class)
    .findOne();
----

Use the link:{jdbidocs}/core/result/ResultIterable.html#first()[ResultIterable#first()^] method when you expect the result to contain at least one row. Returns
`null` if the first row maps to `null`. and throws an exception if the result has  zero rows.

[source,java,indent=0]
----
String name = handle.select("SELECT name FROM users WHERE id = ?", 3)
    .mapTo(String.class)
    .first();
----

Use the link:{jdbidocs}/core/result/ResultIterable.html#findFirst()[ResultIterable#findFirst()^] method when the result may contain any number of rows. Returns
link:{jdkdocs}/java.base/java/util/Optional.html#empty--[Optional.empty()^] if there are no rows, or the first row maps to `null`.

[source,java,indent=0]
----
Optional<String> name = handle.select(...)
    .mapTo(String.class)
    .findFirst();
----

Multiple result rows can be returned in a list or a set:

[source,java,indent=0]
----
include::{exampledir}/TestCollections.java[tag=list]

include::{exampledir}/TestCollections.java[tag=set]
----

Use the link:{jdbidocs}/core/result/ResultIterable.html#list()[ResultIterable#list()^] and link:{jdbidocs}/core/result/ResultIterable.html#set()[ResultIterable#set()^] methods to use the default implementations from the collections framework.

For more control over the set and list types, use the link:{jdbidocs}/core/result/ResultIterable.html#collectIntoList()[ResultIterable#collectIntoList()^] and link:{jdbidocs}/core/result/ResultIterable.html#collectIntoSet()[ResultIterable#collectIntoSet()^] methods which use the link:{jdbidocs}/core/collector/JdbiCollectors.html[JdbiCollectors^] configuration object to retrieve the collection types for link:{jdkdocs}/java.base/java/util/List.html[List^] and link:{jdkdocs}/java.base/java/util/Set.html[Set^]:

[source,java,indent=0]
----
include::{exampledir}/TestCollections.java[tag=into-list]

include::{exampledir}/TestCollections.java[tag=into-set]
----


The  link:{jdbidocs}/core/result/ResultIterable.html#collectInto(java.lang.reflect.Type)[ResultIterable#collectInto()^] methods allows specifying a container type directly:

[source,java,indent=0]
----
include::{exampledir}/TestCollections.java[tag=collect-into]

include::{exampledir}/TestCollections.java[tag=collect-into-generic]
----

<1> collect into a raw collection type

<2> collect into a parameterized generic type


For other collections, use link:{jdbidocs}/core/result/ResultIterable.html#collect(java.util.stream.Collector)[ResultIterable#collect()^] with a
link:{jdkdocs}/java.base/java/util/stream/Collector.html[collector^] or link:{jdbidocs}/core/result/ResultIterable.html#toCollection(java.util.function.Supplier)[ResultIterable#toCollection()^] with a collection supplier:

[source,java,indent=0]
----
include::{exampledir}/TestCollections.java[tag=collect]

include::{exampledir}/TestCollections.java[tag=to-collection]
----

The link:{jdbidocs}/core/result/ResultIterable.html#collectToMap(java.util.function.Function,java.util.function.Function)[ResultIterable#collectToMap()^] method allows collecting results directly into a link:{jdkdocs}/java.base/java/util/Map.html[Map^]:

[source,java,indent=0]
----
include::{exampledir}/TestCollections.java[tag=to-map]
----

You can also stream results:

[source,java,indent=0]
----
include::{exampledir}/TestCollections.java[tag=use-stream]

include::{exampledir}/TestCollections.java[tag=stream]
----

<1> link:{jdbidocs}/core/result/ResultIterable.html#useStream(org.jdbi.v3.core.result.StreamConsumer)[ResultIterable#useStream()^] and link:{jdbidocs}/core/result/ResultIterable.html#withStream(org.jdbi.v3.core.result.StreamCallback)[ResultIterable#withStream()^] provide a callback with a managed stream object.

<2> link:{jdbidocs}/core/result/ResultIterable.html#stream()[ResultIterable#stream()^] provides a stream that must be managed by user code

Equivalent methods for iterators exist as well.

Thus far, all examples have shown a `String` result type. Of course, you can
map to many other data types such as an integer:

[source,java,indent=0]
----
include::{exampledir}/TestCollections.java[tag=int-result]
----

Or a complex, custom type:

[source,java,indent=0]
----
include::{exampledir}/TestCollections.java[tag=movie-result]
----


==== Updates

Updates are operations that return an integer number of rows modified, such
as a database *INSERT*, *UPDATE*, or *DELETE*.

You can execute a simple update with link:{jdbidocs}/core/Handle.html[Handle^]'s `int execute(String sql, Object... args)`
method which binds simple positional parameters.

[source,java,indent=0]
----
include::{exampledir}/StatementsTest.java[tags=execute]
----

To further customize, use `createUpdate`:

[source,java,indent=0]
----
include::{exampledir}/StatementsTest.java[tags=update]
----

Updates may return <<Generated Keys>> instead of a result count.


==== Batches

A *Batch* sends many commands to the server in bulk.

After opening the batch, repeated add statements, and invoke *add*.

[source,java,indent=0]
----

include::{exampledir}/BatchTest.java[tags=simpleBatch]
----

The statements are sent to the database in bulk, but each statement is executed separately.
There are no parameters.  Each statement returns a modification count, as with an Update, and
those counts are then returned in an `int[]` array.  In common cases all elements will be `1`.

Some database drivers might return special values in conditions where modification counts are not available.
See the
link:{jdkdocs}/java.sql/java/sql/Statement.html#executeBatch--[executeBatch^] documentation for details.


==== Prepared Batches

A *PreparedBatch* sends one statement to the server with many argument sets.
The statement is executed repeatedly, once for each batch of arguments that is *add*-ed to it.

The result is again a `int[]` of modified row count.

[source,java,indent=0]
----
include::{exampledir}/StatementsTest.java[tags=batch]
----

SqlObject also supports batch inserts:

[source,java,indent=0]
----
include::{exampledir}/BatchTest.java[tags=sqlObjectBatch]
----

[TIP]
Batching dramatically increases efficiency over repeated single statement execution, but
many databases don't handle extremely large batches well either.  Test with your database
configuration, but often extremely large data sets should be divided
and committed in pieces - or risk bringing your database to its knees.


===== Exception Rewriting

The JDBC SQLException class is very old and predates more modern exception
facilities like Throwable's suppressed exceptions. When a batch fails, there
may be multiple failures to report, which could not be represented by the base
Exception types of the day.

So SQLException has a bespoke
link:{jdkdocs}/java.sql/java/sql/SQLException.html#getNextException--[getNextException^]
chain to represent the causes of a batch failure. Unfortunately, by default
most logging libraries do not print these exceptions out, pushing their
handling into your code. It is very common to forget to handle this situation
and end up with logs that say nothing other than

----
java.sql.BatchUpdateException: Batch entry 1 INSERT INTO something (id, name) VALUES (0, '') was aborted. Call getNextException to see the cause.
----

Jdbi will rewrite such exceptions into "suppressed exceptions" so that your logs are more helpful:

----
java.sql.BatchUpdateException: Batch entry 1 INSERT INTO something (id, name) VALUES (0, 'Keith') was aborted. Call getNextException to see the cause.
Suppressed: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint "something_pkey"
  Detail: Key (id)=(0) already exists.
----


==== Stored Procedure Calls

A *Call* invokes a database stored procedure. Stored procedures execute on the database and take input and output parameters.

Most databases solely support input and output parameters. Input parameters can be mapped using the standard Jdbi
mechanisms for parameters, while output values are returned using link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] objects.

Some databases do not support all SQL types as out parameters but use a mechanism similar to a query and
return a link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] object.

===== Using OutParameters to access database return values

OutParameters hold the output parameters of a stored procedure Call.
Since they can hold result sets and cursors, OutParameters must be consumed before
closing the Call that it came from.

This is an example for a PostgreSQL stored procedure. PostgreSQL (and most other databases) stored procedures use `IN` parameters to pass values into the procedure and `OUT` parameters to return values.

[source,sql]
----
include::{exampleresourcedir}/create_stored_proc_add.sql[tags=createStoredProc]
----

Here's how to call a stored procedure:

[source,java,indent=0]
----
include::{exampledir}/CallTest.java[tags=invokeProcedure]
----
<1> Call `Handle.createCall()` with the SQL statement. Note that JDBC has a
    peculiar SQL format when calling stored procedures, which we must follow.
<2> Bind input parameters to the procedure call.
<3> Register out parameters, the values that will be returned from the stored
    procedure call. This tells JDBC what data type to expect for each out
    parameter.
<4> Out parameters may be registered by name (as shown in the example) or by
    zero-based index, if the SQL is using positional parameters. Multiple output
    parameters may be registered, depending on the output of the stored
    procedure itself.
<5> Finally, call `invoke()` to execute the procedure.

Invoking the stored procedure returns an
link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] object, which
contains the value(s) returned from the stored procedure call and the results can
be extracted from it:

[source,java,indent=0]
----
include::{exampledir}/CallTest.java[tags=getOutParameters]
----

It is possible to access open cursors as a result set objects by declaring them
as link:{jdkdocs}/java.sql/java/sql/Types.html#REF_CURSOR[Types.REF_CURSOR^] and then using link:{jdbidocs}/core/statement/OutParameters.html#getRowSet(int)[OutParameters#getRowSet()^] to access them as link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^] objects. This requires  support from the JDBC driver for the database and is not supported by all databases. Please consult the documentation for the database driver first before filing a bug.

Results must be consumed before closing the statement because closing it will also close all resources and result sets associated with it.

The link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] object can either be returned from the Call using link:{jdbidocs}/core/statement/Call.html#invoke()[Call#invoke()^] or it can be processed as
a consumer argument with link:{jdbidocs}/core/statement/Call.html#invoke(java.util.function.Consumer)[Call#invoke(Consumer)^] or a function argument with
link:{jdbidocs}/core/statement/Call.html#invoke(java.util.function.Function)[Call#invoke(Function)^].

[WARNING]
Due to design constraints within JDBC, the parameter data types available
through link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] are limited to those types supported directly by JDBC. This cannot be expanded through e.g. mapper registration.


===== Using a ResultSet for procedure output values

Some database drivers might return a link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] containing the results of a stored procedure. This result set is available as a link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^] object by calling link:{jdbidocs}/core/statement/OutParameters.html#getResultSet()[OutParameters#getResultSet()^].

[NOTE]
While returning a result set from a procedure call is supported in the JDBC standard, it is pretty uncommon and only very few databases support it. The most prominent one is the JDBC driver for MS SQLServer. Most databases will either return null or an empty result set; in this case the link:{jdbidocs}/core/statement/OutParameters.html#getResultSet()[OutParameters#getResultSet()^] will return an empty link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^] object.

This is the equivalent procedure from above for MS SQLServer using a result set:

[source,sql]
----
CREATE PROCEDURE mssql_add
    @a INT,
    @b INT
AS
BEGIN
  SELECT @a + @b;
END
----

To access data from this procedure, it retrieves the result set using link:{jdbidocs}/core/statement/OutParameters.html#getResultSet()[OutParameters#getResultSet()^]:

[source, java]
----
try (Call call = h.createCall("{call mssql_add(:a, :b)}")) {
    call.bind("a", 13)
        .bind("b", 9);
    OutParameters output = call.invoke();

    int sum = output.getResultSet() // <1>
        .mapTo(Integer.class) // <2>
        .one();

    assertThat(sum).isEqualTo(22);
}
----
<1> Retrieve the output from the procedure using a result set.
<2> Map the first column in the result set to an integer value.

It may not be necessary to use a result set if the JDBC driver also supports OUT parameters. However, e.g. MS SQL Server does not allow link:{jdkdocs}/java.sql/java/sql/Types.html#REF_CURSOR[Types.REF_CURSOR^] as OUT parameters and requires the use of a result set.

It is possible to mix OUT parameters and a result set. In this case, the result set should be consumed before accessing any out parameters as the database driver might invalidate the result set when accessing out parameters.


==== Scripts

A *Script* parses a String into semicolon terminated statements. The statements
can be executed in a single *Batch* or individually.

[source,java,indent=0]
----
include::{exampledir}/StatementsTest.java[tags=script]
----

[NOTE]
Script parsing uses a generic SQL parser and creates separate statements. Depending on the database and its driver, there are small differences in how the script needs to be parsed. The most notorious issue is whether the parsed statements need to retain a trailing semicolon or not. Some databases (e.g. Oracle) require the trailing semicolon while others (e.g. MySQL) actually report a syntax error if it is present. As we can not please everyone equally, there is the link:{jdbidocs}/core/statement/SqlStatements.html#setScriptStatementsNeedSemicolon(boolean)[setScriptStatementsNeedSemicolon()^] switch, which controls this behavior. By default, Jdbi *retains the semicolon if present*.


Turning off the trailing semicolons for databases that have problems with it:
[source,java,indent=0]
----
jdbi.withHandle(h -> {
    // turn off trailing semicolons for script statements
    h.getConfig(SqlStatements.class).setScriptStatementsNeedSemicolon(false);
    return h.createScript(ClasspathSqlLocator.removingComments()
            .getResource("scripts/mysql-script.sql"))
        .execute();
    });
----


==== Metadata

Jdbi allows access to the Database Metadata through `queryMetadata` methods on the link:{jdbidocs}/core/Handle.html[Handle^].

Simple values can be queried directly using a method reference:

[source,java,indent=0]
----
String url = h.queryMetadata(DatabaseMetaData::getURL);
boolean supportsTransactions = h.queryMetadata(DatabaseMetaData::supportsTransactions);
----

Many methods on the link:{jdkdocs}/java.sql/java/sql/DatabaseMetaData.html[DatabaseMetaData^] return a link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^]. These can be used with the `queryMetadata` method that returns a <<ResultBearing>>.

All Jdbi <<Row Mappers>> and <<Column Mappers>> are available to map these results:

[source,java,indent=0]
----
List<String> catalogNames = h.queryMetadata(DatabaseMetaData::getCatalogs)
            .mapTo(String.class)
            .list();
----




=== Usage in asynchronous applications

Calling Jdbc and by extension Jdbi is inherently a blocking operation.
In asynchronous applications
(where results are returned as a link:{jdkdocs}/java.base/java/util/concurrent/CompletionStage.html[CompletionStage^]
or a link:{jdkdocs}/java.base/java/util/concurrent/CompletableFuture.html[CompletableFuture^])
it is very important never to block on threads that the caller doesn't control. For this, there is the
link:{jdbidocs}/core/async/JdbiExecutor.html[JdbiExcecutor^] class that wraps around a link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance
and makes sure calls are made on a specific thread pool.

To create a link:{jdbidocs}/core/async/JdbiExecutor.html[JdbiExcecutor^] instance, we first need to create
a link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance (see <<The Jdbi class>>). Then pass that instance into
link:{jdbidocs}/core/async/JdbiExecutor.html#create(org.jdbi.v3.core.Jdbi,java.util.concurrent.Executor)[JdbiExecutor.create()^]:

[source,java,indent=0]
----
include::{exampledir}/AsyncTest.java[tags=createJdbiExecutor]
----

It is important to size the executor to the specific implementation.
See link:{jdbidocs}/core/async/JdbiExecutor.html#create(org.jdbi.v3.core.Jdbi,java.util.concurrent.Executor)[here^] for some hints.

To use the `jdbiExecutor`, we make similar calls to link:{jdbidocs}/core/async/JdbiExecutor.html[JdbiExcecutor^]
as we do to link:{jdbidocs}/core/Jdbi.html[Jdbi^]

[source,java,indent=0]
----
include::{exampledir}/AsyncTest.java[tags=useHandle]
----

Or

[source,java,indent=0]
----
include::{exampledir}/AsyncTest.java[tags=withHandle]
----

Or

[source,java,indent=0]
----
include::{exampledir}/AsyncTest.java[tags=withExtension]
----

Note, since the handle closes as soon as the callback returns, you cannot return
an iterator, since iteration will call upon the (now closed) handle

[source,java,indent=0]
----
include::{exampledir}/AsyncTest.java[tags=failReturningIterator]
----

== Resource Management

JDBC operations involve stateful objects: link:{jdkdocs}/java.sql/java/sql/Connection.html[Connection^], link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html[PreparedStatement^] and link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] are the most common ones. Jdbi understands the lifecycle of these objects and can often fully manage them.

Within Jdbi, two types of stateful objects exist that need to be managed: <<Handle>> objects and all <<Statement types, Statement objects>>.

Manual resource management for Jdbi objects uses the standard Java _try-with-resources_ construct:

[source,java,indent=0]
----
try (Handle handle = jdbi.open();
    Query query = handle.createQuery("SELECT * from users")) {
    List<User> users = query.mapTo(User.class).list();
}
----


=== Automatic resource management

Jdbi can manage and release resources automatically, so that _try-with-resources_ blocks are often not needed.

Automatic resource management is only available with the SQL Object API and the Extension API. In these situations, Jdbi can manage all resources:

- with methods on a SQL object that was created with link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^]:

[source,java,indent=0]
----
UserDao userDao = jdbi.onDemand(UserDao.class);
User user = userDao.getUser(id);

public interface UserDao {
    @SqlQuery("SELECT * FROM users WHERE id = :id")
    @UseRowMapper(UserMapper.class)
    User getUser(@Bind("id") int id);
}
----

- with the Jdbi link:{jdbidocs}/core/Jdbi.html#withExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionCallback-[withExtension^] and link:{jdbidocs}/core/Jdbi.html#useExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionConsumer-[useExtension^] callbacks:

[source,java,indent=0]
----
User user = jdbi.withExtension(UserDao.class, dao -> dao.getUser(id));

public interface UserDao {
    @SqlQuery("SELECT * FROM users WHERE id = :id")
    @UseRowMapper(UserMapper.class)
    User getUser(@Bind("id") int id);
}
----


=== Handle resource management

Any time a handle is explicitly opened, it must be managed by the calling code. A _try-with-resources_ block is the best way to do this:

[source,java,indent=0]
----
try (Handle handle = jdbi.open()) {
    // handle operations here
}
----

Closing the handle releases the connection that is managed by the handle. Handle resource management is only necessary when using the various link:{jdbidocs}/core/Jdbi.html#open()[Jdbi#open()^] methods on the Jdbi object. Any handle that is passed in through a callback (link:{jdbidocs}/core/Jdbi.html#withHandle(org.jdbi.v3.core.HandleCallback)[Jdbi#withHandle()^], link:{jdbidocs}/core/Jdbi.html#useHandle(org.jdbi.v3.core.HandleConsumer)[Jdbi#useHandle()^], link:{jdbidocs}/core/Jdbi.html#inTransaction(org.jdbi.v3.core.HandleCallback)[Jdbi#inTransaction()^], link:{jdbidocs}/core/Jdbi.html#useTransaction(org.jdbi.v3.core.HandleConsumer)[Jdbi#useTransaction()^]) is managed through Jdbi:

Jdbi is still able to manage statement resources even if the handle is managed manually:

[source,java,indent=0]
----

try (Handle handle = jdbi.open()) { // <1>
    UserDao dao = handle.attach(UserDao.class);
    User user = userDao.getUser(id);
}

User user = jdbi.withHandle(handle -> { // <2>
    UserDao dao = handle.attach(UserDao.class);
    return userDao.getUser(id);
});

public interface UserDao {
    @SqlQuery("SELECT * FROM users WHERE id = :id")
    @UseRowMapper(UserMapper.class)
    User getUser(@Bind("id") int id);
}
----
<1> link:{jdbidocs}/core/Jdbi.html#open()[Jdbi.open()^] creates a new Handle that must be managed through a _try-with-resources_ block.
<2> link:{jdbidocs}/core/Jdbi.html#withHandle(org.jdbi.v3.core.HandleCallback)[jdbi.withHandle()^] passes a managed Handle to the callback and does not require management.

[#statement-resource-management]
=== Statement resource management

All statement types may use resources that need to be released. There are multiple ways to do; each has its advantages and drawbacks:

* <<Explicit statement resource management>> uses code to manage and release resources
* <<Implicit statement resource cleanup>> relies on the Jdbi framework to release the resources when necessary
* <<Attaching statements to the handle lifecycle>> delegates to the Handle lifecycle


==== Explicit statement resource management

All <<Statement types, SQL statement types>> implement the link:{jdkdocs}/java.base/java/lang/AutoCloseable.html[AutoCloseable^] interface and can be used in a _try-with-resources_ block. This is the recommended way to manually manage statements, and it ensures that all resources are properly released when they are no longer needed. The _try-with-resources_ pattern ensures that the link:{jdkdocs}/java.base/java/lang/AutoCloseable.html#close--[close()^] method on the SQL statement is called which releases the resources.

Create, execute and release 100,000 update statements:

[source,java,indent=0]
----
try (Handle handle = jdbi.open()) {
    for (int i = 0; i < 100_000; i++) {
        try (Update update = handle.createUpdate("INSERT INTO users (id, name) VALUES (:id, :name)")) {
            update.bind("id", i)
                  .bind("name", "user_" + i)
                  .execute();
        }
    }
}
----

It is not necessary to use a _try-with-resources_ block, the close() method can be called manually as well:

[source,java,indent=0]
----
try (Handle handle = jdbi.open()) {
    for (int i = 0; i < 100_000; i++) {
        Update update = handle.createUpdate("INSERT INTO users (id, name) VALUES (:id, :name)");
        try {
            update.bind("id", i)
                  .bind("name", "user_" + i)
                  .execute();
        } finally {
            update.close();
        }
    }
}
----

Explicit statement resource management, while a bit more involved ensures that all resources are always correctly released, especially when there are exceptions thrown during statement execution. While many examples and demo code omit managing the <<Statement types, statement types>>, it is strongly recommended to do so.


==== Implicit statement resource cleanup

If possible, Jdbi will help with resource management through implicit resource cleanup.

If a SQL statement operation succeeds  and *all data returned by the database was consumed*, then Jdbi will release the allocated resources even if the statement is used without a _try-with-resources_ block.

All terminal operations on the link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^] interface, except for the link:{jdbidocs}/core/result/ResultIterable.html#stream()[stream()^] and link:{jdbidocs}/core/result/ResultIterable.html#stream()#iterator()[iterator()^] methods, consume all data from the database, even if they return only a subset (e.g. link:{jdbidocs}/core/result/ResultIterable.html#findOne()[findOne()^]). The same applies for operations such as Update or Batch.

For all other operations, the resources will be released if the operation succeeds and does not throw an exception.

[source,java,indent=0]
----
try (Handle handle = jdbi.open()) {
    List<User> users = handle
        .createQuery("SELECT * from users") // <1>
        .mapTo(User.class) // <2>
        .list(); // <3>
}
----
<1> creates a link:{jdbidocs}/core/statement/Query.html[Query^] object
<2> returns an object implementing link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^]
<3> is a terminal operation that consumes all the data from the database

As long as no exception is thrown, this example above will release all resources allocated by the link:{jdbidocs}/core/statement/Query.html[Query^] object, even though it is not managed.

[WARNING]
This code that works well as long as nothing goes awry! If an unmanaged SQL statement operation fails halfway through (e.g. with a connection timeout or a database problem), then *resources will not be cleanup up by Jdbi*. This may lead to resource leaks that are difficult to find or reproduce. Some JDBC drivers will also clean up resources that they hand out (such as link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html[JDBC statements ^] or link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] objects) when a connection is closed. In these situations, resources may be released eventually when the handle is closed (which also closes the JDBC connection). This is highly driver dependent and should not be relied upon.


[#resources-with-streams-iterators]
==== Resources with Streams and Iterators

Most methods on objects that implement link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^] are terminal. They consume all data returned by the database and will release statement resources at the end. All of these methods may buffer results in memory, something that is not acceptable for very large data sets or when data needs to be streamed.

[TIP]
Just using an iterator or stream may not be enough to actually stream data without buffering it in memory. Often the JDBC driver might still buffer data. See the documentation for your database on how to ensure that the driver does not buffer all the results in memory.

For these use cases, Jdbi offers the link:{jdbidocs}/core/result/ResultIterable.html#stream()[stream()^] and link:{jdbidocs}/core/result/ResultIterable.html#iterator()[iterator()^] methods, which return lazy-loading objects that return data from the database row by row. These objects are stateful and must be managed.

The link:{jdkdocs}/java.base/java/util/stream/Stream.html[stream^] and link:{jdkdocs}/java.base/java/util/Iterator.html[iterator^] objects provided by Jdbi will release all their resources when the data stream from the database is exhausted or when an instance is explicitly closed. Standard Java link:{jdkdocs}/java.base/java/util/stream/Stream.html[Streams^] support the _try-with-resources_ pattern directly; the link:{jdbidocs}/core/result/ResultIterable.html#iterator()[iterator()^] method returns a link:{jdbidocs}/core/result/ResultIterator.html[ResultIterator^] object which extends link:{jdkdocs}/java.base/java/lang/AutoCloseable.html[AutoCloseable^].

When using a stream or iterator, *either* the statement *or* the result object *must* be managed. Calling link:{jdkdocs}/java.base/java/lang/AutoCloseable.html#close--[close()^] on either the statement or the stream/iterator will terminate the operation and release all resources.

[source,java,indent=0]
----
// managing resources through the query SQL statement
try (Handle handle = jdbi.open()) {
    try (Query query = handle.createQuery("SELECT * from users")) { // <1>
        Stream<User> users = query.mapTo(User.class).stream();
        // consume the stream
    }
}

// managing resources through the stream
try (Handle handle = jdbi.open()) {
    try (Stream<User> users = handle.createQuery("SELECT * from users")
        .mapTo(User.class)
        .stream()) { // <2>
            // consume the stream
        }
}
----
<1> use a _try-with-resources_ block with the <<Queries, Query>> object releases the resources and closes the stream when the block is left
<2> use a _try-with-resources_ block with the stream releases the resources and closes the stream when the block is left

The same pattern applies to a result iterator.

Streams and iterators are cursor-type "live" objects. They require an active statement and result set. Any operation that closes and releases these resources will cause future operations on the stream or iterator to fail.

The following code *does not work*:

[source,java,indent=0]
----
Stream<User> userStream = jdbi.withHandle(handle ->
    handle.createQuery("SELECT * from users")
        .mapTo(User.class)
        .stream();  <1>
    });  <2>

Optional<User> user = stream.findFirst(); <3>
----

<1> Creates a stream object backed by the open result set of the query
<2> leaving the callback closes the handle and releases all resources including the result set
<3> throws an exception because the result set has already been closed

This can be avoided by using one of the callback methods that ResultIterable offers: link:{jdbidocs}/core/result/ResultIterable.html#withIterator(org.jdbi.v3.core.result.IteratorCallback)[withIterator()^], link:{jdbidocs}/core/result/ResultIterable.html#useIterator(org.jdbi.v3.core.result.IteratorConsumer)[useIterator()^], link:{jdbidocs}/core/result/ResultIterable.html#withStream(org.jdbi.v3.core.result.StreamCallback)[withStream()^], link:{jdbidocs}/core/result/ResultIterable.htmll#useStream(org.jdbi.v3.core.result.StreamConsumer)[useStream()^]. Each of these methods manages the iterator / stream through Jdbi and allow consumption of its contents within a callback:

[source,java,indent=0]
----
try (Handle handle = jdbi.open()) {
    try (Query query = handle.createQuery("SELECT * from users")) {
        query.mapTo(User.class).useIterator(it -> {
            // consume the iterator contents
        });
    }
}
----

While it is not strictly necessary to execute the query in a _try-with-resources_ block because the link:{jdbidocs}/core/result/ResultIterable.html#useIterator(org.jdbi.v3.core.result.IteratorConsumer)[useIterator()^] method will close the iterator and release all resources from the query, it is good practice and guards against possible errors that may happen between the creation of the query and the callback execution.

Using a jdbi callback allows fully automated resource management:

[source,java,indent=0]
----
jdbi.useHandle(handle -> {
    handle.createQuery("SELECT * from users")
        .mapTo(User.class)
        .useIterator(it -> {
            // consume the iterator contents
        });
    });
----


==== OutParameters return values for stored procedures

Interacting with stored procedures generally involves passing values back and forth from database. Jdbi uses link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] objects which are returned from the various invoke methods of the link:{jdbidocs}/core/statement/Call.html[Call^] object.

When using link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] with stored procedures, the link:{jdbidocs}/core/statement/Call.html[Call^] statement *must* be managed. Calling link:{jdkdocs}/java.base/java/lang/AutoCloseable.html#close--[close()^] on the statement terminates the operation and release all resources.

Closing the stream or iterator associated with an object returned by link:{jdbidocs}/core/statement/OutParameters.html#getResultSet()[OutParameters#getResultSet()^] or link:{jdbidocs}/core/statement/OutParameters.html#getRowSet(int)[OutParameters#getRowSet()^] is *not* sufficient as the link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] object may hold multiple result sets.

[source, java]
----
try (Call call = h.createCall("{call some_procedure()}")) {
    OutParameters output = call.invoke();

    output.getRowSet("result") // <1>
        .mapTo(SomeType.class) // <2>
        .useStream(stream -> { ... consume stream ... }); <3>
}
----
<1> Retrieve the cursor for the `result` parameter
<2> Map the results onto a data type using a row mapper
<3> Consume the stream of objects with a consumer argument.

When the stream terminates, the link:{jdbidocs}/core/statement/Call.html[Call^] statement is *not* closed as it may have returned multiple cursor parameters. It must be managed using try-with-resources as shown above.

link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] objects are cursor-type "live" objects. They require an active statment and any operation that closes and releases the statement will cause future operations on a related link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] object to fail.

The following code *does not work*:

[source,java,indent=0]
----
// DOES NOT WORK!
OutParameters out  = jdbi.withHandle(handle -> {
    Call call = handle.createCall("{call some_procedure()}");
    return call.invoke(); // <1>
}); // <2>
String result = out.getString("result"); // <3>
----
<1> Creates an OutParameter object and returns it from withHandle.
<2> Leaving the callback closes the handle and releases all resources including the statement.
<3> throws an exception because closing the handle and the statement invalidates the link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] object.

This can be avoided by either processing the link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] object within the handle callback or by using either the link:{jdbidocs}/core/statement/Call.html#invoke(java.util.function.Consumer)[Call#invoke(Consumer)^] or
link:{jdbidocs}/core/statement/Call.html#invoke(java.util.function.Function)[Call#invoke(Function)^] callback methods:

[source,java,indent=0]
----
// process the OutParameters within the handle callback
String result  = jdbi.withHandle(handle -> {
    Call call = handle.createCall("{call some_procedure()}");
    OutParameters out = call.invoke();
    return out.getString("result");
});
----

[source,java,indent=0]
----
// use a callback method from the Call statement
String result  = jdbi.withHandle(handle -> {
    Call call = handle.createCall("{call some_procedure()}");
    return call.invoke(out -> out.getString("result"));
});
----


==== Attaching statements to the handle lifecycle

An elegant way to manage resources is attaching the statement to the handle lifecycle. Calling the link:{jdbidocs}/core/statement/SqlStatement.html#attachToHandleForCleanup()[attachToHandleForCleanup()^] method, which is available on <<Statement types, SQL statements>>, associates the statement with the handle. When the handle is closed, all attached statements that have not been cleaned up yet, will also be released.

[source,java,indent=0]
----
Optional<User> user = handle.createQuery("SELECT * FROM users WHERE id = :id")
        .attachToHandleForCleanup() <1>
        .bind("id", id)
        .mapTo(User.class)
        .stream()
        .findAny();
----

<1> By attaching the statement to the handle, all resources are now managed by Jdbi and released even if the operation throws an exception.

This works best for short-lived handles with a few statement operations. As the resources may not be released until the handle is closed, executing a large number of SQL statements that all may need cleaning up could lead to resource exhaustion. When in doubt, prefer the _try-with-resources_ construct over attaching a SQL statements to the handle.

It is possible to attach all created statements by default to a handle by calling link:{jdbidocs}/core/statement/SqlStatements.html#setAttachAllStatementsForCleanup(boolean)[setAttachAllStatementsForCleanup(true)^] on the SqlStatements config object:

[source,java,indent=0]
----
jdbi.getConfig(SqlStatements.class)
    .setAttachAllStatementsForCleanup(true);

try (Handle handle = jdbi.open()) {
    Optional<User> user = handle.createQuery("SELECT * FROM users WHERE id = :id")
        .bind("id", id)
        .mapTo(User.class)
        .stream()
        .findAny();
}
----

This setting can be controlled either per Jdbi object or per Handle.

[source,java,indent=0]
----
try (Handle handle = jdbi.open()) {
    handle.getConfig(SqlStatements.class)
        .setAttachAllStatementsForCleanup(true);

    Optional<User> user = handle.createQuery("SELECT * FROM users WHERE id = :id")
        .bind("id", id)
        .mapTo(User.class)
        .stream()
        .findAny();
}
----


As a special case, any method on the Jdbi object that takes a callback (link:{jdbidocs}/core/Jdbi.html#withHandle(org.jdbi.v3.core.HandleCallback)[withHandle^], link:{jdbidocs}/core/Jdbi.html#useHandle(org.jdbi.v3.core.HandleConsumer)[useHandle^], link:{jdbidocs}/core/Jdbi.html#inTransaction(org.jdbi.v3.core.HandleCallback)[inTransaction^], link:{jdbidocs}/core/Jdbi.html#useTransaction(org.jdbi.v3.core.HandleConsumer)[useTransaction^]) attaches statements created in the callback by default to the handle passed into the callback. These handles are fully managed and will be closed when the callback exits.

[source,java,indent=0]
----
User user = jdbi.withHandle(handle ->
    handle.createQuery("SELECT * FROM users WHERE id = :id")
        .bind("id", id)
        .mapTo(User.class)
        .one());
----

This behavior can be controlled through the link:{jdbidocs}/core/statement/SqlStatements.html#setAttachCallbackStatementsForCleanup(boolean)[setAttachCallbackStatementsForCleanup()^] method.
If a callback executes a huge number of statements, it may be preferable to manage resources manually:

[source,java,indent=0]
----
jdbi.useHandle(handle -> {
    handle.getConfig(SqlStatements.class).setAttachCallbackStatementsForCleanup(false); <1>

    for (int i = 0; i < 100_000; i++) {
        try (Update update = handle.createUpdate("INSERT INTO users (id, name) VALUES (:id, :name)")) {
            update.bind("id", i)
                  .bind("name", "user_" + i)
                  .execute();
        }
    }
});
----

<1> Turn off automatic attachment of statements to the handle because the callback creates a large number of statements. Modifying this value only changes the setting for the current handle; it does not affect the global setting associated with the Jdbi object that created the handle.


[NOTE]
While the `attachAllStatementsForCleanup` setting affects all statements created *outside* a Jdbi callback (link:{jdbidocs}/core/Jdbi.html#withHandle(org.jdbi.v3.core.HandleCallback)[withHandle^], link:{jdbidocs}/core/Jdbi.html#useHandle(org.jdbi.v3.core.HandleConsumer)[useHandle^], link:{jdbidocs}/core/Jdbi.html#inTransaction(org.jdbi.v3.core.HandleCallback)[inTransaction^], link:{jdbidocs}/core/Jdbi.html#useTransaction(org.jdbi.v3.core.HandleConsumer)[useTransaction^]), *inside* these callbacks, the behavior is controlled by the `attachCallbackStatementsForCleanup` setting.
The default value for the `attachAllStatementsForCleanup` is `false` while the default value for `attachCallbackStatementsForCleanup` is `true`.

== Arguments

Arguments are Jdbi's representation of JDBC statement parameters (the `?` in `SELECT * FROM Foo WHERE bar = ?`).

To set a parameter `?` on a JDBC `PreparedStatement`, you would `ps.setString(1, "Baz")`.
With Jdbi, when you bind the string `"Baz"`, it will search through all registered _ArgumentFactory_ instances
until it finds one that is willing to convert the String into an _Argument_.
The argument is responsible for setting the String for the placeholder exactly as `setString` does.

Arguments can perform more advanced bindings than simple JDBC supports:
a BigDecimal could be bound as a SQL decimal, a java.time.Year as a SQL int,
or a complex object could be serialized to a byte array and bound as a SQL blob.

[NOTE]
The use of Jdbi arguments is limited to JDBC prepared statement parameters.
Notably, arguments usually cannot be used to change the structure of a query
(for example the table or column name, `SELECT` or `INSERT`, etc.)
nor may they be interpolated into string literals.
See <<Query Templating>> and <<TemplateEngine>> for more information.


=== Positional Arguments

When a SQL statement uses `?` tokens, Jdbi can bind a values to parameters
at the corresponding index (0-based):

[source,java,indent=0]
----
include::{exampledir}/FiveMinuteTourTest.java[tags=positionalParameters]
----


=== Named Arguments

When a SQL statement uses colon-prefixed tokens like `:name`, Jdbi can bind
parameters by name:

[source,java,indent=0]
----
include::{exampledir}/FiveMinuteTourTest.java[tags=namedParameters]
----

A parameter or attribute name can contain any valid Java identifier characters and the dot (`.`).

[NOTE]
By default, Jbdi uses the see the link:{jdbidocs}/core/statement/ColonPrefixSqlParser.html[ColonPrefixSqlParser^] that understands
the  `:foo` syntax. This can be changed if the colon is problematic in the SQL dialect used. Jdbi includes support for an alternate `#foo` syntax out-of-the-box using the link:{jdbidocs}/core/statement/HashPrefixSqlParser.html[HashPrefixSqlParser^]. It is also possible to create custom parsers for named arguments.

[TIP]
Mixing named and positional arguments is not allowed, as it would become confusing very quickly.


=== Supported Argument Types

Out of the box, Jdbi supports the following types as SQL statement arguments:

* Primitives: `boolean`, `byte`, `short`, `int`, `long`, `char`, `float`, and
  `double`
* java.lang: `Boolean`, `Byte`, `Short`, `Integer`, `Long`, `Character`,
  `Float`, `Double`, `String`, and `Enum` (stored as the enum value's name by default)
* java.math: `BigDecimal`
* java.net: `Inet4Address`, `Inet6Address`, `URL`, and `URI`
* java.sql: `Blob`, `Clob`, `Date`, `Time`, and `Timestamp`
* java.time: `Instant`, `LocalDate`, `LocalDateTime`, `LocalTime`,
  `OffsetDateTime`, `ZonedDateTime`, and `ZoneId`
* java.util: `Date`, link:{jdkdocs}/java.base/java/util/Optional.html[Optional^] (around any other supported type), and `UUID`
* `java.util.Collection` and Java arrays (stored as SQL arrays).
Some additional setup may be required depending on the type of array element.

[NOTE]
The binding and mapping method for enum values
can be controlled via the link:{jdbidocs}/core/enums/Enums.html[Enums^] config,
as well as the annotations link:{jdbidocs}/core/enums/EnumByName.html[@EnumByName^],
link:{jdbidocs}/core/enums/EnumByOrdinal.html[@EnumByOrdinal^], and
link:{jdbidocs}/core/enums/DatabaseValue.html[@DatabaseValue^].

You can also configure Jdbi to support additional argument types.
More on that later.

=== Binding Arguments

Arguments to SQL statement can be bound in a few different ways.

You can bind individual arguments:

[source,java,indent=0]
----
handle.createUpdate("INSERT INTO contacts (id, name) VALUES (:id, :name)")
    .bind("id", 1)
    .bind("name", "Alice")
    .execute();
----

You can bind multiple arguments at once from the entries of a link:{jdkdocs}/java.base/java/util/Map.html[Map^]:

[source,java,indent=0]
----
Map<String, Object> contact = new HashMap<>();
contact.put("id", 2)
contact.put("name", "Bob");

handle.createUpdate("INSERT INTO contacts (id, name) VALUES (:id, :name)")
    .bindMap(contact)
    .execute();
----

You can bind multiple values at once, from either a link:{jdkdocs}/java.base/java/util/List.html[List<T>^] or a vararg:

[source,java,indent=0]
----
List<String> keys = new ArrayList<String>()
keys.add("user_name");
keys.add("street");

handle.createQuery("SELECT value FROM items WHERE kind in (<listOfKinds>)")
    .bindList("listOfKinds", keys)
    .mapTo(String.class)
    .list();

// or, using the 'vararg' definition
handle.createQuery("SELECT value FROM items WHERE kind in (<varargListOfKinds>)")
    .bindList("varargListOfKinds", "user_name", "docs", "street", "library")
    .mapTo(String.class)
    .list();
----

[NOTE]
Using `bindList` requires writing your SQL with an attribute, not a binding,
despite the fact that your values are bound. The attribute is a placeholder that will be
safely rendered to a comma-separated list of binding placeholders.


You can bind multiple arguments from properties of a Java Bean:

[source,java,indent=0]
----
Contact contact = new Contact();
contact.setId(3);
contact.setName("Cindy");

handle.createUpdate("INSERT INTO contacts (id, name) VALUES (:id, :name)")
    .bindBean(contact)
    .execute();
----

You can also bind an Object's public fields:

[source,java,indent=0]
----
Object contact = new Object() {
    public int id = 0;
    public String name = "Cindy";
};

handle.createUpdate("INSERT INTO contacts (id, name) VALUES (:id, :name)")
    .bindFields(contact)
    .execute();
----

Alternatively, you can bind public, parameter-less methods of an Object:

[source,java,indent=0]
----
Object contact = new Object() {
    public int theId() {
        return 0;
    }

    public String theName() {
        return "Cindy";
    }
};

handle.createUpdate("INSERT INTO contacts (id, name) VALUES (:theId, :theName)")
    .bindMethods(contact)
    .execute();
----

Optionally, you can qualify each bound bean/object with a prefix. This can help
remove ambiguity in situations where two or more bound beans have similar
property names:

[source,java,indent=0]
----
Folder folder = new Folder(1, "Important Documents");
Document document =
    new Document(100, "memo.txt", "Business business business. Numbers.");

handle.createUpdate("INSERT INTO documents (id, folder_id, name, contents) " +
                    "VALUES (:d.id, :f.id, :d.name, :d.contents)")
    .bindBean("f", folder)
    .bindMethods("f", folder)
    .bindFields("d", document)
    .execute();
----

[NOTE]
`bindBean()`, `bindFields()`, and `bindMethods()` may be used to bind nested
properties, e.g. `:user.address.street`.

[CAUTION]
`bindMap()` does not bind nested properties--map keys are expected to exactly
match the bound parameter name.

[TIP]
The authors recommend checking out <<Immutables>> support for an advanced way
to easily bind and map value types.


=== Argument Annotations

* `@JdbiProperty(bind=false)` allows configuring whether a discovered property is bound as an argument. Turn the `bind` annotation value off, and the property discovery mechanism will ignore it.


=== Custom Arguments

Occasionally your data model will use data types not natively supported by
Jdbi (see <<Supported Argument Types>>).

Fortunately, Jdbi can be configured to bind custom data types as arguments,
by implementing a few simple interfaces.

[NOTE]
Core JDBC features are generally well-supported by all database vendors.
However, more advanced usages like array support or geometry types tend to
quickly become vendor-specific.


==== Using the Argument interface

The link:{jdbidocs}/core/argument/Argument.html[Argument^] interface wraps a
single value into a binding.

[source,java,indent=0]
----
include::{exampledir}/ArgumentsTest.java[tags=uuidArgument]
----

<1> Since Argument usually directly calls into JDBC directly, it is given the
*one-based index* (as expected by JDBC) when it is applied.

Here we use an *Argument* to directly bind a UUID. In this particular case,
the most obvious approach is to send the UUID to the database as a String. If
your JDBC driver supports custom types directly or efficient binary transfers,
you can leverage them easily here.


==== Using the ArgumentFactory interface

The link:{jdbidocs}/core/argument/ArgumentFactory.html[ArgumentFactory^]
interface provides <<Using the Argument interface, Argument interface>> instances for any data type it knows about. By implementing and registering an argument factory, it is possible to bind custom data types without having to explicitly wrap them in objects implementing the link:{jdbidocs}/core/argument/Argument.html[Argument^] interface.

Jdbi provides an link:{jdbidocs}/core/argument/AbstractArgumentFactory.html[AbstractArgumentFactory^] class which simplifies implementing
the link:{jdbidocs}/core/argument/ArgumentFactory.html[ArgumentFactory^] contract:

[source,java,indent=0]
----
include::{exampledir}/ArgumentsTest.java[tags=uuidArgumentFactory]
----

<1> The JDBC link:{jdkdocs}/java.sql/java/sql/Types.html[SQL type constant^] to use when
    binding UUIDs. Jdbi needs this in order to bind UUID values of `null`. See
   link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html#setNull-int-int-[PreparedStatement.setNull(int,int)^]
<2> Since `Argument` is a functional interface, it can be implemented as a lambda expression.


==== Using Prepared Arguments for batches

Traditional argument factories decide to bind based on both the type and actual value of the binding.
This is very flexible but when binding a large `PreparedBatch` it incurs a serious performance penalty
as the entire chain of argument factories must be consulted for each batch of arguments added.
To address this issue, implement `ArgumentFactory.Preparable` which promises to handle all values
of a given `Type`.  Most built in argument factories now implement the Preparable interface.

Preparable argument factories are consulted before traditional argument factories. If you'd prefer
to keep the old behavior, you may disable this feature with `getConfig(Arguments.class).setPreparedArgumentsEnabled(false)`.


==== The Arguments Registry

When you register an `ArgumentFactory`, the registration is stored in an
link:{jdbidocs}/core/argument/Arguments.html[Arguments^] instance held by Jdbi.
`Arguments` is a configuration class, which stores all registered argument
factories (including the factories for built-in arguments).

Under the hood, when you bind arguments to a statement, Jdbi consults the
`Arguments` config object and searches for an `ArgumentFactory` which knows how
to convert a bound object into an `Argument`.

Later, when the statement is executed, each `Argument` located during binding
is applied to the JDBC
link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html[PreparedStatement^].

[NOTE]
Occasionally, two or more argument factories will support arguments of the same
data type. When this happens, the last-registered factory wins. Preparable argument factories
always take precedence over base argument factories. This means that
you can override the way any data type is bound, including the data types
supported out of the box.


== Mappers

Jdbi makes use of mappers to convert result data into Java objects. There are
two types of mappers:

* <<Row Mappers>>, which map a full row of result set data.
* <<Column Mappers>>, which map a single column of a result set row.


=== Row Mappers

link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^] is a functional
interface, which maps the current row of a JDBC
link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] to a mapped type. Row
mappers are invoked once for each row in the result set.

Since link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^] is a functional interface, they can be provided inline to a
query using a lambda expression:

[source,java,indent=0]
----
include::{exampledir}/ResultsTest.java[tags=inlineRowMapper]
----

[TIP]
There are three different types being used in the above example. link:{jdbidocs}/core/statement/Query.html[Query^],
returned by `Handle.createQuery()`, implements the link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^] interface.
The `ResultBearing.map()` method takes a link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper<T>^] and returns a
`ResultIterable<T>`. Finally, `ResultBearing.list()` collects each row in the
result set into a link:{jdkdocs}/java.base/java/util/List.html[List<T>^].

Row mappers may be defined as classes, which allows for re-use:

[source,java,indent=0]
----
include::{exampledir}/ResultsTest.java[tags=userMapper]
----

[source,java,indent=0]
----
include::{exampledir}/ResultsTest.java[tags=rowMapper]
----

This link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^] is equivalent to the lambda mapper above but more explicit.


==== RowMappers registry

Row mappers can be registered for particular types. This simplifies usage,
requiring only that you specify what type you want to map to. Jdbi
automatically looks up the mapper from the registry, and uses it.

[source,java,indent=0]
----
jdbi.registerRowMapper(User.class,
    (rs, ctx) -> new User(rs.getInt("id"), rs.getString("name"));

try (Handle handle = jdbi.open()) {
    List<User> users = handle
        .createQuery("SELECT id, name FROM user ORDER BY id ASC")
        .mapTo(User.class)
        .list();
}
----

A mapper which implements link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^] with an explicit mapped type (such as the
`UserMapper` class in the previous section) may be registered without specifying
the mapped type:

[source,java,indent=0]
----
handle.registerRowMapper(new UserMapper());
----

When this method is used, Jdbi inspects the generic class signature of the
mapper to automatically discover the mapped type.

It is possible to register more than one mapper for any given type. When this
happens, the last-registered mapper for a given type takes precedence. This
permits optimizations, like registering a "default" mapper for some type, while
allowing that default mapper to be overridden with a different one when
appropriate.


==== RowMapperFactory

A link:{jdbidocs}/core/mapper/RowMapperFactory.html[RowMapperFactory^] can
produce row mappers for arbitrary types.

Implementing a factory might be preferable to a regular row mapper if:

* The mapper implementation is generic, and could apply to multiple mapped
  types. For example, Jdbi provides a generalized <<BeanMapper>>, which maps
  columns to bean properties for any bean class.
* The mapped type has a generic signature, and/or the mapper could be composed
  of other registered mappers. For example, Jdbi provides a
  <<mapentry-mapping,Map.Entry<K,V> mapper>>, provided a mapper is registered
  for types `K` and `V`.
* You want to bundle multiple mappers into a single class.

Let's take an example `Pair<L, R>` class:

[source,java,indent=0]
----
public final class Pair<L, R> {
    public final L left;
    public final R right;

    public Pair(L left, R right) {
        this.left = left;
        this.right = right;
    }
}
----

Now, let's implement a row mapper factory. The factory should produce a
link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper<Pair<L, R>>^] for any `Pair<L, R>` type, where the `L` type is mapped
from the first column, and `R` from the second--assuming there are column
mappers registered for both `L` and `R`.

Let's take this one step at a time:

[source,java,indent=0]
----
public class PairMapperFactory implements RowMapperFactory {
    public Optional<RowMapper<?>> build(Type type, ConfigRegistry config) {
        // ...
    }
}
----

The `build` method accepts a mapped type, and a config registry. It may return
`Optional.of(someMapper)` if it knows how to map that type, or
link:{jdkdocs}/java.base/java/util/Optional.html#empty--[Optional.empty()^] otherwise.

First we check whether the mapped type is a `Pair`:

[source,java,indent=0]
----
if (!Pair.class.equals(GenericTypes.getErasedType(type))) {
    return Optional.empty();
}
----

[TIP]
The `GenericTypes` utility class is discussed in <<Working with Generic Types>>.

Next, we extract the `L` and `R` generic parameters from the mapped type:

[source,java,indent=0]
----
Type leftType = GenericTypes.resolveType(Pair.class.getTypeParameters()[0], type);
Type rightType = GenericTypes.resolveType(Pair.class.getTypeParameters()[1], type);
----

In the first line, `Pair.class.getTypeParameters()[0]` gives the type variable
`L`. Likewise in the second line, `Pair.class.getTypeParameters()[1]` gives the type
variable `R`.

We use `resolveType()` to resolve the types for the `L` and `R` type variables
in the context of the mapped type.

Now that we have the types for `L` and `R`, we can look up the column mappers
for those types from the `ColumnMappers` config class, through the config
registry:

[source,java,indent=0]
----
ColumnMappers columnMappers = config.get(ColumnMappers.class);

ColumnMapper<?> leftMapper = columnMappers.findFor(leftType)
    .orElseThrow(() -> new NoSuchMapperException(
        "No column mapper registered for Pair left parameter " + leftType));
ColumnMapper<?> rightMapper = columnMappers.findFor(rightType)
    .orElseThrow(() -> new NoSuchMapperException(
        "No column mapper registered for Pair right parameter " + rightType));
----

The config registry is a locator for config classes. So when we call
`config.get(ColumnMappers.class)`, we get back a `ColumnMappers` instance with
the current column mapper configuration.

Next we call `ColumnMappers.findFor()` to get the column mappers for the left
and right types.

[TIP]
You may have noticed that although this method can return link:{jdkdocs}/java.base/java/util/Optional.html[Optional^], we are
throwing an exception if we can't find the left- or right-hand mappers. We have
found this to be a best practice: return link:{jdkdocs}/java.base/java/util/Optional.html#empty--[Optional.empty()^] if the factory
knows nothing about the mapped type (`Pair`, in this case). If it knows the
mapped type but is missing some configuration to make it work (e.g. mappers not
registered for `L` or `R` parameter) it is more helpful to throw an exception
with an informative message, so users can diagnose _why_ the mapper is not
working as expected.

Finally, we construct a pair mapper, and return it:

[source,java,indent=0]
----
RowMapper<?> pairMapper = (rs, ctx) ->
    new Pair(leftMapper.map(rs, 1, ctx), // In JDBC, column numbers start at 1
             rightMapper.map(rs, 2, ctx));

return Optional.of(pairMapper);
----

Here is the factory class all together:

[source,java,indent=0]
----
public class PairMapperFactory implements RowMapperFactory {
    public Optional<RowMapper<?>> build(Type type, ConfigRegistry config) {
        if (!Pair.class.equals(GenericTypes.getErasedType(type))) {
            return Optional.empty();
        }

        Type leftType = GenericTypes.resolveType(Pair.class.getTypeParameters()[0], type);
        Type rightType = GenericTypes.resolveType(Pair.class.getTypeParameters()[1], type);

        ColumnMappers columnMappers = config.get(ColumnMappers.class);

        ColumnMapper<?> leftMapper = columnMappers.findFor(leftType)
            .orElseThrow(() -> new NoSuchMapperException(
                "No column mapper registered for Pair left parameter " + leftType));
        ColumnMapper<?> rightMapper = columnMappers.findFor(rightType)
            .orElseThrow(() -> new NoSuchMapperException(
                "No column mapper registered for Pair right parameter " + rightType));

        RowMapper<?> pairMapper = (rs, ctx) -> new Pair(leftMapper.map(rs, 1, ctx),
            rightMapper.map(rs, 2, ctx));

        return Optional.of(pairMapper);
    }
}
----

Row mapper factories may be registered similar to regular row mappers:

[source,java,indent=0]
----
jdbi.registerRowMapper(new PairMapperFactory());

try (Handle handle = jdbi.open()) {
    List<Pair<String, String>> configPairs = handle
        .createQuery("SELECT key, value FROM config")
        .mapTo(new GenericType<Pair<String, String>>() {})
        .list();
}
----

[TIP]
The `GenericType` utility class is discussed in <<Working with Generic Types>>.


=== Column Mappers

link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper^] is a functional
interface, which maps a column from the current row of a JDBC
link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] to a mapped type.

Since link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper^] is a functional interface, they can be provided inline to a query using a lambda expression:

[source,java,indent=0]
----
List<Money> amounts = handle
    .select("SELECT amount FROM transactions WHERE account_id = ?", accountId)
    .map((rs, col, ctx) -> Money.parse(rs.getString(col))) // <1>
    .list();
----

Whenever a column mapper is used to map rows, only the first column of each row
is mapped.

Column mappers may be defined as classes, which allows for re-use:

[source,java,indent=0]
----
public class MoneyMapper implements ColumnMapper<Money> {
    public Money map(ResultSet r, int columnNumber, StatementContext ctx) throws SQLException {
        return Money.parse(r.getString(columnNumber));
    }
}
----

[source,java,indent=0]
----
List<Money> amounts = handle
    .select("SELECT amount FROM transactions WHERE account_id = ?", accountId)
    .map(new MoneyMapper())
    .list();
----

This link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper^] is equivalent to the lambda mapper above, but more explicit.


==== ColumnMappers registry

Column mappers may be registered for specific types. This simplifies usage,
requiring only that you specify what type you want to map to. Jdbi automatically
looks up the mapper from the registry, and uses it.

[source,java,indent=0]
----
jdbi.registerColumnMapper(Money.class,
    (rs, col, ctx) -> Money.parse(rs.getString(col)));

List<Money> amounts = jdbi.withHandle(handle ->
    handle.select("SELECT amount FROM transactions WHERE account_id = ?", accountId)
        .mapTo(Money.class)
        .list());
----

A mapper which implements link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper^] with an explicit mapped type (such as
the `MoneyMapper` class in the previous section) may be registered without
specifying the mapped type:

[source,java,indent=0]
----
handle.registerColumnMapper(new MoneyMapper());
----

When this method is used, Jdbi inspects the generic class signature of the
mapper to automatically discover the mapped type.

It is possible to register more than one mapper for any given type. When this
happens, the last-registered mapper for a given type takes precedence. This
permits optimizations, like registering a "default" mapper for some type, while
allowing that default mapper to be overridden with a different one when
appropriate.

Out of the box, column mappers are registered for the following types:

* Primitives: `boolean`, `byte`, `short`, `int`, `long`, `char`, `float`, and
  `double`
* java.lang: `Boolean`, `Byte`, `Short`, `Integer`, `Long`, `Character`,
  `Float`, `Double`, `String`, and `Enum` (stored as the enum value's name by default)
* java.math: `BigDecimal`
* `byte[]` arrays (e.g. for BLOB or VARBINARY columns)
* java.net: `InetAddress`, `URL`, and `URI`
* java.sql: `Timestamp`
* java.time: `Instant`, `LocalDate`, `LocalDateTime`, `LocalTime`,
  `OffsetDateTime`, `ZonedDateTime`, and `ZoneId`
* java.util: `UUID`
* `java.util.Collection` and Java arrays (for array columns). Some
  additional setup may be required depending on the type of array element--see
  <<SQL Arrays>>.

[NOTE]
The binding and mapping method for enum values
can be controlled via the link:{jdbidocs}/core/enums/Enums.html[Enums^] config,
as well as the annotations link:{jdbidocs}/core/enums/EnumByName.html[@EnumByName^],
link:{jdbidocs}/core/enums/EnumByOrdinal.html[@EnumByOrdinal^], and
link:{jdbidocs}/core/enums/DatabaseValue.html[@DatabaseValue^].


==== ColumnMapperFactory

A link:{jdbidocs}/core/mapper/ColumnMapperFactory.html[ColumnMapperFactory^] can
produce column mappers for arbitrary types.

Implementing a factory might be preferable to a regular column mapper if:

* The mapper class is generic, and could apply to multiple mapped types.
* The type being mapped is generic, and/or the mapper could be composed
  of other registered mappers.
* You want to bundle multiple mappers into a single class.

Let's create a mapper factory for `Optional<T>` as an example. The factory
should produce a link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper<Optional<T>>^] for any `T`, provided a column
mapper is registered for `T`.

Let's take this one step at a time:

[source,java,indent=0]
----
public class OptionalColumnMapperFactory implements ColumnMapperFactory {
    public Optional<ColumnMapper<?>> build(Type type, ConfigRegistry config) {
        // ...
    }
}
----

The `build` method accepts a mapped type, and a config registry. It may return
`Optional.of(someMapper)` if it knows how to map that type, or
link:{jdkdocs}/java.base/java/util/Optional.html#empty--[Optional.empty()^] otherwise.

First, we check whether the mapped type is an link:{jdkdocs}/java.base/java/util/Optional.html[Optional^]:

[source,java,indent=0]
----
if (!Optional.class.equals(GenericTypes.getErasedType(type))) {
    return Optional.empty();
}
----

[TIP]
The `GenericTypes` utility class is discussed in <<Working with Generic Types>>.

Next, extract the `T` generic parameter from the mapped type:

[source,java,indent=0]
----
Type t = GenericTypes.resolveType(Optional.class.getTypeParameters()[0], type);
----

The expression `Optional.class.getTypeParameters()[0]` gives the type variable
`T`.

We use `resolveType()` to resolve the type of `T` in the context of the mapped
type.

Now that we have the type of `T`, we can look up a column mapper for that type
from the `ColumnMappers` config class, through the config registry:

[source,java,indent=0]
----
ColumnMapper<?> tMapper = config.get(ColumnMappers.class)
    .findFor(embeddedType)
    .orElseThrow(() -> new NoSuchMapperException(
        "No column mapper registered for parameter " + embeddedType + " of type " + type));
----

The config registry is a locator for config classes. So when we call
`config.get(ColumnMappers.class)`, we get back a `ColumnMappers` instance with
the current column mapper configuration.

Next we call `ColumnMappers.findFor()` to get the column mapper for the embedded
type.

[TIP]
You may have noticed that although this method can return link:{jdkdocs}/java.base/java/util/Optional.html[Optional^], we're
throwing an exception if we can't find a mapper for the embedded type. We've
found this to be a best practice: return link:{jdkdocs}/java.base/java/util/Optional.html#empty--[Optional.empty()^] if the factory knows
nothing about the mapped type (link:{jdkdocs}/java.base/java/util/Optional.html[Optional^], in this case). If it knows the mapped
type but is missing some configuration to make it work (e.g. no mapper
registered for tye `T` parameter) it is more helpful to throw an exception with
an informative message, so users can diagnose _why_ the mapper is not working as
expected.

Finally, we construct the column mapper for optionals, and return it:

[source,java,indent=0]
----
ColumnMapper<?> optionalMapper = (rs, col, ctx) ->
    Optional.ofNullable(tMapper.map(rs, col, ctx));

return Optional.of(optionalMapper);
----

Here is the factory class all together:

[source,java,indent=0]
----
public class OptionalColumnMapperFactory implements ColumnMapperFactory {
    public Optional<ColumnMapper<?>> build(Type type, ConfigRegistry config) {
        if (!Optional.class.equals(GenericTypes.getErasedType(type))) {
            return Optional.empty();
        }

        Type t = GenericTypes.resolveType(Optional.class.getTypeParameters()[0], type);

        ColumnMapper<?> tMapper = config.get(ColumnMappers.class)
            .findFor(t)
            .orElseThrow(() -> new NoSuchMapperException(
                "No column mapper registered for parameter " + t + " of type " + type));

        ColumnMapper<?> optionalMapper = (rs, col, ctx) -> Optional.ofNullable(tMapper.map(rs, col, ctx));

        return Optional.of(optionalMapper);
    }
}
----

Column mapper factories may be registered similar to regular column mappers:

[source,java,indent=0]
----
jdbi.registerColumnMapper(new OptionalColumnMapperFactory());

try (Handle handle = jdbi.open()) {
    List<Optional<String>> middleNames = handle
        .createQuery("SELECT middle_name FROM contacts")
        .mapTo(new GenericType<Optional<String>>() {})
        .list();
}
----

[TIP]
The `GenericType` utility class is discussed in <<Working with Generic Types>>.


=== Primitive Mapping

All Java primitive types have default mappings to their corresponding JDBC types.
Generally, Jdbi will automatically perform boxing and unboxing as appropriate when
it encounters wrapper types.

By default, SQL `null` mapped to a primitive type will adopt the JDBC default value.
This may be disabled by configuring
`jdbi.getConfig(ColumnMappers.class).setCoalesceNullPrimitivesToDefaults(false)`.


=== Immutables Mapping

`Immutables` value objects may be mapped, see the <<Immutables>> section for details.


=== Freebuilder Mapping

`Freebuilder` value objects may be mapped, see the <<Freebuilder>> section for details.


=== Reflection Mappers for Beans and POJOs

Jdbi provides a number of reflection-based mappers out of the box which treat column
names as attributes. The different mappers can be used to map values onto

* Java Bean properties (`BeanMapper`)
* Class fields (`FieldMapper`)
* Constructor parameters (`ConstructorMapper`)

There is also an equivalent mapper for Kotlin classes that supports constructor arguments and class properties.

Reflective mappers are snake_case aware and will automatically match up these
columns to camelCase field/argument/property names.


==== Supported property annotations

Reflection mappers support the following annotations.
Unless otherwise noted, all annotations are supported on bean getters and setters for the `BeanMapper`, constructor parameters for the `ConstructorMapper` and bean fields for the `FieldMapper`.

* link:{jdbidocs}/core/mapper/reflect/ColumnName.html[@ColumnName^] allows explicit naming of the column that is mapped to the specific attribute.
* link:{jdbidocs}/core/mapper/Nested.html[@Nested^] for nested beans.
Without this annotation, any attribute is treated as mappable from a single column.
This annotation creates a mapper for the nested bean.
There is a limitation that only one type of mapper can be nested at a time; `BeanMapper` will create another `BeanMapper`, `ConstructorMapper` will create another `ConstructorMapper` etc. link:{jdbidocs}/core/mapper/Nested.html[@Nested^] supports an optional prefix for all attributes in the nested bean (`@Nested("prefix")`).
* `@PropagateNull` on a given attribute propagates a null value for a specific attribute up.
So if the attribute or column is null, the whole bean will be discarded and a null value will be used instead of the bean itself.
This annotation can also be used on the bean class with a column name that must be present in the result set.
When used on an attribute, no value must be set.
* `@Nullable` for `ConstructorMapper` arguments.
If no column is mapped onto a specific constructor argument, don't fail but use `null` as value.
* `@JdbiProperty(map=false)` allows configuring whether a discovered property is mapped in results.
Turn the `map` value off, and the property discovery mechanism will ignore it.
This used to be called `@Unmappable`.

[NOTE]
The link:{jdbidocs}/core/mapper/reflect/ColumnName.html[@ColumnName^] annotation only applies while mapping SQL data into Java objects.
When binding object properties (e.g. with `bindBean()`), bind the property name (`:id`) rather than the column name (`:user_id`).

===== Using `@Nullable` annotations

Jdbi accepts any annotation that is named `Nullable` to mark a field or method as nullable.

These are popular choices:

- `jakarta.annotation.Nullable` -- https://search.maven.org/artifact/jakarta.annotation/jakarta.annotation-api[jakarta annotation-api^]
- `javax.annotation.Nullable` -- https://search.maven.org/artifact/com.google.code.findbugs/jsr305[findbugs jsr305^]
- `edu.umd.cs.findbugs.annotations.Nullable` -- https://search.maven.org/artifact/com.github.spotbugs/spotbugs-annotations[Spotbugs annotations^]
- `org.jetbrains.annotations.Nullable` -- https://search.maven.org/artifact/org.jetbrains/annotations[Jetbrains annotations^]
- `org.checkerframework.checker.nullness.qual.Nullable` -- https://search.maven.org/artifact/org.checkerframework/checker-qual[checker framework^]
- `org.springframework.lang.Nullable` -- https://search.maven.org/artifact/org.springframework/spring-core[Spring Framework^]

[WARNING]
To allow Jdbi to discover the `@Nullable` annotation at runtime, it must use link:{jdkdocs}/java.base/java/lang/annotation/RetentionPolicy.html#RUNTIME[RetentionPolicy.RUNTIME^].
When in doubt, prefer the link:{jakartadocs}/jakarta/annotation/nullable[Jakarta variant^]!.

==== ConstructorMapper

link:{jdbidocs}/core/mapper/reflect/ConstructorMapper.html[ConstructorMapper^] assigns columns to constructor parameters by
name. If the java compiler stores method parameter names in the java
classes (using the `-parameters` flag on the compiler -- see also
<<Compiling with Parameter Names>>), the constructor mapper will use
these names to select columns.

[source,java,indent=0]
----
include::{exampledir}/ResultsTest.java[tags=userConstructor]
----

Otherwise, the names can be explictly set with the link:{jdbidocs}/core/mapper/reflect/ColumnName.html[@ColumnName^]
annotation on each constructor parameter:

[source,java,indent=0]
----
public User(@ColumnName("id") int id, @ColumnName("name") String name) {
    this.id = id;
    this.name = name;
}
----

The standard Java Bean `@ConstructorProperties` annotation can also be used:

[source,java,indent=0]
----
@ConstructorProperties({"id", "name"})
public User(int id, String name) {
    this.id = id;
    this.name = name;
}
----

[TIP]
Lombok's `@AllArgsConstructor` annotation generates the
`@ConstructorProperties` annotation for you.

Register a constructor mapper for your mapped class using the `factory()` or `of()`
methods:

[source,java,indent=0]
----
include::{exampledir}/ResultsTest.java[tags=constructorMapper]
----

The constructor parameter names "id", "name" match the database column names
and as such no custom mapper code is required at all.

Constructor mappers can be configured with a column name prefix for each mapped
constructor parameter. This can help to disambiguate mapping joins, e.g. when
two mapped classes have identical property names (like `id` or `name`):

[source,java,indent=0]
----
handle.registerRowMapper(ConstructorMapper.factory(Contact.class, "c"));
handle.registerRowMapper(ConstructorMapper.factory(Phone.class, "p"));
handle.registerRowMapper(JoinRowMapper.forTypes(Contact.class, Phone.class);

List<JoinRow> contactPhones = handle.select("SELECT " +
    "c.id cid, c.name cname, " +
    "p.id pid, p.name pname, p.number pnumber " +
    "FROM contacts c LEFT JOIN phones p ON c.id = p.contact_id")
    .mapTo(JoinRow.class)
    .list();
----

Typically, the mapped class will have a single constructor. If it has multiple
constructors, Jdbi will pick one based on these rules:

- First, use the constructor annotated with `@JdbiConstructor`, if any.
- Next, use the constructor annotated with `@ConstructorProperties`, if any.
- Otherwise, throw an exception that Jdbi does not know which constructor to
  use.

For legacy column names that don't match up to property names, use the
link:{jdbidocs}/core/mapper/reflect/ColumnName.html[@ColumnName^] annotation to provide an exact column name.

[source,java,indent=0]
----
public User(@ColumnName("user_id") int id, String name) {
    this.id = id;
    this.name = name;
}
----

Nested constructor-injected types can be mapped using the link:{jdbidocs}/core/mapper/Nested.html[@Nested^] annotation:

[source,java,indent=0]
----
public class User {
    public User(int id,
                String name,
                @Nested Address address) {
        // ...
    }
}

public class Address {
    public Address(String street,
                   String city,
                   String state,
                   String zip) {
        // ...
    }
}
----

[source,java,indent=0]
----
handle.registerRowMapper(ConstructorMapper.factory(User.class));

List<User> users = handle
    .select("SELECT id, name, street, city, state, zip FROM users")
    .mapTo(User.class)
    .list();
----

The link:{jdbidocs}/core/mapper/Nested.html[@Nested^] annotation has an optional `value()` attribute, which can be used to apply a column name prefix to each nested constructor parameter:

[source,java,indent=0]
----
public User(int id,
            String name,
            @Nested("addr") Address address) {
    // ...
}
----

[source,java,indent=0]
----
handle.registerRowMapper(ConstructorMapper.factory(User.class));

List<User> users = handle
    .select("SELECT id, name, addr_street, addr_city, addr_state, addr_zip FROM users")
    .mapTo(User.class)
    .list();
----

By default, ConstructorMapper expects the result set to contain columns to map every constructor parameter, and will throw an exception if any parameters cannot be mapped.

Parameters annotated `@Nullable` (see <<Using `@Nullable` annotations>>) may be omitted from the result set, in which
`ConstructorMapper` will pass `null` to the constructor for that parameter.

[source,java,indent=0]
----
public class User {
    public User(int id,
                String name,
                @Nullable String passwordHash,
                @Nullable @Nested Address address) {
        // ...
    }
}
----

In this example, the `id` and `name` columns must be present in the result set, but `passwordHash` and `address` are optional.
If they are present, they will be mapped.

==== BeanMapper

link:{jdbidocs}/core/mapper/reflect/BeanMapper.html[BeanMapper^] assigns columns to bean properties. This mapper uses the standard Java Bean conventions.

[source,java,indent=0]
----
include::{exampledir}/UserBean.java[tags=beanMapper]
----

[NOTE]
The standard bean convention requires that the setter returns a `void` value. The popular "builder pattern" setter
convention of returning the bean itself does not work with the standard Java Bean convention and the setter will not be found. This is a common source of problems when using the `BeanMapper`.


Register a bean mapper for your mapped class, using the `factory()` method:

[source,java,indent=0]
----
include::{exampledir}/ResultsTest.java[tags=beanMapper]
----

Alternatively, call `mapToBean()` instead of registering a bean mapper:

[source,java,indent=0]
----
include::{exampledir}/ResultsTest.java[tags=mapToBean]
----

Or use `map` with an instance:

[source,java,indent=0]
----
include::{exampledir}/ResultsTest.java[tags=useMapper]
----

Bean mappers can be configured with a column name prefix for each mapped
property. This can help to disambiguate mapping joins, e.g. when two mapped
classes have identical property names (like `id` or `name`):

[source,java,indent=0]
----
include::{exampledir}/ResultsTest.java[tags=beanMapperPrefix]
----

For legacy column names that don't match up to property names, use the
link:{jdbidocs}/core/mapper/reflect/ColumnName.html[@ColumnName^] annotation to provide an exact column name.

[source,java,indent=0]
----
public class User {
    private int id;

    @ColumnName("user_id")
    public int getId() { return id; }

    public void setId(int id) { this.id = id; }
}
----

The link:{jdbidocs}/core/mapper/reflect/ColumnName.html[@ColumnName^] annotation can be placed on either the getter or setter method.
If conflicting annotations exist, then Annotations on the setter are preferred.

Nested Java Bean types can be mapped using the link:{jdbidocs}/core/mapper/Nested.html[@Nested^] annotation:

[source,java,indent=0]
----
public class User {
    private int id;
    private String name;
    private Address address;

    // ... (getters and setters)

    @Nested // <1>
    public Address getAddress() { ... }

    public void setAddress(Address address) { ... }
}

public class Address {
    private String street;
    private String city;
    private String state;
    private String zip;

    // ... (getters and setters)
}
----

<1> The link:{jdbidocs}/core/mapper/Nested.html[@Nested^] annotation can be placed on either the getter or setter method.
The setter is preferred.

[source,java,indent=0]
----
handle.registerRowMapper(BeanMapper.factory(User.class));

List<User> users = handle
    .select("SELECT id, name, street, city, state, zip FROM users")
    .mapTo(User.class)
    .list();
----

The link:{jdbidocs}/core/mapper/Nested.html[@Nested^] annotation has an optional `value()` attribute, which can be used to apply a column name prefix to each nested bean property:

[source,java,indent=0]
----
@Nested("addr")
public Address getAddress() { ... }
----

[source,java,indent=0]
----
handle.registerRowMapper(BeanMapper.factory(User.class));

List<User> users = handle
    .select("SELECT id, name, addr_street, addr_city, addr_state, addr_zip FROM users")
    .mapTo(User.class)
    .list();
----

[NOTE]
link:{jdbidocs}/core/mapper/Nested.html[@Nested^] properties are left unmodified (i.e. null) if the result set has no columns matching any properties of the nested object.

==== FieldMapper

link:{jdbidocs}/core/mapper/reflect/FieldMapper.html[FieldMapper^] uses reflection
to map database columns directly to object fields (including private fields).

[source,java,indent=0]
----
public class User {
    public int id;

    public String name;
}
----

Register a field mapper for your mapped class, using the `factory()` method:

[source,java,indent=0]
----
handle.registerRowMapper(FieldMapper.factory(User.class));

List<UserBean> users = handle
    .createQuery("SELECT id, name FROM user")
    .mapTo(User.class)
    .list();
----

Field mappers can be configured with a column name prefix for each mapped
field. This can help to disambiguate mapping joins, e.g. when two mapped
classes have identical property names (like `id` or `name`):

[source,java,indent=0]
----
handle.registerRowMapper(FieldMapper.factory(Contact.class, "c"));
handle.registerRowMapper(FieldMapper.factory(Phone.class, "p"));
handle.registerRowMapper(JoinRowMapper.forTypes(Contact.class, Phone.class);
List<JoinRow> contactPhones = handle.select(
    "SELECT " +
    "c.id cid, c.name cname, " +
    "p.id pid, p.name pname, p.number pnumber " +
    "FROM contacts c LEFT JOIN phones p ON c.id = p.contact_id")
    .mapTo(JoinRow.class)
    .list();
----

For legacy column names that don't match up to field names, use the
link:{jdbidocs}/core/mapper/reflect/ColumnName.html[@ColumnName^] annotation to provide an exact column name:

[source,java,indent=0]
----
public class User {
    @ColumnName("user_id")
    public int id;

    public String name;
}
----

Nested field-mapped types can be mapped using the link:{jdbidocs}/core/mapper/Nested.html[@Nested^] annotation:

[source,java,indent=0]
----
public class User {
    public int id;
    public String name;

    @Nested
    public Address address;
}

public class Address {
    public String street;
    public String city;
    public String state;
    public String zip;
}
----

[source,java,indent=0]
----
handle.registerRowMapper(FieldMapper.factory(User.class));

List<User> users = handle
    .select("SELECT id, name, street, city, state, zip FROM users")
    .mapTo(User.class)
    .list();
----

The link:{jdbidocs}/core/mapper/Nested.html[@Nested^] annotation has an optional `value()` attribute, which can be used to apply a column name prefix to each nested field:

[source,java,indent=0]
----
public class User {
    public int id;
    public String name;

    @Nested("addr")
    public Address address;
}
----

[source,java,indent=0]
----
handle.registerRowMapper(FieldMapper.factory(User.class));

List<User> users = handle
    .select("SELECT id, name, addr_street, addr_city, addr_state, addr_zip FROM users")
    .mapTo(User.class)
    .list();
----

[NOTE]
link:{jdbidocs}/core/mapper/Nested.html[@Nested^] fields are left unmodified (i.e. null) if the result set has no columns matching any fields of the nested object.

////
==== ReflectionMappers config class

TODO:

* strict matching
* column name matchers
* default column name matchers out of the box
////

[#mapentry-mapping]
=== Map.Entry Mapping

Out of the box, Jdbi registers a link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper<Map.Entry<K,V>>^]. Since each row in
the result set is a `Map.Entry<K,V>`, the entire result set can be easily
collected into a `Map<K,V>` (or Guava's `Multimap<K,V>`).

NOTE: A mapper must be registered for both the key and value type.

Join rows can be gathered into a map result by specifying the generic map
signature:

[source,java,indent=0]
----
include::{coreexampledir}/MapEntryMapperTest.java[tags=joinRow]
----

In the preceding example, the `User` mapper uses the "u" column name prefix, and
the `Phone` mapper uses "p". Since each mapper only reads columns with the
expected prefix, the respective `id` columns are unambiguous.

A unique index (e.g. by ID column) can be obtained by setting the key column
name:

[source,java,indent=0]
----
include::{coreexampledir}/MapEntryMapperTest.java[tags=uniqueIndex]
----

Set both the key and value column names to gather a two-column query into a map
result:

[source,java,indent=0]
----
include::{coreexampledir}/MapEntryMapperTest.java[tags=keyValue]
----

All the above examples assume a one-to-one key/value relationship. What if
there is a one-to-many relationship?

<<google-guava, Google Guava>> provides a `Multimap` type, which supports mapping multiple
values per key.

First, follow the instructions in the <<google-guava,Google Guava>> section to install the
link:{jdbidocs}/guava/GuavaPlugin.html[GuavaPlugin^] into Jdbi.

Then, simply ask for a `Multimap` instead of a link:{jdkdocs}/java.base/java/util/Map.html[Map^]:

[source,java,indent=0]
----
include::{guavaexampledir}/MultimapEntryMapperTest.java[tags=joinRow]
----

The `collectInto()` method is worth explaining. When you call it, several things
happen behind the scenes:

* Consult the link:{jdbidocs}/core/collector/JdbiCollectors.html[JdbiCollectors^] registry to obtain a
 link:{jdbidocs}/core/collector/CollectorFactory.html[CollectorFactory^] which
  supports the given container type.
* Next, ask that `CollectorFactory` to extract the element type from the
  container type signature. In the above example, the element type of
  `Multimap<User,Phone>` is `Map.Entry<User,Phone>`.
* Obtain a mapper for that element type from the mapping registry.
* Obtain a link:{jdkdocs}/java.base/java/util/stream/Collector.html[Collector^] for the
  container type from the `CollectorFactory`.
* Finally, return `map(elementMapper).collect(collector)`.

NOTE: If the lookup for the collector factory, element type, or element mapper
fails, an exception is thrown.

Jdbi can be enhanced to support arbitrary container types.
// See <<JdbiCollectors>> for more information.


== Codecs

A codec is a replacement for registering an argument and a column mapper for a type. It is responsible for serializing a typed value into a database column and creating a type from a database column.

Codecs are collected in a codec factory, which can be registered with the registerCodecFactory convenience method.

[source,java,indent=0]
----
// register a single codec
jdbi.registerCodecFactory(CodecFactory.forSingleCodec(type, codec));

// register a few codecs
jdbi.registerCodecFactory(CodecFactory.builder()
    // register a codec by qualified type
    .addCodec(QualifiedType.of(Foo.class), codec1)
    // register a codec by direct java type
    .addCodec(Foo.class, codec2)
    // register a codec by generic type
    .addCodec(new GenericType<Set<Foo>>() {}. codec3)
    .build());

// register many codecs
Map<QualifiedType<?>, Codec<?>> codecs = ...
jdbi.registerCodecFactory(new CodecFactory(codecs));
----


Codec example:

[source,java,indent=0]
----
include::{exampledir}/Counter.java[tags=counterCodec]
----

Jdbi core API:

[source,java,indent=0]
----
include::{exampledir}/CodecExampleTest.java[tags=register;load;store]
----

SQL Object API uses the codecs transparently:

[source,java,indent=0]
----
include::{exampledir}/CodecSqlObjectTest.java[tags=dao;register;load;store]
----


=== Resolving Types

By using the `TypeResolvingCodecFactory` from the link:{jdbidocs}/guava/package-summary.html[guava^] module, it is possible to use codecs that are registered for subclasses or interface types for concrete classes. This is necessary to e.g. map https://github.com/google/auto/blob/master/value/userguide/index.md[Auto Value^] generated classes to database columns.

In the following example, there is only a codec for `Value<String>` registered, but the code uses beans and classes that are concrete implementations (`StringBean` contains a `StringValue` and `StringValue` implements the `Value<String>` interface). The `TypeResolvingCodecFactory` will inspect the types to find a codec for an interface or superclass if no perfect match can be found.

[source,java,indent=0]
----
include::{exampledir}/TestInheritedValueH2.java[tags=dao;type;codec;value;bean]
----


== Results

A number of operations return data from the database through a JDBC link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^]:

* <<Queries, Query>> operations
* The link:{jdbidocs}/core/statement/Update.html#executeAndReturnGeneratedKeys(java.lang.String\...)[Update#executeAndReturnGeneratedKeys^] and link:{jdbidocs}/core/statement/PreparedBatch.html#executePreparedBatch(java.lang.String\...)[PreparedBatch#executeAndReturnGeneratedKeys^] methods
* <<Metadata>> operations

The JDBC link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] class can do simple mapping to Java primitives
and built in classes, but the API is often cumbersome to use.

Jdbi offers many ways to process and map these responses onto other objects using configurable mapping, including the ability to register custom mappers for rows  and columns.

A link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^] converts a row of a link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] into a result object.

A link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper^] converts a single column's value into a Java object. It can be
used as a link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^] if there is only one column present, or it can be used to
build more complex link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^] types.

The mapper is selected based on the declared result type of your query.

Jdbi iterates over the rows in the link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] and presents the mapped results
to you in a container such as a link:{jdkdocs}/java.base/java/util/List.html[List^], link:{jdkdocs}/java.base/java/util/stream/Stream.html[Stream^], link:{jdkdocs}/java.base/java/util/Optional.html[Optional^], or link:{jdkdocs}/java.base/java/util/Iterator.html[Iterator^].

[source,java,indent=0]
----
include::{exampledir}/ResultsTest.java[tags=headlineExample]
----

Jdbi operations that involve a link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] are defined and executed in multiple steps:

[source,java,indent=0]
----
List<User> users = handle.createQuery("SELECT * FROM users WHERE department = :department") // <1>
    .bind("department", departmentId) // <2>
    .mapTo(User.class) // <3>
    .list(); // <4>
----
<1> create a <<Statement types, Statement>> that implements link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^]
<2> execute methods on the statement in builder-style which return the same statement type
<3> execute a method defined by link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^] that returns a link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^]
<4> execute a terminal method on link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^] that returns the result

The link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^] and link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^] interfaces define all data mapping operations that Jdbi offer.


=== ResultBearing

The link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^] interface represents the result set of a database operation, which has not been mapped to any particular result type.

link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^] contains two major groups of operations:

* _latent_ operations that return a link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^]. These operations map the unmapped result of an operation to a specific type. They require a method on the link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^] to be called to execute the actual operation
* _terminal_ operations that collect, scan or reduce the result set. Calling one of these methods, executes the actual operation and returns a result.


==== Mapping result types with latent operations

These operations create a map from the data returned by the database onto java objects. This mapping is described in multiple ways:

* `map()` operations using a RowMapper, ColumnMapper or RowViewMapper instance.
* `mapTo()` operations using a type definition. The matching mapper is retrieved from the RowMappers registry. Supports link:{jdkdocs}/java.base/java/lang/reflect/Type.html[regular Java Types^], <<GenericType, Generic Types>> and <<Qualified Types>>.
* `mapToMap()` operations where the key is the (lower-cased) column name and the value is the column value. Supports link:{jdkdocs}/java.base/java/lang/reflect/Type.html[regular Java Types^], <<GenericType, Generic Types>> and <<Qualified Types>> for the values. The value mapper is retrieved from the RowMappers registry.
* `mapToBean()` maps to a mutable bean instance with that provides setters to set values. For each column name, the corresponding setter is called.

This is the most common use case when using the link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^] interface:

[source,java,indent=0]
----
ResultIterable<User> resultIterable = handle
    .createQuery("SELECT * from users")
    .mapTo(User.class);

List<User> users = resultIterable.list();
----

TODO:

* Describe terminal operations on the ResultBearing
* reduceRows
** RowView
* reduceResultSet
* collectInto e.g. with a GenericType token. Implies a mapTo() and a collect()
  in one operation. e.g. collectInto(new GenericType<List<User>>(){}) is the
  same as mapTo(User.class).collect(toList())
* Provide list of container types supported out of the box


=== ResultIterable

A link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^] represents a result set which has been mapped to a specific type, e.g. a `ResultIterable<User>`.

Almost all operations on the link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^] interface are _terminal_ operations. When they finish, they close and release all resources, especially the link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] and link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html[PreparedStatement^] objects.

See <<Statement resource management>> for more details on how resources are released and should be managed.

The  link:{jdbidocs}/core/result/ResultIterable.html#stream()[stream()^] and link:{jdbidocs}/core/result/ResultIterable.html#stream()#iterator()[iterator()^] operations are *not* terminal. They return objects that need to be managed by the caller. See the <<Resources with Streams and Iterators>> chapter for more details.



TODO:

* one(), list(), first(), findOne(), findFirst()
* mention filter, map as non-terminals
* collect, reduce
* callback consumers for iterator and stream
* ResultIterable.forEach, forEachWithCount


==== Finding a Single Result

`ResultIterable.one()` returns the only row in the result set. If zero or
multiple rows are encountered, it will throw `IllegalStateException`.

`ResultIterable.findOne()` returns an `Optional<T>` of the only row in the
result set, or link:{jdkdocs}/java.base/java/util/Optional.html#empty--[Optional.empty()^] if no rows are returned.

`ResultIterable.first()` returns the first row in the result set. If zero
rows are encountered, `IllegalStateException` is thrown.

`ResultIterable.findFirst()` returns an `Optional<T>` of the first row, if
any.


==== Stream

*Stream* integration allows you to use a link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^] to adapt a link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] into  the Java Streams framework. The stream will lazily fetch rows from the database as necessary.

The link:{jdbidocs}/core/result/ResultIterable.html#stream()[stream()^] method returns a link:{jdkdocs}/java.base/java/util/stream/Stream.html[Stream<T>^]. This is not a terminal operation and the stream must be closed to release any database resources held. See <<Resources with Streams and Iterators>> for more details.

The link:{jdbidocs}/core/result/ResultIterable.html#withStream(org.jdbi.v3.core.result.StreamCallback)[withStream()^] and link:{jdbidocs}/core/result/ResultIterable.htmll#useStream(org.jdbi.v3.core.result.StreamConsumer)[useStream()^] methods pass the Stream into a callback.

[source,java,indent=0]
----
handle.createQuery("SELECT id, name FROM user ORDER BY id ASC")
    .map(new UserMapper())
    .useStream(stream -> {
        Optional<String> first = stream
            .filter(u -> u.id > 2)
            .map(u -> u.name)
            .findFirst();
        assertThat(first).contains("Charlie");
    });
----

These methods handle closing the stream for the caller. The link:{jdbidocs}/core/result/ResultIterable.html#withStream(org.jdbi.v3.core.result.StreamCallback)[withStream()^] method allows passing a result back to the caller, link:{jdbidocs}/core/result/ResultIterable.htmll#useStream(org.jdbi.v3.core.result.StreamConsumer)[useStream()^] only executed the code in the callback.


==== List

*#list* emits a *List<T>*. This necessarily buffers all results in memory.

[source,java,indent=0]
----
List<User> users =
    handle.createQuery("SELECT id, name FROM user")
        .map(new UserMapper())
        .list();
----


==== Collectors

*#collect* takes a `Collector<T, ?, R>` that builds a resulting collection
*R<T>*. The *java.util.stream.Collectors* class has a number of interesting
*Collector* implementations to start with.

You can also write your own custom collectors.  For example, to accumulate
found rows into a *Map*:

[source,java,indent=0]
----
h.execute("INSERT INTO something (id, name) VALUES (1, 'Alice'), (2, 'Bob'), (3, 'Chuckles')");
Map<Integer, Something> users = h.createQuery("SELECT id, name FROM something")
    .mapTo(Something.class)
    .collect(Collector.of(HashMap::new, (accum, item) -> {
        accum.put(item.getId(), item);   // Each entry is added into an accumulator map
    }, (l, r) -> {
        l.putAll(r);                     // While jdbi does not process rows in parallel,
        return l;                        // the Collector contract encourages writing combiners
    }, Characteristics.IDENTITY_FINISH));
----


==== Reduction

*#reduce* provides a simplified *Stream#reduce*. Given an identity starting
value and a *BiFunction<U, T, U>* it will repeatedly combine *U* until only a
single remains, and then return that.

// TODO: example


==== ResultSetScanner

The *ResultSetScanner* interface accepts a lazily-provided link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^]
and produces the result Jdbi returns from statement execution.

Most of the above operations are implemented in terms of *ResultSetScanner*.
The Scanner has ownership of the link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] and may advance or seek it.

The return value ends up being the final result of statement execution.

Most users should prefer using the higher level result collectors described above,
but someone's gotta do the dirty work.


=== Joins

Joining multiple tables together is a very common database task. It is also
where the mismatch between the relational model and Java's object model starts
to rear its ugly head.

Here we present a couple of strategies for retrieving results from more
complicated rows.

Consider a contact list app as an example. The contact list contains any
number of contacts. Contacts have a name, and any number of phone numbers.
Phone numbers have a type (e.g. home, work) and a phone number:

[source,java,indent=0]
----
class Contact {
    Long id;
    String name;
    List<Phone> phones = new ArrayList<>();

    void addPhone(Phone phone) {
        phones.add(phone);
    }
}

class Phone {
    Long id;
    String type;
    String phone;
}
----

We've left out getters, setters, and access modifiers for brevity.

Since we'll be reusing the same queries, we'll define them as constants now:

----
static final String SELECT_ALL = "SELECT contacts.id c_id, name c_name, "
    + "phones.id p_id, type p_type, phones.phone p_phone "
    + "FROM contacts LEFT JOIN phones ON contacts.id = phones.contact_id "
    + "order by c_name, p_type ";

static final String SELECT_ONE = SELECT_ALL + "where phones.id = :id";
----

Note that we've given aliases (e.g. `c_id`, `p_id`) to distinguish columns of
the same name (`id`) from different tables.

Jdbi provides a few different APIs for dealing with joined data.


==== ResultBearing.reduceRows()

The
link:{jdbidocs}/core/result/ResultBearing.html#reduceRows-U-java.util.function.BiFunction-["ResultBearing.reduceRows(U, BiFunction)"^]
method accepts an accumulator seed value and a lambda function. For each row in
the result set, Jdbi calls the lambda with the current accumulator value and a
link:{jdbidocs}/core/result/RowView.html[RowView^] over the current row of the
result set. The value returned for each row becomes the input accumulator
passed in for the next row. After the last row has been processed,
`reducedRows()` returns the last value returned from the lambda.

[source,java,indent=0]
----
List<Contact> contacts = handle.createQuery(SELECT_ALL)
    .registerRowMapper(BeanMapper.factory(Contact.class, "c"))
    .registerRowMapper(BeanMapper.factory(Phone.class, "p")) // <1>
    .reduceRows(new LinkedHashMap<Long, Contact>(), // <2>
        (map, rowView) -> {
            Contact contact = map.computeIfAbsent( // <3>
                rowView.getColumn("c_id", Long.class),
                id -> rowView.getRow(Contact.class));

            if (rowView.getColumn("p_id", Long.class) != null) { // <4>
                contact.addPhone(rowView.getRow(Phone.class));
            }

            return map; // <5>
        })
    .values() // <6>
    .stream()
    .collect(toList()); // <7>
----

<1> Register row mappers for `Contact` and `Phone`. Note the `"c"` and `"p"`
    arguments used--these are column name prefixes. By registering mappers with
    prefixes, the `Contact` mapper will only map the `c_id` and `c_name`
    columns, whereas the `Phone` mapper will only map `p_id`, `p_type`, and
    `p_phone`.
<2> Use an empty link:{jdkdocs}/java.base/java/util/LinkedHashMap.html[LinkedHashMap^]
    as the accumulator seed, mapped by contact ID. `LinkedHashMap` is a good
    accumulator when selecting multiple master records, since it has fast
    storage and lookup while preserving insertion order (which helps honor
    `ORDER BY` clauses). If ordering is unimportant, a `HashMap` would also
    suffice.
<3> Load the `Contact` from the accumulator if we already have it; otherwise,
    initialize it through the `RowView`.
<4> If `p_id` column is not null, load the phone number from the current row
    and add it to the current contact.
<5> Return the input map (now sporting an additional contact and/or phone) as
    the accumulator for the next row.
<6> At this point, all rows have been read into memory, and we don't need the
    contact ID keys. So we call `Map.values()` to get a `Collection<Contact>`.
<7> Collect the contacts into a link:{jdkdocs}/java.base/java/util/List.html[List<Contact>^].

Alternatively, the
link:{jdbidocs}/core/result/ResultBearing.html#reduceRows-org.jdbi.v3.core.result.RowReducer-[ResultBearing.reduceRows(RowReducer)^]
variant accepts a link:{jdbidocs}/core/result/RowReducer.html[RowReducer^] and
returns a stream of reduced elements.

For simple master-detail joins, the
link:{jdbidocs}/core/result/ResultBearing.html#reduceRows-java.util.function.BiConsumer-[ResultBearing.reduceRows(BiConsumer<Map<K,V>,RowView>)^]
method makes it easy to reduce these joins into a stream of master elements.

Adapting the example above:

[source,java,indent=0]
----
List<Contact> contacts = handle.createQuery(SELECT_ALL)
    .registerRowMapper(BeanMapper.factory(Contact.class, "c"))
    .registerRowMapper(BeanMapper.factory(Phone.class, "p"))
    .reduceRows((Map<Long, Contact> map, RowView rowView) -> { // <1>
        Contact contact = map.computeIfAbsent(
            rowView.getColumn("c_id", Long.class),
            id -> rowView.getRow(Contact.class));

        if (rowView.getColumn("p_id", Long.class) != null) {
            contact.addPhone(rowView.getRow(Phone.class));
        }
        // <2>
    })
    .collect(toList()); // <3>
----

<1> The lambda receives a map where result objects will be stored, and a
    `RowView`. The map is a `LinkedHashMap`, so the result stream will
    yield the result objects in the same order they were inserted.
<2> No `return` statement needed. The same `map` is reused on every row.
<3> This `reduceRows()` invocation produces a `Stream<Contact>` (i.e. from
    `map.values().stream()`. In this example, we collect the elements into a
    list, but we could call any link:{jdkdocs}/java.base/java/util/stream/Stream.html[Stream^] method here.

You may be wondering about the `getRow()` and `getColumn()` calls to `rowView`.
When you call `rowView.getRow(SomeType.class)`, `RowView` looks up the
registered row mapper for `SomeType`, and uses it to map the current row to a
`SomeType` object.

Likewise, when you call `rowView.getColumn("my_value", MyValueType.class)`,
`RowView` looks up the registered column mapper for `MyValueType`, and uses it
to map the `my_value` column of the current row to a `MyValueType` object.

Now let's do the same thing, but for a single contact:

[source,java,indent=0]
----
Optional<Contact> contact = handle.createQuery(SELECT_ONE)
    .bind("id", contactId)
    .registerRowMapper(BeanMapper.factory(Contact.class, "c"))
    .registerRowMapper(BeanMapper.factory(Phone.class, "p"))
    .reduceRows(LinkedHashMapRowReducer.<Long, Contact> of((map, rowView) -> {
      Contact contact = map.orElseGet(() -> rowView.getRow(Contact.class));

      if (rowView.getColumn("p_id", Long.class) != null) {
        contact.addPhone(rowView.getRow(Phone.class));
      }
    })
    .findFirst();
----


==== ResultBearing.reduceResultSet()

link:{jdbidocs}/core/result/ResultBearing.html#reduceResultSet-U-org.jdbi.v3.core.result.ResultSetAccumulator-[ResultBearing.reduceResultSet()^]
is a low-level API similar to `reduceRows()`, except it provides direct access
to the JDBC link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] instead of a `RowView` for each row.

This method can provide superior performance compared to `reduceRows()`, at the
expense of verbosity:

[source,java,indent=0]
----
List<Contact> contacts = handle.createQuery(SELECT_ALL)
    .reduceResultSet(new LinkedHashMap<Long, Contact>(),
        (acc, resultSet, ctx) -> {
            long contactId = resultSet.getLong("c_id");
            Contact contact;
            if (acc.containsKey(contactId)) {
                contact = acc.get(contactId);
            } else {
                contact = new Contact();
                acc.put(contactId, contact);
                contact.setId(contactId);
                contact.setName(resultSet.getString("c_name"));
            }

            long phoneId = resultSet.getLong("p_id");
            if (!resultSet.wasNull()) {
                Phone phone = new Phone();
                phone.setId(phoneId);
                phone.setType(resultSet.getString("p_type"));
                phone.setPhone(resultSet.getString("p_phone"));
                contact.addPhone(phone);
            }

            return acc;
        })
    .values()
    .stream()
    .collect(toList());
----


==== JoinRowMapper

The JoinRowMapper takes a set of types to extract from each row. It uses the
mapping registry to determine how to map each given type, and presents you with
a JoinRow that holds all the resulting values.

Let's consider two simple types, User and Article, with a join table named
Author. Guava provides a Multimap class, which is very handy for representing
joined tables like this. Assuming we have mappers already registered:

[source,java,indent=0]
----
include::{coreexampledir}/JoinRowMapperTest.java[tags=mapperSetup]
----

we can then easily populate a Multimap with the mapping from the database:

[source,java,indent=0]
----
include::{coreexampledir}/JoinRowMapperTest.java[tags=multimap]
----

NOTE: While this approach is easy to read and write, it can be inefficient for
certain patterns of data. Consider performance requirements when deciding
whether to use high level mapping or more direct low level access with
handwritten mappers.

You can also use it with SqlObject:

[source,java,indent=0]
----
include::{sqlobjectexampledir}/TestRegisterJoinRowMapper.java[tags=joinrowdao]
----

[source,java,indent=0]
----
include::{sqlobjectexampledir}/TestRegisterJoinRowMapper.java[tags=joinrowusage]
----


== Transactions

Jdbi provides full support for JDBC transactions.


=== Managed Transactions

A managed transaction is controlled through Jdbi code and provides a handle with an open transaction to user code.

* The link:{jdbidocs}/core/Jdbi.html#inTransaction(org.jdbi.v3.core.HandleCallback)[inTransaction^] and link:{jdbidocs}/core/Jdbi.html#useTransaction(org.jdbi.v3.core.HandleConsumer)[useTransaction^] methods on the link:{jdbidocs}/core/Jdbi.html[Jdbi^] object create a new link:{jdbidocs}/core/Handle.html[Handle^], open a transaction and pass it to the callback code.
* The link:{jdbidocs}/core/Handle.html#inTransaction(org.jdbi.v3.core.HandleCallback)[inTransaction^] and link:{jdbidocs}/core/Handle.html#useTransaction(org.jdbi.v3.core.HandleConsumer)[useTransaction^] methods on link:{jdbidocs}/core/Handle.html[Handle^] objects open a transaction on the handle itself and then pass it to the callback code. By default, if these methods are called while the handle is already in an open transaction, the existing transaction is reused (no nested transaction is created).

Each of these methods also has a variant that allows setting the link:{jdbidocs}/core/transaction/TransactionIsolationLevel.html[transaction isolation level^]. Changing the transaction isolation level within an open transaction is not supported (and will cause an exception).

At the end of the callback, the transaction is committed, if

* the code has not thrown an exception
* it was not a nested call from another `useTransaction`/`inTransaction` callback. In that case, control is handed back to the original caller and the transaction finishes when that callback returns.
* the code did not call the link:{jdbidocs}/core/Handle.html#rollback()[rollback()^] method on the Handle object.

Executing a SQL operation in a transaction:
[source,java,indent=0]
----
include::{exampledir}/TransactionTest.java[tags=simpleTransaction]
----


=== Unmanaged Transactions

Jdbi provides the necessary primitives to control transactions directly from a Handle:

* the link:{jdbidocs}/core/Handle.html#begin()[begin()^]/link:{jdbidocs}/core/Handle.html#commit()[commit()^]/link:{jdbidocs}/core/Handle.html#rollback()[rollback()^] methods provide standard transaction semantics
* link:{jdbidocs}/core/Handle.html#setTransactionIsolationLevel(org.jdbi.v3.core.transaction.TransactionIsolationLevel)[setTransactionIsolationLevel()^] and link:{jdbidocs}/core/Handle.html#getTransactionIsolationLevel()[getTransactionIsolationLevel()^] to control the transaction isolation level
* link:{jdbidocs}/core/Handle.html#isInTransaction()[isInTransaction()^] returns `true` if the handle is currently in a transaction
* link:{jdbidocs}/core/Handle.html#savepoint(java.lang.String)[savepoint()^]/link:{jdbidocs}/core/Handle.html#releaseSavepoint(java.lang.String)[releaseSavepoint()^]/link:{jdbidocs}/core/Handle.html#rollbackToSavepoint(java.lang.String)[rollbackToSavepoint()^] for transaction savepoint support. This is not supported by all TransactionHandlers and requires support from the JDBC driver

Transactions are managed by link:{jdbidocs}/core/transaction/TransactionHandler.html[TransactionHandler^] implementations. By default, transactions are delegated to the JDBC connection and managed through the connection by the database.

The transaction handler can be set per link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance using the link:{jdbidocs}/core/Jdbi.html#setTransactionHandler(org.jdbi.v3.core.transaction.TransactionHandler)[setTransactionHandler^] and link:{jdbidocs}/core/Jdbi.html#getTransactionHandler()[getTransactionHandler^] methods.

In addition to the link:{jdbidocs}/core/transaction/LocalTransactionHandler.html[standard transaction handler^], Jdbi includes a link:{jdbidocs}/core/transaction/CMTTransactionHandler.html[handler that works correctly in a container managed environment^] and a link:{jdbidocs}/core/transaction/SerializableTransactionRunner.html[serializable transaction handler^] that allows multiple concurrent operations on a single handle to retry transparently.


=== Serializable Transactions

For more advanced queries, sometimes serializable transactions are required.

Jdbi includes a link:{jdbidocs}/core/transaction/SerializableTransactionRunner.html[transaction runner that is able to retry transactions^] that abort due to serialization failures.

[WARNING]
It is important that your transaction does not have side effects as it may be executed multiple times.

[source,java,indent=0]
----
include::{exampledir}/TransactionTest.java[tags=serializable]
----

The above test is designed to run two transactions in lock step. Each attempts to read the sum of all rows in the table, and then insert a new row with that sum. We seed the table with the values 10 and 20.

Without serializable isolation, each transaction reads 10 and 20, and then returns 30. The end result is 30 + 30 = 60, which does not correspond to any serial execution of the transactions!

With serializable isolation, one of the two transactions is forced to abort and retry. On the second go around, it calculates 10 + 20 + 30 = 60. Adding to 30 from the other, we get 30 + 60 = 90 and the assertion succeeds.


== Configuration

Jdbi aims to be useful out of the box with minimal configuration. If necessary,
there is a wide range of configurations and customizations available to change the
default behavior or add in extensions to handle additional database types.

Configuration is managed by the
link:{jdbidocs}/core/config/ConfigRegistry.html[ConfigRegistry^] class.
Each Jdbi object that represents a distinct database context (for
example, link:{jdbidocs}/core/Jdbi.html[Jdbi^] itself, a
link:{jdbidocs}/core/Handle.html[Handle^] instance, or an attached
link:{jdbidocs}/sqlobject/SqlObject.html[SqlObject^] class) has a
separate config registry instance.

When a new context is created, it inherits a copy of its parent
configuration at the time of creation - further modifications to the
original will not affect already created configuration contexts.
Configuration context copies happen when creating a
link:{jdbidocs}/core/Handle.html[Handle^] from
link:{jdbidocs}/core/Jdbi.html[Jdbi^], when opening a
link:{jdbidocs}/core/statement/SqlStatement.html[SqlStatement^] from
the Handle, and when attaching or creating an on-demand extension such
as link:{jdbidocs}/sqlobject/SqlObject.html[SqlObject^].

A configurable Jdbi object implements the
link:{jdbidocs}/core/config/Configurable.html[Configurable^] interface
which allows modification of its configuration as well as retrieving
the current context's configuration for use by Jdbi core or
extensions.

[source,java,indent=0]
----

// fetch the config registry object
ConfigRegistry config = jdbi.getConfig();

// access the SqlStatements configuration object:
SqlStatements sqlStatements = jdbi.getConfig(SqlStatements.class);

// modify a setting in SqlStatements with a callback
jdbi.configure(SqlStatements.class, s -> s.setUnusedBindingAllowed(true));

// modify a setting in SqlStatements with direct method invocation
jdbi.getConfig(SqlStatements.class).setUnusedBindingAllowed(true);
----

The link:{jdbidocs}/core/config/Configurable.html[Configurable^]
interface also adds a number of convenience methods for commonly used
configuration objects.


See <<JdbiConfig>> for more advanced implementation details.


=== core settings

[%header, cols="<2, <2, ^1, ^1, <5a", stripe=none]
|===
| Object | Property | Type | Default | Description

.3+| link:{jdbidocs}/core/argument/Arguments.html[Arguments^] | bindingNullToPrimitivesPermitted
     | boolean  | `true`
     | Allows binding `null` values for primitive types.

| preparedArgumentsEnabled
   ^| boolean  ^| `true`
    <| PreparedArguments speed up argument processing but have some backwards compatibility risk with old (pre-3.24.0) releases.

<| untypedNullArgument
   ^| link:{jdbidocs}/core/argument/Argument.html[Argument^] ^| link:{jdbidocs}/core/argument/NullArgument.html[NullArgument^] using link:{jdkdocs}/java.sql/java/sql/Types.html#OTHER[Types.OTHER^].
    <| This argument instance is invoked when a `null` value is assigned to an argument whose type is unknown (this can happen in some corner cases).

| link:{jdbidocs}/core/mapper/ColumnMappers.html[ColumnMappers^] | coalesceNullPrimitivesToDefaults
    | boolean  | `true`
    | Uses the JDBC default value for primitive types if a SQL NULL value was returned by the database.

| link:{jdbidocs}/core/enums/Enums.html[Enums^] | enumStrategy
    | link:{jdbidocs}/core/enums/EnumStrategy.html[EnumStrategy^] | `BY_NAME`
    | Sets the strategy to map a Java enum value onto a database column. Available strategies are

[cols="1,3"]
!===
! link:{jdbidocs}/core/enums/EnumStrategy.html#BY_NAME[BY_NAME^] ! map the name of the enum from and to the database column
! link:{jdbidocs}/core/enums/EnumStrategy.html#BY_ORDINAL[BY_ORDINAL^] ! map the ordinal number of the enum value from and to the database column
!===

.2+| link:{jdbidocs}/core/extension/Extensions.html[Extensions^] | allowProxy
    | boolean  | `true`
    | Whether Jdbi is allowed to create link:{jdkdocs}/java.base/java/lang/reflect/Proxy.html[proxy ^] instances for classes (as extension and on-demand reference). This is useful for debugging when using the generator to create java classes for sql objects.

| failFast
^| boolean  ^| `false`
<| If set to `true`, extension objects with misconfigured methods will fail at first use of any method. Default is to fail when a misconfigured method is used.

| link:{jdbidocs}/core/Handles.html[Handles^] | forceEndTransactions
    | boolean  | `true`
    | Whether to ensure transaction discipline. If `true`, transactions *must* be committed or rolled back before a Handle is closed. If `true`, any uncommitted
transaction is rolled back and an exception is thrown when the Handle is closed.


| link:{jdbidocs}/core/mapper/MapMappers.html[MapMappers^] | caseChange
    | link:{jdkdocs}/java.base/java/util/function/UnaryOperator.html[UnaryOperator<String>^] | link:{jdbidocs}/core/mapper/CaseStrategy.html#LOCALE_LOWER[LOCALE_LOWER^]
    | Defines the strategy for mapping the database column names to key names. Available strategies are:

[cols="1,3"]
!===
! link:{jdbidocs}/core/mapper/CaseStrategy.html#NOP[NOP^] ! no name mapping, use name as is
! link:{jdbidocs}/core/mapper/CaseStrategy.html#LOWER[LOWER^] ! lowercase column names using the `ROOT` locale
! link:{jdbidocs}/core/mapper/CaseStrategy.html#UPPER[UPPER^] ! uppercase column names using the `ROOT` locale
! link:{jdbidocs}/core/mapper/CaseStrategy.html#LOCALE_LOWER[LOCALE_LOWER^] ! lowercase column names using the current locale
! link:{jdbidocs}/core/mapper/CaseStrategy.html#LOCALE_UPPER[LOCALE_UPPER^] ! uppercase column names using the current locale
!===

Custom strategies can be set by implementing link:{jdkdocs}/java.base/java/util/function/UnaryOperator.html[UnaryOperator<String>^] with custom code.


.2+| link:{jdbidocs}/core/mapper/reflect/ReflectionMappers.html[ReflectionMappers^] | caseChange
    | link:{jdkdocs}/java.base/java/util/function/UnaryOperator.html[UnaryOperator<String>^] | link:{jdbidocs}/core/mapper/CaseStrategy.html#LOCALE_LOWER[LOCALE_LOWER^]
    | Defines the strategy for mapping the database column names to key names. Available strategies are:

[cols="1,3"]
!===
! link:{jdbidocs}/core/mapper/CaseStrategy.html#NOP[NOP^] ! no name mapping, use name as is
! link:{jdbidocs}/core/mapper/CaseStrategy.html#LOWER[LOWER^] ! lowercase column names using the `ROOT` locale
! link:{jdbidocs}/core/mapper/CaseStrategy.html#UPPER[UPPER^] ! uppercase column names using the `ROOT` locale
! link:{jdbidocs}/core/mapper/CaseStrategy.html#LOCALE_LOWER[LOCALE_LOWER^] ! lowercase column names using the current locale
! link:{jdbidocs}/core/mapper/CaseStrategy.html#LOCALE_UPPER[LOCALE_UPPER^] ! uppercase column names using the current locale
!===

Custom strategies can be set by implementing link:{jdkdocs}/java.base/java/util/function/UnaryOperator.html[UnaryOperator<String>^] with custom code.

| strictMatching
    ^| boolean ^| `false`
    <| If `true`, all database columns must be mapped to a property. If any columns are unmatched or any property is unset, an exception is thrown.

| link:{jdbidocs}/core/result/ResultProducers.html[ResultProducers^] | allowNoResults
    ^| boolean ^| `false`
    <| If `false`, Jdbi throws an exception if a query does not return a result set object (this is *different* from an empty result, e.g. no rows in a query). When setting this to `true`, Jdbi uses an empty result set instead.

.4+| link:{jdbidocs}/core/transaction/SerializableTransactionRunner.Configuration.html[SerializableTransactionRunner.Configuration^] | maxRetries
    | int | `5`
    | number of times a transaction is retried if the database reports a serialization error.

| onFailure
    ^| link:{jdkdocs}/java.base/java/util/function/Consumer.html[Consumer<List<Exception>>^] ^| <unset>
    <| Is called whenever a serialization failure occurs. Can be used e.g. for logging.

| onSuccess
    ^| link:{jdkdocs}/java.base/java/util/function/Consumer.html[Consumer<List<Exception>>^] ^| <unset>
    <| Is called once a transaction successfully finishes with any exception that has happened during the transaction execution.

| serializationFailureSqlState
    ^| String ^| `40001`
    <| SQL state value from a `SQLException` that is considered a serialization failure. This is defined in the SQL:2011 standard as `40001` but can be different depending on the database.

| link:{jdbidocs}/core/array/SqlArrayTypes.html[SqlArrayTypes^] | argumentStrategy
| link:{jdbidocs}/core/array/SqlArrayArgumentStrategy.html[SqlArrayArgumentStrategy^] | link:{jdbidocs}/core/array/SqlArrayArgumentStrategy.html#SQL_ARRAY[SQL_ARRAY^]
| Sets the strategy on how to bind arrays in the database driver.

[cols="1,3"]
!===
! link:{jdbidocs}/core/array/SqlArrayArgumentStrategy.html#SQL_ARRAY[SQL_ARRAY^]       ! create a SQL array using link:{jdkdocs}/java.sql/java/sql/Connection.html#createArrayOf-java.lang.String-java.lang.Object:A-[Connection#createArrayOf^] and call link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html#setArray-int-java.sql.Array-[PreparedStatement#setArray^]. This is the default and any modern JDBC driver should support it.
! link:{jdbidocs}/core/array/SqlArrayArgumentStrategy.html#OBJECT_ARRAY[OBJECT_ARRAY^] ! call link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html#setObject-int-java.lang.Object-[PreparedStatement#setObject^] and assume that the driver can handle this.
!===

.8+| link:{jdbidocs}/core/statement/SqlStatements.html[SqlStatements^]     | attachAllStatementsForCleanup
    | boolean | `false`
    | Jdbi supports automatic resource management by attaching statements to their handle so that closing the handle will free up all its resources.
If this setting is `true`, then statements are attached by default.

| attachCallbackStatementsForCleanup
^| boolean ^| `true`
<| Similar to `attachAllStatementsForCleanup` but for statements created in any of the Jdbi callback methods (link:{jdbidocs}/core/Jdbi.html#withHandle(org.jdbi.v3.core.HandleCallback)[withHandle^], link:{jdbidocs}/core/Jdbi.html#useHandle(org.jdbi.v3.core.HandleConsumer)[useHandle^], link:{jdbidocs}/core/Jdbi.html#inTransaction(org.jdbi.v3.core.HandleCallback)[inTransaction^], link:{jdbidocs}/core/Jdbi.html#useTransaction(org.jdbi.v3.core.HandleConsumer)[useTransaction^]).


| queryTimeout
^| Integer ^| <unset>
<| Sets the query timeout value in seconds. This value is used to call link:{jdkdocs}/java.sql/java/sql/Statement.html#setQueryTimeout-int-[Statement#setQueryTimeout^]. Enforcement of the timeout depends on the JDBC driver.


| scriptStatementsNeedSemicolon
^| boolean ^| `true`
<| Controls whether the statements parsed in a link:{jdbidocs}/core/statements/Script.html[Script^] object have trailing semicolons or not. This fixes some issues with specific JDBC drivers (e.g. MySQL when using `rewriteBatchedStatements=true`).


<| sqlParser
^| link:{jdbidocs}/core/statement/SqlParser.html[SqlParser^] ^| link:{jdbidocs}/core/statement/ColonPrefixSqlParser.html[ColonPrefixSqlParser^]
<a| The parser used to find the placeholders to bind arguments to.

Jdbi currently provides the following parsers:

[cols="1,3"]
!===
! link:{jdbidocs}/core/statement/ColonPrefixSqlParser.html[ColonPrefixSqlParser^] ! the default parser for `:name` placeholders.
! link:{jdbidocs}/core/statement/HashPrefixSqlParser.html[HashPrefixSqlParser^] ! use `#name` placeholders
!===

Custom implementations must implement link:{jdbidocs}/core/statement/SqlParser.html[SqlParser^] and may extend link:{jdbidocs}/core/statement/CachingSqlParser.html[CachingSqlParser^] to benefit from caching.

| sqlLogger
^| link:{jdbidocs}/core/statement/SqlLogger.html[SqlLogger^] ^| <unset>
<| Controls logging around statement execution. A SqlLogger instance receives the statement context before and after query execution and the context and an exception in case of an execution problem.

Jdbi provides link:{jdbidocs}/core/statement/Slf4jSqlLogger.html[Slf4jSqlLogger^] for the popular https://slf4j.org/[slf4j^] logging framework.

| templateEngine
^| link:{jdbidocs}/core/statement/TemplateEngine.html[TemplateEngine^] ^| link:{jdbidocs}/core/statement/DefinedAttributeTemplateEngine.html[DefineAttributeTemplateEngine^]
<a| The template engine to render SQL statements and substitute placeholders with values that have been defined on a statement (This is for *defined* attributes, not *bound* attributes!).

[cols="1,1,3"]
!===
! jdbi core ! link:{jdbidocs}/core/statement/DefinedAttributeTemplateEngine.html[DefineAttributeTemplateEngine^] ! the default engine, replaces angle-bracket placeholders (`<name>`).
! jdbi core ! link:{jdbidocs}/core/statement/NoTemplateEngine.html[NoTemplateEngine^] ! Ignore all defined values, do not do any substitutions.
! jdbi commons-text ! link:{jdbidocs}/commonstext/StringSubstitutorTemplateEngine.html[StringSubstitutorTemplateEngine^] ! use the https://commons.apache.org/proper/commons-text/[Apache Commons Text^] `StringSubstitutor` class
! jdbi freemarker ! link:{jdbidocs}/freemarker/FreemarkerEngine.html[FreemarkerEngine^] ! use https://freemarker.apache.org[Apache Freemarker^].
! jdbi stringtemplate4 ! link:{jdbidocs}/stringtemplate4/StringTemplateEngine.html[StringTemplateEngine^] ! use https://www.stringtemplate.org/[StringTemplate 4^].
!===

Custom implementations must implement link:{jdbidocs}/core/statement/TemplateEngine.html[TemplateEngine^].


| unusedBindingsAllowed
^| boolean ^| `false`
<| All bindings to a SQL operation must be used or an exception is thrown. If this setting is `true`, then unused bindings in a SQL operation are
ignored.

.2+| link:{jdbidocs}/core/statement/StatementExceptions.html[StatementExceptions^] | lengthLimit
    | int | `1024`
    | Controls the maximum length for variable length strings when they are rendered using the `SHORT_STATEMENT` message rendering strategy.

| messageRendering
    ^| link:{jdbidocs}/core/statement/StatementExceptions.MessageRendering.html[MessageRendering^] ^| link:{jdbidocs}/core/statement/StatementExceptions.MessageRendering.html#SHORT_STATEMENT[SHORT_STATEMENT^]
    <a| Sets the message rendering strategy when fetching the message from a link:{jdbidocs}/core/statement/StatementException.html[StatementException^] and its subclasses.

Controls how error messages from a Statement are displayed (e.g. for logging).

[cols="1,3"]
!===
! link:{jdbidocs}/core/statement/StatementExceptions.MessageRendering.html#NONE[NONE^] ! only render the statement exception message itself, do not add any information.
! link:{jdbidocs}/core/statement/StatementExceptions.MessageRendering.html#PARAMETERS[PARAMETERS^] ! include exception message and the bound parameters
! link:{jdbidocs}/core/statement/StatementExceptions.MessageRendering.html#SHORT_STATEMENT[SHORT_STATEMENT^] ! include exception message, SQL statement and the bound parameters. Truncate the SQL statement and the list of parameters each to the value of `lengthLimit`
! link:{jdbidocs}/core/statement/StatementExceptions.MessageRendering.html#DETAIL[DETAIL^] ! include exception message, unrendered SQL statement, rendered SQL statement, parsed SQL statement and binding parameters.
!===

|===

=== SQLObject configuration settings

[%header, cols="<2, <2, ^1, ^1, <5a", stripe=none]
|===
| Object | Property | Type | Default | Description

| link:{jdbidocs}/sqlobject/SqlObjects.html[SqlObjects^] | sqlLocator
     | link:{jdbidocs}/sqlobject/SqlLocator.html[SqlLocator^] | link:{jdbidocs}/sqlobject/AnnotationSqlLocator.html[AnnotationSqlLocator^]
     | Sets the locator for finding SQL statements. Default is to look for SQL operation annotations.

Jdbi provides two implementations of the `SqlLocator` interface:

[cols="1,3"]
!===
! link:{jdbidocs}/sqlobject/AnnotationSqlLocator.html[AnnotationSqlLocator^] ! Use annotations (
link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^],
link:{jdbidocs}/sqlobject/statement/SqlCall.html[@SqlCall^],
link:{jdbidocs}/sqlobject/statement/SqlQuery.html[@SqlQuery^],
link:{jdbidocs}/sqlobject/statement/SqlUpdate.html[@SqlUpdate^] and
link:{jdbidocs}/sqlobject/statement/SqlScript.html[@SqlScript^]) to locate SQL statements
! link:{jdbidocs}/sqlobject/SqlObjectClasspathSqlLocator.html[SqlObjectClasspathSqlLocator^] ! Associates a class or interface with a file located on the classpath (`com.foo.Bar#query()` becomes `com/foo/Bar/query.sql`) and loads the SQL from that file. The file may contain comments which are stripped.
!===

| link:{jdbidocs}/sqlobject/customizer/TimestampedConfig.html[TimestampedConfig^] | timezone
     | link:{jdkdocs}/java.base/java/time/ZoneId.html[ZoneId^] | system zone id
     | Sets the timezone for the link:{jdbidocs}/sqlobject/customizer/Timestamped.html[@Timestamped^] annotation.

|===


=== other configuration settings

[%header, cols="<2, <2, ^1, ^1, <5a", stripe=none]
|===
| Object | Property | Type | Default | Description

| link:{jdbidocs}/json/JsonConfig.html[JsonConfig^] | jsonMapper
     | link:{jdbidocs}/json/JsonMapper.html[JsonMapper^] | see description
     | Sets the JSON implementation used to serialize and deserialize json columns. Needs to be set when using the generic Json serialization/deserialization mapper. When installing the `jdbi3-gson2`, `jdbi3-jackson2` or `jdbi3-moshi` plugin, this is automatically set to the provided implementation.

If none of these modules is loaded, it defaults to an implementation that throws an exception whenever serialization or deserialization is attempted.

| link:{jdbidocs}/gson2/Gson2Config.html[Gson2Config^] | gson
     | https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html[Gson^] | A `Gson` instance created with the default constructor.
     | Sets the Gson object used to parse and render json text.

.4+| link:{jdbidocs}/jackson2/Jackson2Config.html[Jackson2Config^] | mapper
     | https://javadoc.io/static/com.fasterxml.jackson.core/jackson-databind/2.10.5.1/com/fasterxml/jackson/databind/ObjectMapper.html[ObjectMapper^] | An `ObjectMapper` instance created with the default constructor.
     | Sets the object mapper instance used to parse and render json text.
| deserializationView
     ^| link:{jdkdocs}/java.base/java/lang/Class.html[Class<?>^] ^| <unset>
     <a| Sets a view (see https://javadoc.io/static/com.fasterxml.jackson.core/jackson-annotations/2.10.5/com/fasterxml/jackson/annotation/JsonView.html[@JsonView^]) for deserialization. Can be used to limit the values read when mapping a json column.
| serializationView
     ^| link:{jdkdocs}/java.base/java/lang/Class.html[Class<?>^] ^| <unset>
     <a| Sets a view (see https://javadoc.io/static/com.fasterxml.jackson.core/jackson-annotations/2.10.5/com/fasterxml/jackson/annotation/JsonView.html[@JsonView^]) for serialization. Can be used to limit the values written when using a json argument.
| view
     ^| link:{jdkdocs}/java.base/java/lang/Class.html[Class<?>^] ^| <unset>
     <a| Sets a view (see https://javadoc.io/static/com.fasterxml.jackson.core/jackson-annotations/2.10.5/com/fasterxml/jackson/annotation/JsonView.html[@JsonView^]) for serialization and deserialization. Can be used to limit the values read and written by json arguments and mappers.

| link:{jdbidocs}/moshi/MoshiConfig.html[MoshiConfig^] | moshi
     | https://javadoc.io/doc/com.squareup.moshi/moshi/latest/moshi/com.squareup.moshi/-moshi/index.html[Moshi^] | A `Moshi` instance created with the default constructor.
     | Sets the Moshi instance used to parse and render json text.

| link:{jdbidocs}/freemarker/FreemarkerConfig.html[FreemarkerConfig^] | freemarkerConfiguration
     | https://javadoc.io/static/org.freemarker/freemarker/2.3.32/freemarker/template/Configuration.html[Configuration^] | The default configuration object.
     | Sets the freemarker configuration object for the template engine. See the https://freemarker.apache.org[freemarker documentation^] for details.
The default configuration has the following modifications for Jdbi:


- uses `Configuration.DEFAULT_INCOMPATIBLE_IMPROVEMENTS`
- configures a class template loader that loads templates from the root of the class path.
- the number format is set to `computer`.

| link:{jdbidocs}/stringtemplate4/StringTemplates.html[StringTemplates^] | failOnMissingAttribute
     | boolean | `false`
     | If `true`, fail rendering a template if a referenced attribute is missing.

|===


== SQL Arrays

Jdbi can bind/map Java arrays to/from SQL arrays:

[source,java,indent=0]
----
handle.createUpdate("INSERT INTO groups (id, user_ids) VALUES (:id, :userIds)")
    .bind("id", 1)
    .bind("userIds", new int[] {10, 5, 70})
    .execute();

int[] userIds = handle.createQuery("SELECT user_ids FROM groups WHERE id = :id")
    .bind("id", 1)
    .mapTo(int[].class)
    .one();
----

You can also use Collections in place of arrays, but you'll need to provide
the element type if you're using the fluent API, since it's erased:

[source,java,indent=0]
----
handle.createUpdate("INSERT INTO groups (id, user_ids) VALUES (:id, :userIds)")
    .bind("id", 1)
    .bindArray("userIds", int.class, Arrays.asList(10, 5, 70))
    .execute();

List<Integer> userIds = handle.createQuery("SELECT user_ids FROM groups WHERE id = :id")
    .bind("id", 1)
    .mapTo(new GenericType<List<Integer>>() {})
    .one();
----

Use link:{jdbidocs}/sqlobject/SingleValue.html[@SingleValue^] for mapping an array result with the SqlObject API:

[source,java,indent=0]
----
public interface GroupsDao {
    @SqlQuery("SELECT user_ids FROM groups WHERE id = ?")
    @SingleValue
    List<Integer> getUserIds(int groupId);
}
----


=== Registering array types

Any Java array element type you want binding support for needs to be registered
with Jdbi's `SqlArrayTypes` registry. An array type that is directly supported
by your JDBC driver can be registered using:

[source,java,indent=0]
----
jdbi.registerArrayType(int.class, "integer");
----

Here, `"integer"` is the SQL type name that the JDBC driver supports natively.

[NOTE]
Plugins like `PostgresPlugin` and `H2DatabasePlugin` automatically
register the most common array element types for their respective databases.

[TIP]
Postgres supports enum array types, so you can register an array type for
`enum Colors { red, blue }` using `jdbi.registerArrayType(Colors.class, "colors")`
where `"colors"` is a user-defined enum type name in your database.


=== Binding custom array types

You can also provide your own implementation of `SqlArrayType` that converts
a custom Java element type to a type supported by the JDBC driver:

[source,java,indent=0]
----
class UserArrayType implements SqlArrayType<User> {

    @Override
    public String getTypeName() {
        return "integer";
    }

    @Override
    public Object convertArrayElement(User user) {
        return user.getId();
    }
}
----

You can now bind instances of `User[]` to arguments of data type `integer[]`:

[source,java,indent=0]
----
User user1 = new User(1, "bob");
User user2 = new User(42, "alice");

handle.registerArrayType(new UserArrayType());
handle.createUpdate("INSERT INTO groups (id, user_ids) VALUES (:id, :users)")
    .bind("id", 1)
    .bind("users", new User[] {user1, user2})
    .execute();
----

[NOTE]
Like the <<The Arguments Registry, Arguments Registry>>, if there are multiple `SqlArrayType` s
registered for the same data type, the last registered wins.


=== Mapping array types

`SqlArrayType` only allows you to bind Java array/collection arguments to their
SQL counterparts. To map SQL array columns back to Java types, you can register
a regular link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper^]:

[source,java,indent=0]
----
public class UserIdColumnMapper implements ColumnMapper<UserId> {
    @Override
    public UserId map(ResultSet rs, int col, StatementContext ctx) throws SQLException {
        return new UserId(rs.getInt(col));
    }
}
----

[source,java,indent=0]
----
handle.registerColumnMapper(new UserIdColumnMapper());
List<UserId> userIds = handle.createQuery("SELECT user_ids FROM groups WHERE id = :id")
    .bind("id", 1)
    .mapTo(new GenericType<List<UserId>>() {})
    .one();
----

[NOTE]
Array columns can be mapped to any container type registered with the
link:{jdbidocs}/core/collector/JdbiCollectors.html[JdbiCollectors^] registry. E.g. a `VARCHAR[]` may be mapped to an
`ImmutableList<String>` if the Guava plugin is installed.

[#sql-objects]
== SQL Objects

SQL Objects are a declarative-style extension to the fluent-style, programmatic Core APIs. SQL Objects are implemented as an extension to the core API using the
<<extension-framework,Extension framework>>.

To start using the SQL Object plugin, add a dependency to your project:

For Apache Maven:

[source,xml,indent=0,subs="attributes,specialchars"]
----
<dependencies>
    <dependency>
        <groupId>org.jdbi</groupId>
        <artifactId>jdbi3-sqlobject</artifactId>
        <version>{project_version}</version>
    </dependency>
</dependencies>
----

For Gradle:

[source,groovy,subs="attributes,specialchars"]
----
dependencies {
    implementation("org.jdbi:jdbi3-sqlobject:{project_version}")
}
----

Then install the plugin into the link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance:

[source,java,indent=0]
----
Jdbi jdbi = ...
jdbi.installPlugin(new SqlObjectPlugin());
----

With SQL Object, you declare a public interface class as a SQL Object extension type, add methods for database operations, and specify what SQL statement to
execute.

You can specify what each method does in one of two ways:

* Annotate the method with a SQL method annotation. Jdbi provides a number of these
  annotations out of the box.
* Use Java _interface default methods_, and provide your own implementation in the method body.

At runtime, you can request an instance of your interface, and Jdbi synthesizes
an implementation based on the annotations and methods you declared.


=== SQL Method annotations

Interface methods can be annotated with one of Jdbi's SQL method annotations:

* link:{jdbidocs}/sqlobject/statement/SqlQuery.html[@SqlQuery^] - select operations that return data
* link:{jdbidocs}/sqlobject/statement/SqlUpdate.html[@SqlUpdate^] - insert, update, delete etc. operations that modify data
* link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^] - bulk operations
* link:{jdbidocs}/sqlobject/statement/SqlCall.html[@SqlCall^] - call stored procedures
* link:{jdbidocs}/sqlobject/statement/SqlScript.html[@SqlScript^] - execute multiple statements as a script


As with any extension type, parameters to the method are used as arguments. For the SQL Object extension, the arguments are passed to the statement, and the SQL statement result is mapped to the method return type.

SQL Object provides data mapping onto return types, argument mapping and mapper annotations to allow fully declarative definition of SQL queries.


==== @SqlQuery

Use the link:{jdbidocs}/sqlobject/statement/SqlQuery.html[@SqlQuery^] annotation for select operations. Each operation may return one or more rows which are mapped onto a return type by the SQL Object extension.

This is an example for a simple query:

[source,java,indent=0]
----
@SqlQuery("SELECT id, name FROM users") // <1>
List<User> retrieveUsers(); // <2>
----

<1> defines the SQL query that gets executed
<2> The method can return any type. The SQL Object framework will map the response from the SQL query onto this data type.

The SQL Object plugin uses the same configuration as the Jdbi core framework. Row and column mappers need to be registered to map to the correct types. This can be done through configuration or by using <<sqlobject-mapper-annotations, Mapper annotations>>.


==== @SqlUpdate

Use the link:{jdbidocs}/sqlobject/statement/SqlUpdate.html[@SqlUpdate^] annotation for operations that modify data (i.e. inserts, updates, deletes).

This is an example that uses link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html[PreparedStatement^] placeholders (`?`) for arguments:

[source,java,indent=0]
----
public interface UserDao {
    @SqlUpdate("INSERT INTO users (id, name) VALUES (?, ?)") // <1>
    void insert(long id, String name); // <2>
}
----

<1> Method arguments are bound to the `?` token in the SQL statement at their respective positions.

<2> `id` is bound to the first placeholder (`?`), and `name` to the second placeholder.

[TIP]
link:{jdbidocs}/sqlobject/statement/SqlUpdate.html[@SqlUpdate^] can also be used for DDL (Data Definition Language) operations like creating or altering tables. However, we recommend using a schema migration tool such
as https://flywaydb.org/[Flyway^] or https://www.liquibase.org/[Liquibase^] to maintain your database schemas.

By default, a link:{jdbidocs}/sqlobject/statement/SqlUpdate.html[@SqlUpdate^] method may declare one of these return types:

* `void` - no return value
* `int` or `long` - returns the update count. Depending on the database vendor and JDBC driver, this may be either the number of rows changed, or the number
  matched by the query (regardless of whether any data was changed).
* `boolean` - returns true if the update count is greater than zero.


Some databases also support returning additional values. See the <<sqlupdate-getgeneratedkeys,@GetGeneratedKeys>> annotation for more details.


==== @SqlBatch

Use the link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^] annotation for bulk update operations. It works similar to the <<Prepared Batches,PreparedBatch>> operation in the Jdbi core.

[source,java,indent=0]
----
public interface ContactDao {
    @SqlBatch("INSERT INTO contacts (id, name, email) VALUES (?, ?, ?)")
    void bulkInsert(List<Integer> ids,  // <1>
                    Iterator<String> names, // <2>
                    String... emails); // <3>
}
----

<1> a collection argument for the batch operation
<2> an iterable argument for the batch operation
<3> a varargs argument for the batch operation

When a batch method is called, it iterates through the method's iterable parameters (collections, iterables, varargs etc.), and executes the SQL statement with the corresponding elements from each parameter.

Thus, a statement like:

[source,java,indent=0]
----
contactDao.bulkInsert(
    ImmutableList.of(1, 2, 3),
    ImmutableList.of("foo", "bar", "baz").iterator(),
    "a@example.com", "b@example.com", "c@fake.com");
----

would execute:

[source,sql]
----
INSERT INTO contacts (id, name, email) VALUES (1, 'foo', 'a@example.com');
INSERT INTO contacts (id, name, email) VALUES (2, 'bar', 'b@example.com');
INSERT INTO contacts (id, name, email) VALUES (3, 'baz', 'c@fake.com');
----

Constant values may also be used as parameters to a SQL batch. In this case,
the same value is bound to that parameter for every SQL statement in the batch.

[source,java,indent=0]
----
public interface UserDao {
    @SqlBatch("INSERT INTO users (tenant_id, id, name) " +
              "VALUES (:tenantId, :user.id, :user.name)")
    void bulkInsert(@Bind("tenantId") long tenantId, // <1>
        @BindBean("user") User... users);
}
----
<1> Insert each user record using the same `tenant_id`. See <<mapping-arguments, SQL Object arguments mapping>> for details about the @Bind annotation.

[WARNING]
Any method annotated with link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^] must have at least one iterable parameter.

By default, methods annotated with link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^] may declare one of these
return types:

* `void` - no return value
* `int[]` or `long[]` - returns the update count per execution in the batch.  Depending on the database vendor and JDBC driver, this may be either the number of
  rows changed by a statement, or the number matched by the query (regardless of whether any data was changed).
* `boolean[]` - returns true if the update count is greater than zero, one value for each execution in the batch.


==== @SqlCall

Use the link:{jdbidocs}/sqlobject/statement/SqlCall.html[@SqlCall^] annotation to call stored procedures.

[source,java,indent=0]
----
public interface AccountDao {
    @SqlCall("{call suspend_account(:id)}")
    void suspendAccount(long id);
}
----

link:{jdbidocs}/sqlobject/statement/SqlCall.html[@SqlCall^] methods can return `void`, or may return
link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] if the stored procedure has any output parameters. Each output parameter must be registered
with the link:{jdbidocs}/sqlobject/customizer/OutParameter.html[@OutParameter^] annotation.

Returning an link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] object from an extension method is *incompatible* with <<on-demand-extension, on-demand objects>>. Any <<using-jdbi-extensions, other extension method>> can be used to create extension objects that can provide output parameters. Alternatively, it is possible to use <<sql-call-consumer-arguments, consumer or function arguments>> with on-demand extensions.


[source,java,indent=0]
----
public interface OrderDao {
    // only works with Handle#attach() or Jdbi#withExtension() / Jdbi#useExtension()
    @SqlCall("{call prepare_order_from_cart(:cartId, :orderId, :orderTotal)}")
    @OutParameter(name = "orderId",    sqlType = java.sql.Types.BIGINT)
    @OutParameter(name = "orderTotal", sqlType = java.sql.Types.DECIMAL)
    OutParameters prepareOrderFromCart(@Bind("cartId") long cartId);

    // using a consumer argument works with any extension method
    @SqlCall("{call prepare_order_from_cart(:cartId, :orderId, :orderTotal)}")
    @OutParameter(name = "orderId",    sqlType = java.sql.Types.BIGINT)
    @OutParameter(name = "orderTotal", sqlType = java.sql.Types.DECIMAL)
    prepareOrderFromCart(@Bind("cartId") long cartId, Consumer<OutParameters> consumer);

    // using a function argument also works with any extension method
    @SqlCall("{call prepare_order_from_cart(:cartId, :orderId, :orderTotal)}")
    @OutParameter(name = "orderId",    sqlType = java.sql.Types.BIGINT)
    @OutParameter(name = "orderTotal", sqlType = java.sql.Types.DECIMAL)
    SomeResult prepareOrderFromCart(@Bind("cartId") long cartId, Function<OutParameters, SomeResult> function);
}
----

Individual output parameters can be extracted from the
link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] object:

[source,java,indent=0]
----
db.useExtension(OrderDao.class, orderDao -> {
    OutParameters outParams = orderDao.prepareOrderFromCart(cartId);
    long orderId = outParams.getLong("orderId");
    double orderTotal = outParams.getDouble("orderTotal");
    ...
});
----

link:{jdbidocs}/sqlobject/statement/SqlCall.html[@SqlCall^] supports <<sql-call-consumer-arguments, special arguments>> for link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] processing.


==== @SqlScript

Use link:{jdbidocs}/sqlobject/statement/SqlScript.html[@SqlScript^] to execute one or more statements in a batch.

While link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^] executes the same SQL statement with different values, the link:{jdbidocs}/sqlobject/statement/SqlScript.html[@SqlScript^] annotation executes different SQL statements without explicit data bound to each statement.

[source,java,indent=0]
----
include::{sqlobjectexampledir}/statement/TestSqlScripts.java[tags=scripts]
----

<1> Sql scripts can use substitute placeholders. The default template engine uses angle brackets (`<` and `>`).

<2> The link:{jdbidocs}/sqlobject/customizer/Define.html[@Define^] annotation provides values for the placeholder attributes

<3> The link:{jdbidocs}/sqlobject/locator/UseClasspathSqlLocator.html[@UseClasspathSqlLocator^] annotation loads SQL templates from the classpath

<4> Use the name of the annotated method to locate the script

<5> specify the script name in the annotation

By default, methods annotated with link:{jdbidocs}/sqlobject/statement/SqlScript.html[@SqlScript^] may declare one of these return types:

* `void` - no return value
* `int[]` or `long[]` - return value of each statement executed.  Depending on the database vendor and JDBC driver, this may be either the number of rowsreturn
  nothing changed by a statement, or the number matched by the query (regardless of whether any data was changed).
* `boolean[]` - returns true if the update count is greater than zero, one value for each statement in the script.


=== Using SQL Objects

SQL Object types are regular Java interfaces classes that must be public. Once they have been defined, there are multiple ways to use them. They differ in the <<extension-handle-lifecycle, lifecycle>> of the underlying link:{jdbidocs}/core/Handle.html[Handle^] object:

* *attached to an existing handle object*

The link:{jdbidocs}/core/Handle.html#attach(java.lang.Class)[Handle#attach()^] method uses an existing handle to create a SQL object instance:

[source,java,indent=0]
----
try (Handle handle = jdbi.open()) {
    ContactPhoneDao dao = handle.attach(ContactPhoneDao.class);
    dao.insertFullContact(contact);
}
----

Attached SQL Objects have the same lifecycle as the handle--when the handle is closed, the SQL Object becomes unusable.

* *using Jdbi extension methods*

SQL Object types can be created using
link:{jdbidocs}/core/Jdbi.html#withExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionCallback-[Jdbi#withExtension()^]
for operations that return a result, or
link:{jdbidocs}/core/Jdbi.html#useExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionConsumer-[Jdbi#useExtension()^]
for operations with no result. These methods take a callback (or a lambda object) and provide it with a managed instance of the SQL object type:

[source,java,indent=0]
----
jdbi.useExtension(ContactPhoneDao.class, dao -> dao.insertFullContact(alice));
long bobId = jdbi.withExtension(ContactPhoneDao.class, dao -> dao.insertFullContact(bob));
----


* *creating an on-demand object*

On-demand instances are constructed with the link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^] method. They have an open-ended lifecycle, as they obtain and release a connection for each method call. They are thread-safe, and may be reused across an application.


[source,java,indent=0]
----
ContactPhoneDao dao = jdbi.onDemand(ContactPhoneDao.class);
long aliceId = dao.insertFullContact(alice); // <1>
long bobId = dao.insertFullContact(bob); // <1>
----

<1> each of these operations creates and releases a new database connection.

The performance of on-demand objects depends on the database and database connection pooling. For performance critical operations, it may be better to manage the handle manually and use attached objects.

On-demand instances open and close the underlying link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html[PreparedStatement^] objects for every call to an extension method. They are incompatible with any object or operation that relies on an open statement to retrieve data from the database (e.g. link:{jdkdocs}/java/util/stream/Stream.html[Stream^] and link:{jdkdocs}/java/util/Iterator.html[Iterator^] for query operations or link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] for call operations). It is possible to use <<consumer-and-function-arguments, consumer or function arguments>> to process these values as the callback is executed while the statement is still open.


==== Interface default methods

_Interface default methods_ on a SQL object type can provide custom code functionality that uses the same handle as the SQL Object methods.

The SQL object framework manages the underlying handle so that calling a method on the same object on the same thread will use the same link:{jdbidocs}/core/Handle.html[Handle^] object. If the handle is managed by the framework, it will only be closed when the outermost method exits.

[source,java,indent=0]
----
include::{exampledir}/DefaultMethodTest.java[tag=default-method]

include::{exampledir}/DefaultMethodTest.java[tag=dao]
----

<1> The `changeName()` method is called by the user code
<2> The implementation will call both `findUser()` and `updateUser()` with the same handle object.


=== SQL Object method arguments

All SQL Object methods support method arguments. Method arguments are mapped onto SQL statement parameters.

==== Mapping arguments to positional parameters

By default, arguments passed to the method are bound as positional parameters in the SQL statement:

[source,java,indent=0]
----
public interface UserDao {
    @SqlUpdate("INSERT INTO users (id, name) VALUES (?, ?)") // <1>
    void insert(long id, String name); // <2>
}
----
<1> declares two positional parameters
<2> provides two method parameters. `id` will be bound as the first, `name` as the second parameter.

This matches the link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html[PreparedStatement^] way of binding arguments to a statement. Jdbi binds the arguments as the correct types and convert them if necessary.

[#mapping-arguments]
==== Mapping arguments to named parameters

The Jdbi core supports named parameters in SQL statements. When using the SQL Object extension, those can be bound to specific method arguments using annotations.

The link:{jdbidocs}/sqlobject/customizer/Bind.html[@Bind^] annotation binds a single method argument to a named parameter:

[source,java,indent=0]
----
@SqlUpdate("INSERT INTO users (id, name) VALUES (:id, :name)") // <1>
void insert(@Bind("name") String name, @Bind("id") long id); // <2>
----

<1> The SQL statement uses two named parameters, `:id` and `:name`
<2> The method declaration annotates each parameter with the link:{jdbidocs}/sqlobject/customizer/Bind.html[@Bind^] annotation with matching names. The order is not important as each method parameter is explicitly named

Similar to the methods on the link:{jdbidocs}/core/Handle.html[Handle^], arguments can be bound in many different ways:


===== Bind any iterable object with @BindList

Any Java object that implements the Iterable interface can be bound using the link:{jdbidocs}/sqlobject/customizer/BindList.html[@BindList^] annotation. This
will iterate the elements in 'a,b,c,d,...' form.

[NOTE]
This annotation requires you to use a template placeholder (using the `<field>` notation when using the default template engine), similar to the link:{jdbidocs}/core/statement/SqlStatement.html#bindList(java.lang.String,java.lang.Iterable)[SqlStatement#bindList()^] method. Templates placeholders are incompatible with batch operations such as`PreparedBatch` as they are evaluated only once and the evaluated statement is cached. If subsequent batch executions use an iterable object with a different size, the number of placeholders and arguments will not match. If the database supports array types, it is strongly recommended to use `bindArray()` with a SQL array instead of the `bindList()` method.

[source,java,indent=0]
----
@SqlQuery("SELECT name FROM users WHERE id in (<userIds>)")
List<String> getFromIds(@BindList("userIds") List<Long> userIds)
----


===== Bind map instances with @BindMap

Entries from a link:{jdkdocs}/java.base/java/util/Map.html[Map^] can be bound using the link:{jdbidocs}/sqlobject/customizer/BindMap.html[@BindMap^] annotation. Each entry from the map is bound as a named parameter using the map key as the name and the map value as the value. Jdbi will bind the values as the correct types and convert them if necessary:

[source,java,indent=0]
----
@SqlUpdate("INSERT INTO users (id, name) VALUES (:id, :name)")  // <1>
void insert(@BindMap Map<String, ?> map); // <2>
----

<1> The SQL statement expects two named parameters, `:id` and `:name`
<2> Jdbi will look for two keys, `id` and a `name` in the map. The values for these keys are bound to the parameters.


===== Bind bean getters with @BindBean

Java Bean getters can be bound with the link:{jdbidocs}/sqlobject/customizer/BindBean.html[@BindBean^] annotation:

[source,java,indent=0]
----
include::{exampledir}/BindMethodsTest.java[tags=user-bean]
    }

include::{exampledir}/BindMethodsTest.java[tags=user-bean-method]
----

This annotation uses the Java Bean syntax for getters.


===== Bind parameterless public methods with @BindMethods

Similar to link:{jdbidocs}/sqlobject/customizer/BindBean.html[@BindBean^], the link:{jdbidocs}/sqlobject/customizer/BindMethods.html[@BindMethods^] annotation bean methods as parameters. For each binding, it looks for a method with the same name:

[source,java,indent=0]
----
include::{exampledir}/BindMethodsTest.java[tags=user]
    }

include::{exampledir}/BindMethodsTest.java[tags=user-method]
----

[TIP]
When using https://docs.oracle.com/en/java/javase/14/language/records.html[Java 14+ record types^], all getters from the record can be bound using the link:{jdbidocs}/sqlobject/customizer/BindMethods.html[@BindMethods^] annotation.


===== Bind public fields from a java object with @BindFields

Many objects offer public fields instead of getters. Those can be bound by using the link:{jdbidocs}/sqlobject/customizer/BindFields.html[@BindFields^] annotation:

[source,java,indent=0]
----
include::{exampledir}/BindMethodsTest.java[tags=user-field]
    }

include::{exampledir}/BindMethodsTest.java[tags=user-field-method]
----


===== Using object prefixes

The `link:{jdbidocs}/sqlobject/customizer/BindMap.html[@BindMap^], link:{jdbidocs}/sqlobject/customizer/BindBean.html[@BindBean^], link:{jdbidocs}/sqlobject/customizer/BindMethods.html[@BindMethods^], and link:{jdbidocs}/sqlobject/customizer/BindFields.html[@BindFields^] annotations support an optional prefix:

[source,java,indent=0]
----
include::{exampledir}/BindMethodsTest.java[tags=user-bean-prefix-method]
----

<1> The `id` and `name` parameters are prefixed with `user`.
<2> The `User` object which provides the values uses a prefix. The `user.id` parameter will be mapped to the `getId()` method of this bean and the `user.name` parameter to the `getName()` method.

By providing prefixes, it is possible to use multiple objects with different prefixes or mix map and regular bound parameters.

[source,java,indent=0]
----
@SqlUpdate("INSERT INTO users (id, name, password) VALUES (:user.id, :user.name, :password)")
void insert(@BindMap("user") Map<String, ?> map, @Bind("password") String password);
----

Even if the provided map would contain a key named `password`, it would not be used, because all values from the map are bound with the `user` prefix.


===== Using nested properties

Similar to the Core API, the  link:{jdbidocs}/sqlobject/customizer/BindBean.html[@BindBean^], link:{jdbidocs}/sqlobject/customizer/BindFields.html[@BindFields^], and link:{jdbidocs}/sqlobject/customizer/BindMethods.html[@BindMethods^] annotation will also map nested properties.

A Java object that returns a nested object can be bound and then nested properties are addressed using e.g. `:user.address.street`.

This functionality is *not* available for Map objects that have been bound with link:{jdbidocs}/sqlobject/customizer/BindMap.html[@BindMap^]. Map keys must match the bound parameter name.


[source,java,indent=0]
----
include::{exampledir}/BindMethodsTest.java[tags=nested-user]

include::{exampledir}/BindMethodsTest.java[tags=nested-user-method]
----

[NOTE]
"Mixes style" nested properties are not supported. Any nested object will be inspected in the same way as the root object. All nested objects must use either bean-style, methods or fields.


==== Mapping arguments to Java parameter names

When compiling a project with <<compiling_with_parameter_names,parameter names>> enabled, the link:{jdbidocs}/sqlobject/customizer/Bind.html[@Bind^] annotation is not needed. SQLObjects will bind un-annotated parameters to their names.

[source,java,indent=0]
----
@SqlUpdate("INSERT INTO users (id, name) VALUES (:id, :name)")
void insert(long id, String name);
----


[#consumer-and-function-arguments]
==== Consumer and Function arguments

===== Consumer arguments

In addition to the regular method arguments for a SQL Object method, it is possible to use a single link:{jdkdocs}/java.base/java/util/function/Consumer.html[Consumer<T>^] or link:{jdkdocs}/java.base/java/util/function/Function.html[Function<T>^] argument in addition to other arguments.

A consumer argument is a special return type for SQL operations. They can be used to consume the results from a SQL operation with a callback instead of returning a value from the method.

Any SQL operation method that wants to use a consumer argument *must* return `void`. It can declare only a single consumer argument, but can have additional regular method arguments. The consumer argument can be in any position in the argument list. .

Unless the type `T` is a link:{jdkdocs}/java.base/java/util/stream/Stream.html[Stream^], link:{jdkdocs}/java.base/java/util/Iterator.html[Iterator^] or link:{jdkdocs}/java.base/java/lang/Iterable.html[Iterable^], the consumer is executed once for each row in the result set. The static type of parameter `T` determines the row type.

[source,java,indent=0]
----
include::{exampledir}/BindMethodsTest.java[tags=consume-user-method]
----

<1> This SQL operation may return no or just one result. The consumer argument will only be invoked if a user exists.

<2> This SQL operation may return multiple results. It will invoke the consumer argument once for every result.

If the consumer implements link:{jdkdocs}/java.base/java/util/stream/Stream.html[Stream^], link:{jdkdocs}/java.base/java/util/Iterator.html[Iterator^] or link:{jdkdocs}/java.base/java/lang/Iterable.html[Iterable^], then the consumer is executed once with the corresponding object holding the results. The static type of parameter `T` determines the mapped row type here as well. If the result set is empty, the SQL Object framework may not call the consumer or may call it with an empty result object.


[source,java,indent=0]
----
include::{exampledir}/BindMethodsTest.java[tags=consume-iterable-user-method]
----

<1> This consumer argument is called once if any number of results are present. It may be called with an empty iterable object or not at all if no results are present.

[WARNING]
When using link:{jdkdocs}/java.base/java/util/function/Consumer.html[Consumer<Iterable>^] as a consumer argument, the link:{jdkdocs}/java.base/java/lang/Iterable.html[Iterable^] object passed into the consumer is *NOT* a general-purpose Iterable as it supports only a single invocation of the link:{jdkdocs}/java.base/java/lang/Iterable.html#iterator--[Iterable#iterator()^] method. Invoking it the iterator method again to obtain a second or subsequent iterator may throw link:{jdkdocs}/java.base/java/lang/IllegalStateException.html[IllegalStateException^].


===== Function arguments

A function argument can be used to collect or transform the result from a SQL operation. Similar to a consumer argument, it will receive the results of the query. A function argument only supports link:{jdkdocs}/java.base/java/util/stream/Stream.html[Stream^], link:{jdkdocs}/java.base/java/util/Iterator.html[Iterator^] or link:{jdkdocs}/java.base/java/lang/Iterable.html[Iterable^] as the function input type. The result type of the function must match the return type of the method itself.

[source,java,indent=0]
----
include::{exampledir}/BindMethodsTest.java[tags=function-user-method]
----

<1> The results of the SQL operation are passed as a stream into the Function. It returns a set which is then returned by the method.

[#sql-call-consumer-arguments]
===== `@SqlCall` Consumer and Function arguments

The link:{jdbidocs}/sqlobject/statement/SqlCall.html[@SqlCall^] annotation supports either a Consumer argument or a Function argument for the link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] return value.

A method that has been annotated with link:{jdbidocs}/sqlobject/statement/SqlCall.html[@SqlCall^] may have any number of regular method arguments and

- declare `void` or link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] as its return type.
- declare `void` as its return type and have a single link:{jdkdocs}/java.base/java/util/function/Consumer.html[Consumer<OutParameters>^] consumer argument
- declare an arbitrary type `T` as return type and have a single link:{jdkdocs}/java.base/java/util/function/Function.html[Function<OutParameters, T>^] function argument

When using a consumer or function argument, these are called to process the link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] value before the statement is closed.

==== Mapping arguments to defined attributes

The Jdbi core framework supports attributes that can be used anywhere in the SQL statement or that can control <<query-templating,Query template rendering>>. The link:{jdbidocs}/sqlobject/customizer/Define.html[@Define^] annotation provides this functionality for the SQL Object extension:

[source,java,indent=0]
----
include::{exampledir}/AttributeDefineTest.java[tags=dao]

include::{exampledir}/AttributeDefineTest.java[tags=define]
----

<1> declare an attribute placeholder for the table name

<2> bind the placeholder to the method argument

<3> provide the value for the placeholder when calling the SQL object method


=== SQL Object method return values

The SQL Object framework will try to convert the result of a database operation to the declared return value of a SQL Object method.

This is most important for link:{jdbidocs}/sqlobject/statement/SqlQuery.html[@SqlQuery^] operations as most other operations have a very limited set of possible return values:

* link:{jdbidocs}/sqlobject/statement/SqlUpdate.html[@SqlUpdate^] - supports `void`, `int`, `long`, `boolean`
* link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^] -  supports `void`, `int[]`, `long[]`, `boolean[]`
* link:{jdbidocs}/sqlobject/statement/SqlScript.html[@SqlScript^] - supports `void`, `int[]`, `long[]`, `boolean[]`
* link:{jdbidocs}/sqlobject/statement/SqlCall.html[@SqlCall^] - supports `void`, link:{jdbidocs}/core/statement/OutParameters.html[OutParameters^] (and function arguments)


Query methods may return a single row or multiple rows, depending on whether the method return type looks like a collection:

[source,java,indent=0]
----
public interface UserDao {
    @SqlQuery("SELECT name FROM users")
    List<String> listNames(); // <1>

    @SqlQuery("SELECT name FROM users WHERE id = ?")
    String getName(long id); // <2>

    @SqlQuery("SELECT name FROM users WHERE id = ?")
    Optional<String> findName(long id); // <3>

    @SqlQuery("SELECT id, name FROM users WHERE id = ?")
    Optional<User> findUser(long id); // <4>
}
----
<1> Returns a collection of results. This is never null, an empty collection is returned for an empty result set.

<2> Returns a single result. If the query returns a result set with multiple rows, then only the first row is returned. If the row set is empty, `null` is returned.

<3> Methods may return link:{jdkdocs}/java.base/java/util/Optional.html[Optional^] values. If the query returns no rows (or if the value in the row is `null`),
link:{jdkdocs}/java.base/java/util/Optional.html#empty--[Optional.empty()^] is returned instead of `null`.  SQL Object throws an exception if query returns more than one
row.

<4> When returning a complex type, Jdbi must have row and column mappers registered, otherwise it will throw an exception. These can be registered through the Jdbi
core API or with annotations.


[TIP]
Jdbi can use different collection types by registering a link:{jdbidocs}/core/collector/CollectorFactory.html[CollectorFactory^] with the link:{jdbidocs}/core/collector/JdbiCollectors.html[JdbiCollectors^]
config registry.

See
link:{jdbidocs}/core/collector/BuiltInCollectorFactory.html[BuiltInCollectorFactory^]
for the complete list of collection types supported out of the box. Some
Jdbi plugins (e.g. the link:{jdbidocs}/guava/GuavaPlugin.html[GuavaPlugin^]) register additional collection types.


[#using-steams-and-iterators]
==== Using Streams and Iterators

SQL Object method may return
link:{jdbidocs}/core/result/ResultIterable.html[ResultIterable^],
link:{jdbidocs}/core/result/ResultIterator.html[ResultIterator^] or
link:{jdkdocs}/java.base/java/util/stream/Stream.html[Stream^] types. Each of these return values represents a cursor-type object that requires an active link:{jdbidocs}/core/Handle.html[Handle^] object with a database connection <<resources-with-streams-iterators, to support streaming results>>.

All SQL object type methods are subject to the <<extension-handle-lifecycle,extension framework Handle lifecycle>>. When the link:{jdbidocs}/core/Handle.html[Handle^] object is closed, the database connection and the corresponding stream or iterator is closed as well.

This is an example of a SQL Object type that returns cursor types:

[source,java,indent=0]
----
interface UserDao {
    @SqlQuery("SELECT name FROM users")
    Stream<String> getNamesAsStream();

    @SqlQuery("SELECT name FROM users")
    ResultIterable<String> getNamesAsIterable();

    @SqlQuery("SELECT name FROM users")
    ResultIterator<String> getNamesAsIterator();
}
----

===== Use the method return value directly

Only the link:{jdbidocs}/core/Handle.html#attach(java.lang.Class)[Handle#attach()^] method allows cursor type objects as SQL Object method return values. Calling this method attaches the object to the Handle lifecycle which in turn is managed by user code:

[source,java,indent=0]
----
include::{exampledir}/LiveObjectsTest.java[tag=attach]
----

<1> The handle is managed in user code.

<2> The stream is also managed.

<3> The returned stream is used within the _try-with-resources_ block.


The objects returned from these methods hold database resources that should be closed. <<statement-resource-management, Jdbi usually handles resources well>> but using a _try-with-resource_ block is a good practice:

[source,java,indent=0]
----
try (ResultIterable<String> names = dao.getNamesAsIterable()) {
    // ...
}

try (ResultIterator<String> names = dao.getNamesAsIterator()) {
    // ...
}

try (Stream<String> names = dao.getNamesAsStream()) {
    // ...
}
----


The link:{jdbidocs}/core/Jdbi.html#withExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionCallback-[Jdbi#withExtension()^] or link:{jdbidocs}/core/Jdbi.html#useExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionConsumer-[Jdbi#useExtension()^] methods *can not be used*:

[source,java,indent=0]
----
include::{exampledir}/LiveObjectsTest.java[tag=extension]
----

<1> The handle is closed when leaving the link:{jdbidocs}/core/Jdbi.html#withExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionCallback-[Jdbi#withExtension()^] method.

<2> Calling the link:{jdkdocs}/java.base/java/util/stream/Stream.html#collect-java.util.stream.Collector-[Stream#collect()^] method on the returned stream causes a link:{jdbidocs}/core/result/ResultSetException.html[ResultSetException^].


The link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^] method *can not be used either*:

[source,java,indent=0]
----
include::{exampledir}/LiveObjectsTest.java[tag=on-demand]
----

<1> The handle is closed when leaving the `getNamesAsStream` method.

<2> Calling the link:{jdkdocs}/java.base/java/util/stream/Stream.html#collect-java.util.stream.Collector-[Stream#collect()^] method on the returned stream causes a link:{jdbidocs}/core/result/ResultSetException.html[ResultSetException^].


===== Use interface default methods

The SQL Object framework closes the link:{jdbidocs}/core/Handle.html[Handle^] object when returning from the outermost method in a SQL object type. It is possible to write processing logic in an _interface default method_:



[source,java,indent=0]
----
include::{exampledir}/LiveObjectsTest.java[tag=dao]
----

<1> The handle is closed when exiting the `getNames` method as this is the outermost method in the UserDao object.

<2> The stream is managed with a _try-with-resources_ block.

<3> The stream can be processed within the `getNames` method.


The default method can be used with the link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^], link:{jdbidocs}/core/Jdbi.html#withExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionCallback-[Jdbi#withExtension()^] and link:{jdbidocs}/core/Jdbi.html#useExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionConsumer-[Jdbi#useExtension()^] methods:

[source,java,indent=0]
----
include::{exampledir}/LiveObjectsTest.java[tag=on-demand-default]

include::{exampledir}/LiveObjectsTest.java[tag=extension-default]
----

===== Use consumer or function arguments

Using the method return value either directly or through an _interface default method_ has the drawback that the user code to process the cursor-type object must be written within the SQL Object type as it must be executed before closing the link:{jdbidocs}/core/Handle.html[Handle^] object.

An elegant way to sidestep this problem is using a <<Consumer arguments, consumer argument>> or a <<Function, function argument>> to provide a callback:

[source,java,indent=0]
----
include::{exampledir}/LiveObjectsTest.java[tag=callback-dao]
----

Using a callback argument supports all link:{jdbidocs}/core/Jdbi.html[Jdbi^] and link:{jdbidocs}/core/Handle.html[Handle^] methods to attach SQL objects:

[source,java,indent=0]
----
include::{exampledir}/LiveObjectsTest.java[tag=attach-callback]
----

<1> The link:{jdbidocs}/core/Handle.html[Handle^] lifecycle must still be managed by user code.

<2> The stream is managed by the SQL object framework and does not need to be closed by user code.

This code also works with the link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^] and link:{jdbidocs}/core/Jdbi.html#useExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionConsumer-[Jdbi#useExtension()^] methods:

[source,java,indent=0]
----
include::{exampledir}/LiveObjectsTest.java[tag=on-demand-callback]

include::{exampledir}/LiveObjectsTest.java[tag=extension-callback]
----

<1> This code uses link:{jdbidocs}/core/Jdbi.html#useExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionConsumer-[Jdbi#useExtension()^] instead of link:{jdbidocs}/core/Jdbi.html#withExtension-java.lang.Class-org.jdbi.v3.core.extension.ExtensionCallback-[Jdbi#withExtension()^] as the SQL Object method returns `void`.

[NOTE]
While using a consumer or a function argument is a great way to deal with cursor-type objects, there is the drawback that the user code is called while holding the handle (or the database connection) open. If the callback does very expensive or slow processing, this may hold the connection for a very long time.


[#sqlobject-mapper-annotations]
=== SQL Object mapper annotations

The most common use for annotations is to register specific row and column mappers to return values from link:{jdbidocs}/sqlobject/statement/SqlQuery.html[@SqlQuery^].

==== @RegisterRowMapper

Use link:{jdbidocs}/sqlobject/config/RegisterRowMapper.html[@RegisterRowMapper^] to register a concrete row mapper class:

[source,java,indent=0]
----
public interface UserDao {
    @SqlQuery("SELECT * FROM users")
    @RegisterRowMapper(UserMapper.class)
    List<User> list();
}
----

Row mappers used with this annotation must meet a few requirements:

[source,java,indent=0]
----
public class UserMapper implements RowMapper<User> { // <1> <2>
    public UserMapper() { // <3>
        // ...
    }

    public T map(ResultSet rs, StatementContext ctx) throws SQLException {
        // ...
    }
}
----
<1> Must be a public class.
<2> Must implement link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^] with an explicit type argument (e.g.
    link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper<User>^]) instead of a type variable (e.g. link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper<T>^]).
<3> Must have a public, no-argument constructor (or a default constructor).

[TIP]
The link:{jdbidocs}/sqlobject/config/RegisterRowMapper.html[@RegisterRowMapper^] annotation may be repeated multiple times on the same
type or method to register multiple mappers.


==== @RegisterRowMapperFactory

Use link:{jdbidocs}/sqlobject/config/RegisterRowMapperFactory.html[@RegisterRowMapperFactory^] to register a link:{jdbidocs}/core/mapper/RowMapperFactory.html[RowMapperFactory^].

[source,java,indent=0]
----
public interface UserDao {
    @SqlQuery("SELECT * FROM users")
    @RegisterRowMapperFactory(UserMapperFactory.class)
    List<User> list();
}
----

Row mapper factories used with this annotation must meet a few requirements:

[source,java,indent=0]
----
public class UserMapperFactory implements RowMapperFactory { // <1>
    public UserMapperFactory() { // <2>
        // ...
    }

    public Optional<RowMapper<?>> build(Type type, ConfigRegistry config) {
        // ...
    }
}
----
<1> Must be a public class.
<2> Must have a public, no-argument constructor (or a default constructor).

[TIP]
The link:{jdbidocs}/sqlobject/config/RegisterRowMapperFactory.html[@RegisterRowMapperFactory^] annotation may be repeated multiple times on the
same type or method to register multiple factories.


==== @RegisterColumnMapper

Use link:{jdbidocs}/sqlobject/config/RegisterColumnMapper.html[@RegisterColumnMapper^] to register a column mapper:

[source,java,indent=0]
----
public interface AccountDao {
    @SqlQuery("SELECT balance FROM accounts WHERE id = ?")
    @RegisterColumnMapper(MoneyMapper.class)
    Money getBalance(long id);
}
----

Column mappers used with this annotation must meet a few requirements:

[source,java,indent=0]
----
public class MoneyMapper implements ColumnMapper<Money> { // <1> <2>
    public MoneyMapper() { // <3>
        // ...
    }

    public T map(ResultSet r, int columnNumber, StatementContext ctx) throws SQLException {
        // ...
    }
}
----
<1> Must be a public class.
<2> Must implement link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper^] with an explicit type argument (e.g.
link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper<User>^]) instead of a type variable (e.g. link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper<T>^]).
<3> Must have a public, no-argument constructor (or a default constructor).

[TIP]
The link:{jdbidocs}/sqlobject/config/RegisterColumnMapper.html[@RegisterColumnMapper^] annotation may be repeated multiple times on the
same type or method to register multiple mappers.


==== @RegisterColumnMapperFactory

Use link:{jdbidocs}/sqlobject/config/RegisterColumnMapperFactory.html[@RegisterColumnMapperFactory^] to register a column mapper factory:

[source,java,indent=0]
----
public interface AccountDao {
    @SqlQuery("SELECT * FROM users")
    @RegisterColumnMapperFactory(MoneyMapperFactory.class)
    List<User> list();
}
----

Column mapper factories used with this annotation must meet a few requirements:

[source,java,indent=0]
----
public class UserMapperFactory implements RowMapperFactory { // <1>
    public UserMapperFactory() { // <2>
        // ...
    }

    public Optional<RowMapper<?>> build(Type type, ConfigRegistry config) {
        // ...
    }
}
----
<1> Must be a public class.
<2> Must have a public, no-argument constructor (or a default constructor).

[TIP]
The link:{jdbidocs}/sqlobject/config/RegisterColumnMapperFactory.html[@RegisterColumnMapperFactory^] annotation may be repeated multiple times on
the same type or method to register multiple factories.


==== @RegisterBeanMapper

Use link:{jdbidocs}/sqlobject/config/RegisterBeanMapper.html[@RegisterBeanMapper^] to register a <<BeanMapper>> for a bean class:

[source,java,indent=0]
----
public interface UserDao {
    @SqlQuery("SELECT * FROM users")
    @RegisterBeanMapper(User.class)
    List<User> list();
}
----

Using the `prefix` attribute causes the bean mapper to map only those columns
that begin with the prefix:

[source,java,indent=0]
----
public interface UserDao {
    @SqlQuery("SELECT u.id u_id, u.name u_name, r.id r_id, r.name r_name " +
              "FROM users u LEFT JOIN roles r ON u.role_id = r.id")
    @RegisterBeanMapper(value = User.class, prefix = "u")
    @RegisterBeanMapper(value = Role.class, prefix = "r")
    Map<User,Role> getRolesPerUser();
}
----

In this example, the `User` mapper will map the columns `u_id` and `u_name` into
the `User.id` and `User.name` properties. Likewise for `r_id` and `r_name` into
`Role.id` and `Role.name`, respectively.

[TIP]
The link:{jdbidocs}/sqlobject/config/RegisterBeanMapper.html[@RegisterBeanMapper^] annotation may be repeated (as demonstrated above) on
the same type or method to register multiple bean mappers.


==== @RegisterConstructorMapper

Use link:{jdbidocs}/sqlobject/config/RegisterConstructorMapper.html[@RegisterConstructorMapper^] to register a <<ConstructorMapper>> for classes
that are instantiated with all properties through the constructor.

[source,java,indent=0]
----
public interface UserDao {
    @SqlQuery("SELECT * FROM users")
    @RegisterConstructorMapper(User.class)
    List<User> list();
}
----

Using the `prefix` attribute causes the constructor mapper to only map those
columns that begin with the prefix:

[source,java,indent=0]
----
public interface UserDao {
    @SqlQuery("SELECT u.id u_id, u.name u_name, r.id r_id, r.name r_name " +
              "FROM users u LEFT JOIN roles r ON u.role_id = r.id")
    @RegisterConstructorMapper(value = User.class, prefix = "u")
    @RegisterConstructorMapper(value = Role.class, prefix = "r")
    Map<User,Role> getRolesPerUser();
}
----

In this example, the `User` mapper will map the columns `u_id` and `u_name` into
the `id` and `name` parameters of the `User` constructor. Likewise for `r_id`
and `r_name` into `id` and `name` parameters of the `Role` constructor,
respectively.

[TIP]
The link:{jdbidocs}/sqlobject/config/RegisterConstructorMapper.html[@RegisterConstructorMapper^] annotation may be repeated multiple times on
the same type or method to register multiple constructor mappers.


==== @RegisterFieldMapper

Use link:{jdbidocs}/sqlobject/config/RegisterFieldMapper.html[@RegisterFieldMapper^] to register a <<FieldMapper>> for a given class.

[source,java,indent=0]
----
public interface UserDao {
    @SqlQuery("SELECT * FROM users")
    @RegisterFieldMapper(User.class)
    List<User> list();
}
----

Using the `prefix` attribute causes the field mapper to only map those columns
that begin with the prefix:

[source,java,indent=0]
----
public interface UserDao {
    @SqlQuery("SELECT u.id u_id, u.name u_name, r.id r_id, r.name r_name " +
              "FROM users u LEFT JOIN roles r ON u.role_id = r.id")
    @RegisterFieldMapper(value = User.class, prefix = "u")
    @RegisterFieldMapper(value = Role.class, prefix = "r")
    Map<User,Role> getRolesPerUser();
}
----

In this example, the `User` mapper will map the columns `u_id` and `u_name` into
the `User.id` and `User.name` fields. Likewise for `r_id` and `r_name` into the
`Role.id` and `Role.name` fields, respectively.

[TIP]
The link:{jdbidocs}/sqlobject/config/RegisterConstructorMapper.html[@RegisterConstructorMapper^] annotation may be repeated multiple times on
the same type or method to register multiple constructor mappers.

=== Other SQL Object annotations

[#sqlupdate-getgeneratedkeys]
==== @GetGeneratedKeys

Some SQL statements will cause data to be generated on your behalf at the
database, e.g. a table with an auto-generated primary key, or a primary key
selected from a sequence.  The link:{jdbidocs}/sqlobject/statement/GetGeneratedKeys.html[@GetGeneratedKeys^] annotation may be used to return the keys generated from the SQL statement:

The link:{jdbidocs}/sqlobject/statement/GetGeneratedKeys.html[@GetGeneratedKeys^] annotation tells Jdbi that the return value should be generated key from the SQL statement, instead of the update count.

[source,java,indent=0]
----
public interface UserDao {
    @SqlUpdate("INSERT INTO users (id, name) VALUES (nextval('user_seq'), ?)")
    @GetGeneratedKeys("id")
    long insert(String name);
}
----

Multiple columns may be generated and returned:

[source,java,indent=0]
----
public interface UserDao {
    @SqlUpdate("INSERT INTO users (id, name, created_on) VALUES (nextval('user_seq'), ?, now())")
    @GetGeneratedKeys({"id", "created_on"})
    @RegisterBeanMapper(IdCreateTime.class)
    IdCreateTime insert(String name);
}
----

[CAUTION]
Databases vary in support for generated keys. Some support only one generated key column per statement, and some (such as Postgres) can return the entire row.
You should check your database vendor's documentation before relying on this behavior.

link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^] also supports the annotation:

[source,java,indent=0]
----
include::{exampledir}/GeneratedKeysTest.java[tags=sqlObject]
----

When using link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^], the link:{jdbidocs}/sqlobject/statement/GetGeneratedKeys.html[@GetGeneratedKeys^] annotations tells SQL Object  that the return value should be the generated keys from each SQL statement, instead of the update count.

[source,java,indent=0]
----
public interface UserDao {
    @SqlBatch("INSERT INTO users (id, name) VALUES (nextval('user_seq'), ?)")
    @GetGeneratedKeys("id")
    long[] bulkInsert(List<String> names); // <1>
}
----
<1> Returns the generated ID for each inserted name.

Multiple columns may be generated and returned in this way:
[source,java,indent=0]
----
public interface UserDao {
    @SqlBatch("INSERT INTO users (id, name, created_on) VALUES (nextval('user_seq'), ?, now())")
    @GetGeneratedKeys({"id", "created_on"})
    @RegisterBeanMapper(IdCreateTime.class)
    List<IdCreateTime> bulkInsert(String... names);
}
----


[TIP]
Postgres supports additional functionality when returning generated keys. See <<postgres-getgeneratedkeys,PostgreSQL>> for more details.


[#sqllocator]
==== @SqlLocator

When SQL statements grow in complexity, it may be cumbersome to provide
the statements as Java strings in the SQL method annotations.

[TIP]
Jdbi supports the https://docs.oracle.com/en/java/javase/15/text-blocks/index.html[Java Textblock construct] available in Java 15 and later. Using a text block is an elegant way to specify multi-line SQL statements.

Jdbi provides annotations that let you configure external locations to
load SQL statements.

* link:{jdbidocs}/sqlobject/locator/UseAnnotationSqlLocator.html[@UseAnnotationSqlLocator^] - use  annotation value of the SQL method annotations (this is the default behavior)
* link:{jdbidocs}/sqlobject/locator/UseClasspathSqlLocator.html[@UseClasspathSqlLocator^] - loads SQL from a file on the classpath, based on the package and name of the SQL Object interface type.

[source,java,indent=0]
----
package com.foo;

@UseClasspathSqlLocator
interface BarDao {
    // loads classpath resource com/foo/BarDao/query.sql
    @SqlQuery
    void query();
}
----

link:{jdbidocs}/sqlobject/locator/UseClasspathSqlLocator.html[@UseClasspathSqlLocator^] is implemented using the <<ClasspathSqlLocator>>, as described above.

[WARNING]
<<ClasspathSqlLocator>> loads a file unchanged by default. Using the link:{jdbidocs}/sqlobject/locator/UseClasspathSqlLocator.html[@UseClasspathSqlLocator^] annotation will strip out comments by default! This may lead to unexpected behavior, e.g. SQL Server uses the `#` character to denote temporary tables. This can be controlled with the `stripComments` annotation attribute.

[source,java,indent=0]
----
package com.foo;

@UseClasspathSqlLocator(stripComments=false)
interface BarDao {
    // loads classpath resource com/foo/BarDao/query.sql without stripping comment lines
    @SqlQuery
    void query();
}
----

* The <<stringtemplate4,jdbi-stringtemplate4>> module provides link:{jdbidocs}/stringtemplate4/UseStringTemplateSqlLocator.html[@UseStringTemplateSqlLocator^], a SqlLocator, which can load SQL templates from StringTemplate 4 files on the classpath.
* The jdbi-freemarker module provides link:{jdbidocs}/freemarker/UseFreemarkerSqlLocator.html[@UseFreemarkerSqlLocator^], which can load SQL templates from Freemarker files on the classpath.


==== @CreateSqlObject

Use the link:{jdbidocs}/sqlobject/CreateSqlObject.html[@CreateSqlObject^] annotation to reuse a SQL Object type within another object.

This is an example where a SQL update defined in a different SQL Object type is executed as part of a transaction:

[source,java,indent=0]
----
public interface Bar {
    @SqlUpdate("INSERT INTO bar (name) VALUES (:name)")
    @GetGeneratedKeys
    int insert(@Bind("name") String name);
}

public interface Foo {

    @CreateSqlObject
    Bar createBar();

    @SqlUpdate("INSERT INTO foo (bar_id, name) VALUES (:bar_id, :name)")
    void insert(@Bind("bar_id") int barId, @Bind("name") String name);

    @Transaction
    default void insertBarAndFoo(String barName, String fooName) {
        int barId = createBar().insert(barName);
        insert(barId, fooName);
    }
}
----

The link:{jdbidocs}/sqlobject/CreateSqlObject.html[@CreateSqlObject^] annotation can also be used to  process cursor-type objects inside _interface default methods_:

[source,java,indent=0]
----
include::{exampledir}/LiveObjectsTest.java[tag=nested-dao]

include::{exampledir}/LiveObjectsTest.java[tag=on-demand-nested]
----

<1> Returns a nested object that provides a stream of users.


==== @Timestamped

You can annotate any statement with link:{jdbidocs}/sqlobject/customizer/Timestamped.html[@Timestamped^] to bind an link:{jdkdocs}/java.base/java/time/OffsetDateTime.html[OffsetDateTime^] object representing the current time as `now`:

[source,java,indent=0]
----
public interface Bar {
    @Timestamped // <1>
    @SqlUpdate("INSERT INTO times(val) VALUES(:now)") // <2>
    int insert();
}
----

<1> Bind a timestamp as `now`
<2> Use the timestamp as a named binding.

The binding name can be customized:

[source,java,indent=0]
----
public interface Bar {
    @Timestamped("timestamp")
    @SqlUpdate("INSERT INTO times(val) VALUES(:timestamp)")
    int insert();
}
----

The link:{jdbidocs}/sqlobject/customizer/TimestampedConfig.html[TimestampedConfig^] config object allows setting the timezone for the timestamp.

[reftext="SqlQuery-SingleValue"]
==== @SingleValue

Sometimes, when using advanced SQL features like Arrays, a container type such as
`int[]` or link:{jdkdocs}/java.base/java/util/List.html[List<Integer>^] can ambiguously mean either "a single SQL int[]" or
"a ResultSet of int".

Since arrays are not commonly used in normalized schemas, SQL Object assumes by
default that you are collecting a link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] into a container object. You can
annotate a return type as link:{jdbidocs}/sqlobject/SingleValue.html[@SingleValue^] to override this.

For example, suppose we want to select a `varchar[]` column from a single row:

[source,java,indent=0]
----
public interface UserDao {
    @SqlQuery("SELECT roles FROM users WHERE id = ?")
    @SingleValue
    List<String> getUserRoles(long userId)
}
----

Normally, Jdbi would interpret link:{jdkdocs}/java.base/java/util/List.html[List<String>^] to mean that the mapped type is
`String`, and to collect all result rows into a list. The link:{jdbidocs}/sqlobject/SingleValue.html[@SingleValue^]
annotation causes Jdbi to treat link:{jdkdocs}/java.base/java/util/List.html[List<String>^] as the mapped type instead.

[NOTE]
It's tempting to use the link:{jdbidocs}/sqlobject/SingleValue.html[@SingleValue^] annotation on an link:{jdkdocs}/java.base/java/util/Optional.html[Optional<T>^] type , but usually this is not needed.
link:{jdkdocs}/java.base/java/util/Optional.html[Optional<T>^] is implemented as a container of zero-or-one elements.  Adding link:{jdbidocs}/sqlobject/SingleValue.html[@SingleValue^] implies that the database itself has a column of a type like `optional<varchar>`.


The link:{jdbidocs}/sqlobject/SingleValue.html[@SingleValue^] annotation can also be used on an array, collection or iterable method parameter. This causes SQL Object to bind the whole iterable as the parameter value. This is especially useful for link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^] operations (often for a SQL Array parameter):

[source,java,indent=0]
----
public interface UserDao {
    @SqlBatch("INSERT INTO users (id, name, roles) VALUES (?, ?, ?)")
    void bulkInsert(List<Long> ids,
                    List<String> names,
                    @SingleValue List<String> roles);
}
----

In this example, each new row would get the same `varchar[]` value in the `roles` column.


==== Annotations for Map<K,V> Results

SQL Object methods may return `Map<K,V>` types (see <<mapentry-mapping, Map.Entry mapping>> in
the Core API). In this scenario, each row is mapped to a `Map.Entry<K,V>`,
and the entries for each row are collected into a single link:{jdkdocs}/java.base/java/util/Map.html[Map^] instance.

NOTE: A mapper must be registered for both the key and value types.

Gather master/detail join rows into a map, simply by registering mappers
for the key and value types.

[source,java,indent=0]
----
include::{sqlobjectexampledir}/TestReturningMap.java[tags=joinRow]
----

In the preceding example, the `User` mapper uses the "u" column name prefix, and
the `Phone` mapper uses "p". Since each mapper only reads the column with the
expected prefix, the respective `id` columns are unambiguous.

A unique index (e.g. by ID column) can be obtained by setting the key column
name:

[source,java,indent=0]
----
include::{sqlobjectexampledir}/TestReturningMap.java[tags=uniqueIndex]
----

Set both the key and value column names to gather a two-column query into a map
result:

[source,java,indent=0]
----
include::{sqlobjectexampledir}/TestReturningMap.java[tags=keyValue]
----

All of the above examples assume a one-to-one key/value relationship.

What if there is a one-to-many relationship? <<google-guava,Google Guava>> provides a `Multimap`
type, which supports mapping multiple values per key.

First, follow the instructions in the <<google-guava,Google Guava>> section to install the
link:{jdbidocs}/guava/GuavaPlugin.html[GuavaPlugin^].

Then, simply specify a `Multimap` return type instead of link:{jdkdocs}/java.base/java/util/Map.html[Map^]:

[source,java,indent=0]
----
include::{sqlobjectexampledir}/TestReturningMap.java[tags=joinRowMultimap]
----

All the examples so far have been link:{jdkdocs}/java.base/java/util/Map.html[Map^] types where each row in the result set
is a single `Map.Entry`. However, what if the link:{jdkdocs}/java.base/java/util/Map.html[Map^] we want to return is
actually a single row or even a single column?

Jdbi's link:{jdbidocs}/core/mapper/MapMapper.html[MapMapper^] maps each row to a
`Map<String, Object>`, where column names are mapped to column values.

[NOTE]
Jdbi's default setting is to convert column names to lowercase for Map keys. This behavior can be
changed via the `MapMappers` config class.

By default, SQL Object treats link:{jdkdocs}/java.base/java/util/Map.html[Map^] return types as a collection of `Map.Entry`
values. Use the link:{jdbidocs}/sqlobject/SingleValue.html[@SingleValue^] annotation to override this, so that the return
type is treated as a single value instead of a collection:

[source,java,indent=0]
----
@SqlQuery("SELECT * FROM users WHERE id = ?")
@RegisterRowMapper(MapMapper.class)
@SingleValue
Map<String, Object> getById(long userId);
----

The link:{jdbidocs}/core/mapper/GenericMapMapperFactory.html[GenericMapMapperFactory^],
provides the same feature but allows value types other than `Object` as long as a suitable ColumnMapper
is registered and all columns are of the same type:

[source,java,indent=0]
----
@SqlQuery("SELECT 1.0 AS LOW, 2.0 AS MEDIUM, 3.0 AS HIGH")
@RegisterRowMapperFactory(GenericMapMapperFactory.class)
@SingleValue
Map<String, BigDecimal> getNumericLevels();
----

[TIP]
The <<PostgreSQL>> plugin provides an `hstore` to `Map<String, String>` column mapper. See <<postgres-hstore,hstore>> for more information.


==== @UseRowReducer

link:{jdbidocs}/sqlobject/statement/SqlQuery.html[@SqlQuery^] methods that use join queries may reduce master-detail joins
into one or more master-level objects. See <<ResultBearing.reduceRows()>> for
an introduction to row reducers.

Consider a filesystem metaphor with folders and documents. In the join, we'll
prefix folder columns with `f_` and document columns with `d_`.

[source,java,indent=0]
----
@RegisterBeanMapper(value = Folder.class, prefix = "f") // <1>
@RegisterBeanMapper(value = Document.class, prefix = "d")
public interface DocumentDao {
    @SqlQuery("SELECT " +
        "f.id f_id, f.name f_name, " +
        "d.id d_id, d.name d_name, d.contents d_contents " +
        "FROM folders f LEFT JOIN documents d " +
        "ON f.id = d.folder_id " +
        "WHERE f.id = :folderId" +
        "ORDER BY d.name")
    @UseRowReducer(FolderDocReducer.class) // <2>
    Optional<Folder> getFolder(int folderId); // <3>

    @SqlQuery("SELECT " +
        "f.id f_id, f.name f_name, " +
        "d.id d_id, d.name d_name, d.contents d_contents " +
        "FROM folders f LEFT JOIN documents d " +
        "ON f.id = d.folder_id " +
        "ORDER BY f.name, d.name")
    @UseRowReducer(FolderDocReducer.class) // <2>
    List<Folder> listFolders(); // <3>

    class FolderDocReducer implements LinkedHashMapRowReducer<Integer, Folder> { // <4>
        @Override
        public void accumulate(Map<Integer, Folder> map, RowView rowView) {
            Folder f = map.computeIfAbsent(rowView.getColumn("f_id", Integer.class), // <5>
                id -> rowView.getRow(Folder.class));

            if (rowView.getColumn("d_id", Integer.class) != null) { // <6>
                f.getDocuments().add(rowView.getRow(Document.class));
            }
        }
    }
}
----
<1> In this example, we register the folder and document mappers with a
    prefix, so that each mapper only looks at the columns with that prefix.
    These mappers are used indirectly by the row reducer in the
    `getRow(Folder.class)` and `getRow(Document.class)` calls.
<2> Annotate the method with `@UseRowReducer`, and specify the `RowReducer`
    implementation class.
<3> The same `RowReducer` implementation may be used for both single- and
    multi-master-record queries.
<4> link:{jdbidocs}/core/result/LinkedHashMapRowReducer.html[LinkedHashMapRowReducer^]
    is an abstract `RowReducer` implementation that uses a `LinkedHashMap` as the result
    container, and returns the `values()` collection as the result.
<5> Get the `Folder` for this row from the map by ID, or create it if not in the map.
<6> Confirm this row has a document (this _is_ a left join) before mapping a document
    and adding it to the folder.

==== @RegisterCollector and @RegisterCollectorFactory

Convenience annotations to register a link:{jdkdocs}/java.base/java/util/stream/Collector.html[Collector^] for a SqlObject method.

link:{jdbidocs}/sqlobject/config/RegisterCollectorFactory.html[@RegisterCollectorFactory^] allows registration of a factory that returns a collector instance and link:{jdbidocs}/sqlobject/config/RegisterCollector.html[@RegisterCollector^] registers a collector implementation:

[source,java,indent=0]
----
public interface RegisterCollectorDao {
    @RegisterCollector(StringConcatCollector.class)
    @SqlQuery("select i from i order by i asc")
    String selectWithCollector();

    @RegisterCollectorFactory(StringConcatCollectorFactory.class)
    @SqlQuery("select i from i order by i asc")
    String selectWithCollectorFactory();
}

class StringConcatCollectorFactory implements CollectorFactory {

    @Override
    public boolean accepts(Type containerType) {
        return containerType == String.class;
    }

    @Override
    public Optional<Type> elementType(Type containerType) {
        return Optional.of(Integer.class);
    }

    @Override
    public Collector<Integer, List<Integer>, String> build(Type containerType) {
        return Collector.of(
            ArrayList::new,
            List::add,
            (x, y) -> {
                x.addAll(y);
                return x;
            },
            i -> i.stream().map(Object::toString).collect(Collectors.joining(" ")));
    }
}

class StringConcatCollector implements Collector<Integer, List<Integer>, String> {
    @Override
    public Supplier<List<Integer>> supplier() {
        return ArrayList::new;
    }

    @Override
    public BiConsumer<List<Integer>, Integer> accumulator() {
        return List::add;
    }

    @Override
    public BinaryOperator<List<Integer>> combiner() {
        return (a, b) -> {
            a.addAll(b);
            return a;
        };
    }

    @Override
    public Function<List<Integer>, String> finisher() {
        return i -> i.stream().map(Object::toString).collect(Collectors.joining(" "));
    }

    @Override
    public Set<Characteristics> characteristics() {
        return Collections.emptySet();
    }
}
----

The element and result types are inferred from the concrete link:{jdkdocs}/java.base/java/util/stream/Collector.html[Collector<Element, ?, Result>^] implementation's type parameters. See <<Collectors>> for more details.



==== Other SQL Object annotations

Jdbi provides many additional annotations out of the box:

* link:{jdbidocs}/sqlobject/config/package-summary.html[org.jdbi.v3.sqlobject.config^]
  provides annotations for things that can be configured at the link:{jdbidocs}/core/Jdbi.html[Jdbi^] or
 link:{jdbidocs}/core/Handle.html[Handle^] level. This includes registration of mappers and arguments, and for
  configuring SQL statement rendering and parsing.
* link:{jdbidocs}/sqlobject/customizer/package-summary.html[org.jdbi.v3.sqlobject.customizer^]
  provides annotations for binding parameters, defining attributes, and
  controlling the fetch behavior of the statement's result set.
* link:{jdbidocs}/jpa/package-summary.html[org.jdbi.v3.jpa^]
  provides the link:{jdbidocs}/jpa/BindJpa.html[@BindJpa^] annotation, for binding properties to column according
  to JPA `@Column` annotations.
* link:{jdbidocs}/sqlobject/locator/package-summary.html[org.jdbi.v3.sqlobject.locator^]
  provides annotations that configure Jdbi to load SQL statements from an
  alternative source, e.g. a file on the classpath.
* link:{jdbidocs}/sqlobject/statement/package-summary.html[org.jdbi.v3.sqlobject.statement^]
  provides the link:{jdbidocs}/sqlobject/statement/MapTo.html[@MapTo^] annotation, which is used for dynamically specifying the
  mapped type at the time the method is invoked.
* link:{jdbidocs}/stringtemplate4/package-summary.html[org.jdbi.v3.stringtemplate4^]
  provides annotations that configure Jdbi to load SQL from StringTemplate 4
  `.stg` files on the classpath, and/or to parse SQL templates using the
  ST4 template engine.
* link:{jdbidocs}/sqlobject/transaction/package-summary.html[org.jdbi.v3.sqlobject.transaction^]
  provides annotations for transaction management in a SQL object. See
  <<SQL Object Transactions>> for details.

The SQL Object framework is built on top of the <<extension-framework, Jdbi Extension framework>> which can be extended with user-defined annotations. See the
<<extension-framework-annotations, extension framework annotation documentation>> for an overview on how to build your own annotations.


==== Annotations and Inheritance

SQL Objects inherit methods and annotations from the interfaces they extend:

[source,java,indent=0]
----
package com.app.dao;

@UseClasspathSqlLocator // <1> <2>
public interface CrudDao<T, ID> {
    @SqlUpdate // <3>
    void insert(@BindBean T entity);

    @SqlQuery // <3>
    Optional<T> findById(ID id);

    @SqlQuery
    List<T> list();

    @SqlUpdate
    void update(@BindBean T entity);

    @SqlUpdate
    void deleteById(ID id);
}
----
<1> See <<#sqllocator, @SqlLocator>>.
<2> Class annotations are inherited by subtypes.
<3> Method and parameter annotations are inherited by subtypes, unless the
    subtype overrides the method.

[source,java,indent=0]
----
package com.app.contact;

@RegisterBeanMapper(Contact.class)
public interface ContactDao extends CrudDao<Contact, Long> {}
----

[source,java,indent=0]
----
package com.app.account;

@RegisterConstructorMapper(Account.class)
public interface AccountDao extends CrudDao<Account, UUID> {}
----

In this example we're using the link:{jdbidocs}/sqlobject/locator/UseClasspathSqlLocator.html[@UseClasspathSqlLocator^] annotation, so each
method will use SQL loaded from the classpath. Thus, `ContactDao` methods will
use SQL from:

* `/com/app/contact/ContactDao/insert.sql`
* `/com/app/contact/ContactDao/findById.sql`
* `/com/app/contact/ContactDao/list.sql`
* `/com/app/contact/ContactDao/update.sql`
* `/com/app/contact/ContactDao/deleteById.sql`

Whereas `AccountDao` will use SQL from:

* `/com/app/account/AccountDao/insert.sql`
* `/com/app/account/AccountDao/findById.sql`
* `/com/app/account/AccountDao/list.sql`
* `/com/app/account/AccountDao/update.sql`
* `/com/app/account/AccountDao/deleteById.sql`

Suppose `Account` used `name()`-style accessors instead of `getName()`. In that
case, we'd want `AccountDao` to use link:{jdbidocs}/sqlobject/customizer/BindMethods.html[@BindMethods^] instead of link:{jdbidocs}/sqlobject/customizer/BindBean.html[@BindBean^].

Let's override those methods with the right annotations:

[source,java,indent=0]
----
package com.app.account;

@RegisterConstructorMapper(Account.class)
public interface AccountDao extends CrudDao<Account, UUID> {
    @Override
    @SqlUpdate // <1>
    void insert(@BindMethods Account entity);

    @Override
    @SqlUpdate // <1>
    void update(@BindMethods Account entity);
}
----
<1> Method annotations are not inherited on override, so we must duplicate
    those we want to keep.


=== Combining SQL Object and the core API

The SQL Object extension uses the same core API as programmatic SQL operations. There is an underlying link:{jdbidocs}/core/Handle.html[Handle^] object that is used to execute the SQL methods.

A SQL Object type can extend the link:{jdbidocs}/sqlobject/SqlObject.html[SqlObject^] mixin interface to get access to the handle. It also exposes a number of operations that can be used to mix declarative SQL Object methods with programmatic core API code:

[source,java,indent=0]
----
public interface SomeDao extends SqlObject {
    // ...
}

void mixedCode() {
    SomeDao dao = jdbi.onDemand(SomeDao.class);

    dao.withHandle(handle -> {
        handle.createQuery("SELECT * from users").mapTo(User.class).list();
    })
}
----

This interface gives access to the handle and offers link:{jdbidocs}/sqlobject/SqlObject.html#withHandle(org.jdbi.v3.core.HandleCallback)[SqlObject#withHandle()^] and
link:{jdbidocs}/sqlobject/SqlObject.html#useHandle(org.jdbi.v3.core.HandleConsumer)[SqlObject#useHandle()^] methods that execute callback code using the same handle object as the methods on the SQL object interface itself.

[NOTE]
This is most useful for SQL object instances that get passed from other code, have been created from
link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^] or use default methods. Any object that was created using the
link:{jdbidocs}/core/Handle.html#attach(java.lang.Class)[Handle#attach()^] method will return the handle it was attached to.

[#sqlobject-mixin]
==== Getting access to the handle with the `SqlObject` mixin

Occasionally a use case comes up where SQL Method annotations don't fit. In these situations, it is possible to "drop down" to the Core API using interface
`default` methods and the link:{jdbidocs}/sqlobject/SqlObject.html[SqlObject^] mixin interface:

[source,java,indent=0]
----
public interface SplineDao extends SqlObject {
    default void reticulateSplines(Spline spline) {
        Handle handle = getHandle();
        // do tricky stuff using the Core API
    }
}
----

The link:{jdbidocs}/core/Handle.html[Handle^] can be used for most operations available in the fluent API.

A handle should only be obtained in this way for very specific reasons, and it is a good practice to restrain the use of the handle to code within a Dao class (e.g. a default method). If fluent code and declarative code needs to be mixed, moving from fluent to declarative should be preferred.

[WARNING]
A very notable exception is modifying the configuration of the handle. When a SQL object is created, every method on the SQL object gets its own, distinct configuration object. Calling any configuration modification method (any `set*` or `register*` method from the link:{jdbidocs}/core/config/Configurable.html[Configurable^] interface) will modify *only* the configuration object for the link:{jdbidocs}/sqlobject/SqlObject.html#getHandle()[getHandle()^] method but not for any other method.


The following code example *DOES NOT WORK!*
[source,java,indent=0]
----
@Test
public void testSqlObjectHandleConfigDoesNotWork() {
    List<Sulu> sulus = Arrays.asList(
        new Sulu(1, "George", "Takei"),
        new Sulu(2, "John", "Cho"));

    db.useExtension(SuluDao.class, s -> {
        Handle h = s.getHandle();
        // THIS DOES NOT WORK! The argument factory is only
        // registered for the getHandle() method, not
        // for the insertSulus() method!
        h.registerArgument(new SuluArgumentFactory());
        // This call results in an exception that no argument
        // factory for the Sulu data type could be found!
        dao.insertSulus(sulus);
    }
}

public interface SuluDao extends SqlObject {
    @SqlBatch("insert into something (id, name) values (:bean.id, :sulu)")
    void insertSulus(@Bind("sulu") @BindBean("bean") List<Sulu> sulus);
}
----

The code above can be rewritten to move from fluent to declarative API:

[source,java,indent=0]
----
public void testMixFluentAndSqlObject() {
    List<Sulu> sulus = Arrays.asList(
        new Sulu(1, "George", "Takei"),
        new Sulu(2, "John", "Cho"));

    db.withHandle(h -> {
        // register the argument with the handle before attaching
        // the dao to the handle
        h.registerArgument(new SuluArgumentFactory());
        SuluDao dao = h.attach(SuluDao.class);
        // all methods on the dao have received the configuration with the
        // argument factory
        dao.insertSulus(sulus);
        return null;
    });
}
----

==== Using default Methods

Default methods can be used to group multiple SQL operations into a single method call:

[source,java,indent=0]
----
public interface ContactPhoneDao {
    @SqlUpdate("INSERT INTO contacts (id, name) VALUES (nextval('contact_id'), :name)")
    long insertContact(@BindBean Contact contact);

    @SqlBatch("INSERT INTO phones (contact_id, type, phone) VALUES (:contactId, :type, :phone)")
    void insertPhone(long contactId, @BindBean Iterable<Phone> phones);

    default long insertFullContact(Contact contact) {
        long id = insertContact(contact);
        insertPhone(id, contact.getPhones());
        return id;
    }
}
----


=== SQL Object Transactions

Methods on a SQL object can have a link:{jdbidocs}/sqlobject/transaction/Transaction.html[@Transaction^] annotation:

[source,java,indent=0]
----
include::{exampledir}/TransactionTest.java[tags=sqlObjectTransaction]
----

SQL methods with a link:{jdbidocs}/sqlobject/transaction/Transaction.html[@Transaction^] annotation may optionally specify a
transaction isolation level:

[source,java,indent=0]
----
include::{exampledir}/TransactionTest.java[tags=sqlObjectTransactionIsolation]
----

Similar to the link:{jdbidocs}/core/Jdbi.html#inTransaction(org.jdbi.v3.core.HandleCallback)[Jdbi#inTransaction()^] and link:{jdbidocs}/core/Jdbi.html#useTransaction(org.jdbi.v3.core.HandleConsumer)[Jdbi#useTransaction()^] operations in the core API, transactions are not nested. If a method, that has been annotated with link:{jdbidocs}/sqlobject/transaction/Transaction.html[@Transaction^], calls another method that is annotated as well (e.g. through an _interface default method_), then the same transaction will be reused, and it will be committed when the outer transaction ends.

Nested method calls must either use the same transaction isolation level or inner methods must not specify any transaction level. In that case, the transaction level of the outer transaction maintained.

[source,java,indent=0]
----
include::{exampledir}/TransactionTest.java[tags=sqlObjectNestedTransaction]
----


==== Executing multiple SQL operations in a single transaction

A SQL object method uses its own transaction. Multiple method calls can be grouped together to use a shared transaction:

For an existing handle, attach the SQL object inside the transaction:

[source,java,indent=0]
----
public interface UserDao {
    @Transaction
    @SqlUpdate("INSERT INTO users VALUES (:id, :name)")
    void createUser(int id, String name);
}

public void createUsers(Handle handle) {
    handle.useTransaction(transactionHandle -> {
        UserDao dao = transactionHandle.attach(UserDao.class);

        // both inserts happen in the same transaction
        dao.createUser(1, "Alice");
        dao.createUser(2, "Bob");
    }
}
----

As an alternative, the link:{jdbidocs}/sqlobject/transaction/Transactional.html[Transactional^] mixin interface can be used to provide transaction support on a SQL object.

Similar to the link:{jdbidocs}/sqlobject/SqlObject.html[SqlObject^] interface, it gives access to all transaction related methods on the Handle and offers the same callbacks as the Handle itself.

With this mixin interface, the link:{jdbidocs}/sqlobject/transaction/Transactional.html#useTransaction(org.jdbi.v3.sqlobject.transaction.TransactionalConsumer)[Transactional#useTransaction()^] and link:{jdbidocs}/sqlobject/transaction/Transactional.html#inTransaction(org.jdbi.v3.sqlobject.transaction.TransactionalCallback)[Transactional#inTransaction()^] methods group statements into a single transaction by using a callback:

[source,java,indent=0]
----
public interface UserDao extends Transactional<UserDao> {
    @Transaction
    @SqlUpdate("INSERT INTO users VALUES (:id, :name)")
    void createUser(int id, String name);
}

public void createUsers(Jdbi jdbi) {
    UserDao dao = jdbi.onDemand(UserDao.class);

    dao.useTransaction(transactionDao -> {
        // both inserts happen in the same transaction
        transactionDao.createUser(1, "Alice");
        transactionDao.createUser(2, "Bob");
    });
}
----

Nested calls can be used as well:
[source,java,indent=0]
----
public interface UserDao extends Transactional<UserDao> {
    @Transaction
    @SqlUpdate("INSERT INTO users VALUES (:id, :name)")
    void createUser(int id, String name);
}

public void createUsers(Jdbi jdbi) {
    UserDao dao = jdbi.onDemand(UserDao.class);

    dao.useTransaction(transactionDao1 -> {
        // both inserts happen in the same transaction
        transactionDao1.createUser(1, "Alice");

        transactionDao1.useTransaction(transactionDao2 -> {
            transactionDao2.createUser(2, "Bob");
        });
    });
}
----

SQL object calls and core API calls can be mixed:
[source,java,indent=0]
----
public interface UserDao extends Transactional<UserDao> {
    @Transaction
    @SqlUpdate("INSERT INTO users VALUES (:id, :name)")
    void createUser(int id, String name);
}

public void createUsers(Jdbi jdbi) {
    UserDao dao = jdbi.onDemand(UserDao.class);

    dao.useTransaction(transactionDao -> {
        // inserts happen in the same transaction
        transactionDao.createUser(1, "Alice");
        transactionDao.createUser(2, "Bob");

        // this insert as well
        transactionDao.getHandle().useTransaction(transactionHandle ->
            transactionHandle.createUpdate("USERT INTO users VALUES (:id, :name)")
                .bind("id", 3)
                .bind("name", "Charlie")
                .execute();
        }
    }
}
----

[NOTE]
The link:{jdbidocs}/sqlobject/transaction/Transactional.html[Transactional^] interface  has the same constraints as the <<sqlobject-mixin, SQLObject>> mixin. Especially modifying the configuration by obtaining a handle using link:{jdbidocs}/sqlobject/SqlObject.html#getHandle()[getHandle()^] and then calling any `set*` or `register*` method from the link:{jdbidocs}/core/config/Configurable.html[Configurable^] interface is not supported and will modify only the configuration for the link:{jdbidocs}/sqlobject/SqlObject.html#getHandle()[getHandle()^] method.


== Miscellaneous


=== Generated Keys

An Update or PreparedBatch may automatically generate keys. These keys
are treated separately from normal results. Depending on your database and
configuration, the entire inserted row may be available.

[CAUTION]
There is a lot of variation between databases supporting
this feature so please test this feature's interaction with your database
thoroughly.

In PostgreSQL, the entire row is available, so you can immediately map your
inserted names back to full User objects!  This avoids the overhead of
separately querying after the insert completes.

Consider the following table:

[source,java,indent=0]
----
include::{exampledir}/GeneratedKeysTest.java[tags=setup]
----

You can get generated keys in the fluent style:

[source,java,indent=0]
----
include::{exampledir}/GeneratedKeysTest.java[tags=fluent]
----


=== Qualified Types

Sometimes the same Java object can correspond to multiple data types in a database. For example,
a `String` could be `varchar` plaintext, `nvarchar` text, `json` data, etc., all with different handling requirements.

link:{jdbidocs}/core/qualifier/QualifiedType.html[QualifiedType^] allows you to add such context to a Java type:

[source,java,indent=0]
----
QualifiedType.of(String.class).with(Json.class);
----

This `QualifiedType` still represents the `String` _type_, but _qualified_ with the link:{jdbidocs}/json/Json.html[@Json^] annotation.
It can be used in a way similar to <<GenericType>>, to make components
handling values (mainly `ArgumentFactories` and `ColumnMapperFactories`) perform their work differently,
and to have the values handled by different implementations altogether:

[source,java,indent=0]
----
@Json
public class JsonArgumentFactory extends AbstractArgumentFactory<String> {
    @Override
    protected Argument build(String value, ConfigRegistry config) {
        // do something specifically for json data
    }
}
----

Once registered, this link:{jdbidocs}/json/Json.html[@Json^] qualified factory will receive *only* `@Json String` values.
Other factories _not_ qualified as such will *not* receive this value:

[source,java,indent=0]
----
QualifiedType<String> json = QualifiedType.of(String.class).with(Json.class);
query.bindByType("jsonValue", "{\"foo\":1}", json);
----

[TIP]
Jdbi chooses factories to handle values by *exactly matching* their _qualifiers_. It's up to the
factory implementations to discriminate on the _type_ of the value afterward.

[NOTE]
Qualifiers are implemented as `Annotations`. This allows factories to independently inspect values for qualifiers at the source,
such as on their `Class`, to alter their own behavior or to _requalify_ a value
and have it re-evaluated by Jdbi's lookup chain.

[WARNING]
Qualifiers being annotations does *not* mean they inherently activate
their function when placed in source classes. Each feature decides its own
rules regarding their use.

[CAUTION]
Arguments can only be qualified for binding via `bindByType` calls, not regular
`bind` or `update.execute(Object\...)`. Also, arrays cannot be qualified.

These features currently make use of qualified types:

- `@NVarchar` and `@MacAddr` (the latter in `jdbi3-postgres`) bind and map Strings as `nvarchar` and `macaddr`
respectively, instead of the usual `varchar`.
- `jdbi3-postgres` offers <<postgres-hstore,HStore>>.
- <<jdbi3-json,JSON>>
- `BeanMapper`, link:{jdbidocs}/sqlobject/customizer/BindBean.html[@BindBean^], link:{jdbidocs}/sqlobject/config/RegisterBeanMapper.html[@RegisterBeanMapper^], `mapTobean()`, and `bindBean()` respect qualifiers on getters, setters,
and setter parameters.
- `ConstructorMapper` and link:{jdbidocs}/sqlobject/config/RegisterConstructorMapper.html[@RegisterConstructorMapper^] respect qualifiers on constructor parameters.
- link:{jdbidocs}/sqlobject/customizer/BindMethods.html[@BindMethods^] and `bindMethods()` respect qualifiers on methods.
- link:{jdbidocs}/sqlobject/customizer/BindFields.html[@BindFields^], link:{jdbidocs}/sqlobject/config/RegisterFieldMapper.html[@RegisterFieldMapper^], `FieldMapper` and `bindFields()` respect qualifiers on fields.
- `SqlObject` respects qualifiers on methods (applies them to the return type) and parameters.
* on parameters of type link:{jdkdocs}/java.base/java/util/function/Consumer.html[Consumer<T>^], qualifiers are applied to the `T`.
- link:{jdbidocs}/sqlobject/statement/MapTo.html[@MapTo^]
- link:{jdbidocs}/jpa/BindJpa.html[@BindJpa^] and `JpaMapper` respect qualifiers on getters and setters.
- `@BindKotlin`, `bindKotlin()`, and `KotlinMapper` respect qualifiers on constructor parameters, getters, setters, and setter parameters.

[#query-templating]
=== Query Templating

Binding query parameters, as described above, is excellent for sending a static set of parameters to the database engine.  Binding ensures that the parameterized query string (`\... where foo = ?`) is transmitted to the database without allowing hostile parameter values to inject SQL.

Bound parameters are not always enough. Sometimes a query needs complicated or structural changes before being executed, and parameters just don't cut it. Templating (using a link:{jdbidocs}/core/statement/TemplateEngine.html[TemplateEngine^]) allows you to alter a query's content with general String manipulations.

Typical uses for templating are optional or repeating segments (conditions and loops), complex variables such as comma-separated lists for IN clauses, and variable substitution for non-bindable SQL elements (like table names). Unlike _argument binding_, the _rendering_ of _attributes_ performed by TemplateEngines is *not* SQL-aware. Since they perform generic String manipulations, TemplateEngines can easily produce horribly mangled or subtly defective queries if you don't use them carefully.

[CAUTION]
https://www.xkcd.com/327/[Query templating is a common attack vector!^] Always prefer binding parameters to static SQL over dynamic SQL when possible.

[source,java,indent=0]
----
handle.createQuery("SELECT * FROM <TABLE> WHERE name = :n")

    // -> "SELECT * FROM Person WHERE name = :n"
    .define("TABLE", "Person")

    // -> "SELECT * FROM Person WHERE name = 'MyName'"
    .bind("n", "MyName");
----

[TIP]
Use a TemplateEngine to perform crude String manipulations on a query. Query parameters should be handled by Arguments.

[CAUTION]
TemplateEngines and SqlParsers operate sequentially: the initial String will be rendered by the TemplateEngine using attributes, then parsed by the SqlParser with Argument bindings.

If the TemplateEngine outputs text matching the parameter format of the SqlParser, the parser will attempt to bind an Argument to it. This can be useful to e.g. have named parameters of which the name itself is also a variable, but can also cause confusing bugs:

[source,java,indent=0]
----
String paramName = "arg";

handle.createQuery("SELECT * FROM Foo WHERE bar = :<attr>")
    .define("attr", paramName)
    // ...
    .bind(paramName, "baz"); // <- does not need to know the parameter's name ("arg")!
----

[source,java,indent=0]
----
handle.createQuery("SELECT * FROM emotion WHERE emoticon = <sticker>")
    .define("sticker", ":-)") // -> "... WHERE emoticon = :-)"
    .mapToMap()
    // exception: no binding/argument named "-)" present
    .list();
----

Bindings and definitions are usually separate.  You can link them in a limited manner
using the `stmt.defineNamedBindings()` or `@DefineNamedBindings` customizers.
For each bound parameter (including bean properties), this will define a boolean which is `true` if the
binding is present and not `null`.  You can use this to
craft conditional updates and query clauses.

For example,
[source,java,indent=0]
----
class MyBean {
    long id();
    String getA();
    String getB();
    Instant getModified();
}

handle.createUpdate("UPDATE mybeans SET <if(a)>a = :a,<endif> <if(b)>b = :b,<endif> modified=now() WHERE id=:id")
    .bindBean(mybean)
    .defineNamedBindings()
    .execute();
----

Also see the section about <<TemplateEngine>>.


==== ClasspathSqlLocator

You may find it helpful to store your SQL templates in individual files on the
classpath, rather than in string inside Java code.

The `ClasspathSqlLocator` converts Java type and method names into classpath locations,
and then reads, parses, and caches the loaded statements.

[source,java,indent=0]
----
// reads classpath resource com/foo/BarDao/query.sql
ClasspathSqlLocator.create().locate(com.foo.BarDao.class, "query");

// same resource as above
ClasspathSqlLocator.create().locate("com.foo.BarDao.query");
----

By default, any comments in the loaded file are left untouched. Comments can be stripped out by
instantiating the `ClasspathSqlLocator` with the `removingComments()` method:

[source,java,indent=0]
----
// reads classpath resource com/foo/BarDao/query.sql, stripping all comments
ClasspathSqlLocator.removingComments().locate(com.foo.BarDao.class, "query");

// same resource as above
ClasspathSqlLocator.removingComments().locate("com.foo.BarDao.query");
----

Multiple comment styles are supported:

* C-style (`/* \... */` and `//` to the end of the line)
* SQL style (`--` to the end of the line)
* shell style (`\#` to the end of the line; except when followed immediately by the `>` character; this is required for the Postgres `#>` and `#>>` operators).


Each piece of core or extension that wishes to participate in
configuration defines a configuration class, for example the `SqlStatements`
class stores SqlStatement related configuration.  Then, on any link:{jdbidocs}/core/config/Configurable.html[Configurable^] context
(like a link:{jdbidocs}/core/Jdbi.html[Jdbi^] or link:{jdbidocs}/core/Handle.html[Handle^]) you can change configuration in a type safe way:

[source,java,indent=0]
----
jdbi.getConfig(SqlStatements.class).setUnusedBindingAllowed(true);
jdbi.getConfig(Arguments.class).register(new MyTypeArgumentFactory());
jdbi.getConfig(Handles.class).setForceEndTransactions(true);

// Or, if you have a bunch of work to do:
jdbi.configure(RowMappers.class, rm -> {
    rm.register(new TypeARowMapperFactory();
    rm.register(new TypeBRowMapperFactory();
});
----


=== Statement caching

Jdbi caches statement information in multiple places:

- preparsed SQL where placeholders have been replaced.
- rendered statement templates if the template engine supports it.

Caching can dramatically speed up the execution of statements. By default, Jdbi uses a simple LRU in-memory cache with 1,000 entries. This cache is sufficient for most use cases.

For applications than run a lot of different SQL operations, it is possible to use different cache implementations. Jdbi provides link:{jdbidocs}/core/cache/package-summary.html[a cache SPI^] for this.

The following cache implementations are included:

- `jdbi3-caffeine-cache` - using the https://github.com/ben-manes/caffeine[Caffeine^] cache library. This used to be the default cache up to version 3.36.0
- `jdbi3-noop-cache`, - disables caching. This is useful for testing and debugging.

A cache module can provide a plugin to enable it. Only one plugin can be in use at a time (last one installed wins):

[source,java,indent=0]
----
    // use the caffeine cache library
    jdbi.installPlugin(new CaffeineCachePlugin());
----

==== Using custom cache instances

The default cache instances are installed when the Jdbi object is created. When using a cache plugin, the implementation is changed but only very few aspects of the cache can be modified.

Full customization is possible by creating the cache outside Jdbi and then use a cache builder adapter:

[source,java,indent=0]
----
    // create a custom Caffeine cache
    JdbiCacheBuilder customCacheBuilder = new CaffeineCacheBuilder(
        Caffeine.newBuilder()
            .maximumSize(100_000)
            .expireAfterWrite(10, TimeUnit.MINUTES)
            .recordStats());

    SqlStatements config = jdbi.getConfig(SqlStatements.class);
    config.setTemplateCache(customCacheBuilder));
    config.setSqlParser(new ColonPrefixSqlParser(customCacheBuilder));
----

When setting the caches explicitly, no cache plugin needs to be installed.


[TIP]
If the underlying cache library exposes per-cache statistics, these can be accessed through the link:{jdbidocs}//core/statement/SqlStatements.html#cacheStats()[SqlStatements#cacheStats()^] and https://{jdbidocs}/core/statement/CachingSqlParser.html#cacheStats()[CachingSqlParser#cacheStats()^] methods.


== Testing

[NOTE]
The official test support from Jdbi is in the `jdbi-testing` package. There are a number of additional JUnit 5 extensions in the `jdbi-core` test artifact. These are only intended for Jdbi internal use and not part of the official, public API.


=== JUnit 4

The `jdbi3-testing` artifact provides link:{jdbidocs}/testing/JdbiRule.html[JdbiRule^]
class which implements https://junit.org/junit4/javadoc/latest/org/junit/rules/TestRule.html[TestRule^] and can be used with the https://junit.org/junit4/javadoc/latest/org/junit/Rule.html[Rule^] and https://junit.org/junit4/javadoc/latest/org/junit/ClassRule.html[ClassRule^] annotations.

It provides helpers for writing JUnit 4 tests integrated with a managed database instance. This makes writing unit tests quick and easy!  You must remember to include the database dependency itself, for example to get a pure H2 Java database:

[source,xml,indent=0]
----
<dependency>
    <groupId>com.h2database</groupId>
    <artifactId>h2</artifactId>
    <version>2.1.212</version>
    <scope>test</scope>
</dependency>
----

JUnit 4 supports the OTJ embedded postgres component, which needs to be included when using Postgres:

[source,xml,indent=0]
----
<dependency>
    <groupId>com.opentable.components</groupId>
    <artifactId>otj-pg-embedded</artifactId>
    <version>1.0.1</version>
    <scope>test</scope>
</dependency>
----


=== JUnit 5

The `jdbi3-testing` artifact provides link:{jdbidocs}/testing/junit5/JdbiExtension.html[JdbiExtension^] for JUnit 5 based tests.

It supports both the https://junit.org/junit5/docs/current/api/org.junit.jupiter.api/org/junit/jupiter/api/extension/RegisterExtension.html[@RegisterExtension^] and https://junit.org/junit5/docs/current/api/org.junit.jupiter.api/org/junit/jupiter/api/extension/ExtendWith.html[@ExtendWith^] annotations.

When using https://junit.org/junit5/docs/current/api/org.junit.jupiter.api/org/junit/jupiter/api/extension/RegisterExtension.html[@RegisterExtension^], the extensions can be customized further:

[source,java,indent=0]
----
public class Test {
    @RegisterExtension
    public JdbiExtension h2Extension = JdbiExtension.h2()
        withPlugin(new SqlObjectPlugin());

    @Test
    public void testWithJunit5() {
        Jdbi jdbi = h2Extension.getJdbi();
        Handle handle = h2Extension.openHandle();
        // ...
    }
}
----

The link:{jdbidocs}/testing/junit5/JdbiExtension.html[JdbiExtension^] and all its database specific subclasses can be registered as instance fields or as class-level (static) fields.

When registered as an instance field, each test will get a new Jdbi instance. The in-memory database specific subclasses (H2, SQLite or HsqlDB with the generic extension) will reset their content and provide a new instance.

When registered as a static field, the extension will be initialized before all test methods are executed. All tests share the same extension instance and its associated fields. The in-memory database specific subclasses will retain their contents across multiple tests.

The javadoc page for link:{jdbidocs}/testing/junit5/JdbiExtension.html[JdbiExtension^] contains additional information on how to customize a programmatically registered instance.

When using the https://junit.org/junit5/docs/current/api/org.junit.jupiter.api/org/junit/jupiter/api/extension/ExtendWith.html[@ExtendWith^] declarative extension, test methods can access the link:{jdbidocs}/core/Jdbi.html[Jdbi^] and link:{jdbidocs}/core/Handle.html[Handle^] objects through method parameters:

[source,java,indent=0]
----
@ExtendWith(JdbiH2Extension.class)
public class Test {
    @Test
    public void testWithJunit5(Jdbi jdbi, Handle handle) {
        // ...
    }
}
----

The instances injected are the same instances as returned by link:{jdbidocs}/testing/junit5/JdbiExtension.html#getJdbi()[getJdbi()^] and link:{jdbidocs}/testing/junit5/JdbiExtension.html#getSharedHandle()[getSharedHandle()^].


Currently supported databases:

* https://www.postgresql.org/[Postgres^] - link:{jdbidocs}/testing/junit5/JdbiPostgresExtension.html[JdbiPostgresExtension^], link:{jdbidocs}/testing/junit5/JdbiExternalPostgresExtension.html[JdbiExternalPostgresExtension^], link:{jdbidocs}/testing/junit5/JdbiOtjPostgresExtension.html[JdbiOtjPostgresExtension^]
* https://www.h2database.com/[H2^] - link:{jdbidocs}/testing/junit5/JdbiH2Extension.html[JdbiH2Extension^]
* https://www.sqlite.org/[Sqlite^] - link:{jdbidocs}/testing/junit5/JdbiSqliteExtension.html[JdbiSqliteExtension^]
* Generic JDBC database support - link:{jdbidocs}/testing/junit5/JdbiGenericExtension.html[JdbiGenericExtension^]. This is a minimal extension that can support any database that support JDBC. The driver for the database must be on the classpath. All database management (schema creation, DDL object management etc.) must be done by the calling code.
* https://testcontainers.org/[Testcontainers^] - link:{jdbidocs}/testing/junit5/tc/JdbiTestcontainersExtension.html[JdbiTestcontainersExtension^]. See <<Using Testcontainers>> for detailed documentation.

Support for other databases wanted!

The link:{jdbidocs}/testing/junit5/JdbiExtension.html[JdbiExtension^] provides a number of convenience methods:

[source,java,indent=0]
----
public class JdbiExtension {
    public JdbiExtension postgres(...) // new JdbiPostgresExtension(...)

    public JdbiExtension externalPostgres(...) // new JdbiExternalPostgresExtension(...)

    public JdbiExtension otjEmbeddedPostgres() // new JdbiOtjPostgresExtension()

    public JdbiExtension h2() // new JdbiH2Extension()

    public JdbiExtension sqlite() // new JdbiSqliteExtension()
}
----

Additional functionality may be available by using the database specific implementation classes directly. For most common use cases, the convenience methods should suffice.


==== Testing with H2

The H2 database is one of the most popular choices for embedded testing. The link:{jdbidocs}/testing/junit5/JdbiH2Extension.html[JdbiH2Extension^] class allows for a few additional customizations:

[source,java,indent=0]
----
// JdbiH2Extension(String) constructor allows H2 options
// JDBC URL is jdbc:h2:mem:<UUID>;MODE=MySQL
JdbiH2Extension extension = new JdbiH2Extension("MODE=MySQL");

// set H2 user
extension.withUser("h2-user");

// set H2 user and password
extension.withCredentials("h2-user", "h2-password");
----


==== Testing with Postgres

Postgres is supported through multiple test classes:

* link:{jdbidocs}/testing/junit5/JdbiPostgresExtension.html[JdbiPostgresExtension^] manages a local database on the host. It uses the https://pg-embedded.softwareforge.de/[pg-embedded^] library that can spin up Postgres instances on various OS and architectures. This is the fastest way to get to a Postgres instance. Most of the Jdbi test classes that use Postgres use this extension.
* link:{jdbidocs}/testing/junit5/JdbiExternalPostgresExtension.html[JdbiExternalPostgresExtension^] supports an external Postgres database and can run tests against any local or remote database.
* link:{jdbidocs}/testing/junit5/JdbiOtjPostgresExtension.html[JdbiOtjPostgresExtension^] supports the https://github.com/opentable/otj-pg-embedded[OpenTable Java Embedded PostgreSQL component^].


=== Using Testcontainers

The https://testcontainers.org[Testcontainers^] project provides a number of services as docker containers with a programmatic interface for JVM code. Jdbi supports JDBC type databases with the link:{jdbidocs}/testing/junit5/tc/JdbiTestcontainersExtension.html[JdbiTestcontainersExtension^]:

[source,java,indent=0]
----
@Testcontainers
class TestWithContainers {
    @Container
    static JdbcDatabaseContainer<?> dbContainer = new YugabyteDBYSQLContainer("yugabytedb/yugabyte");

    @RegisterExtension
    JdbiExtension extension = JdbiTestcontainersExtension.instance(dbContainer);

    // ... test code using the yugabyte engine
}
----

The link:{jdbidocs}/testing/junit5/tc/JdbiTestcontainersExtension.html[JdbiTestcontainersExtension^] has built-in support to isolate each test method in a test class. The container can be declared as a static class member which speeds up test execution significantly.

There is built-in support for MySQL, MariaDB, TiDB, PostgreSQL, CockroachDB, YugabyteDB, ClickHouse, Oracle XE, Trino and MS SQLServer. It also supports the various compatible flavors (such as PostGIS for PostgreSQL).

==== Providing custom database information

The link:{jdbidocs}/testing/junit5/tc/JdbiTestcontainersExtension.html[JdbiTestcontainersExtension^] creates a new database or schema (depending on the database engine) for each test. This speeds up test execution. In some cases (e.g. when using a not yet supported database engine or when using a custom docker image), it may be necessary to provide a custom instance of the link:{jdbidocs}/testing/junit5/tc/TestcontainersDatabaseInformation.html[TestcontainersDatabaseInformation^] class that describes how to manage a specific database engine.

Here are examples for MySQL and PostgreSQL:

[source,java,indent=0]
----
// MySQL has only databases, no schemata. The Jdbi extension creates a new database
// for each test method.
private static final TestcontainersDatabaseInformation MYSQL = TestcontainersDatabaseInformation.of(
        "root",  // Testcontainers provides the 'root' superuser for MySQL instances.
        null,    // do not override the generated catalog name
        null,    // do not override the generated schema name (which is not used by MySQL)
        // create a new database from the catalog name
        (catalogName, schemaName) -> format("CREATE DATABASE %s", catalogName)
);

// PostgreSQL knows about schemata but needs to use the predefined "test" database.
// The Jdbi extension creates a new schema for each test method
private static final TestcontainersDatabaseInformation POSTGRES = TestcontainersDatabaseInformation.of(
        null,   // Use the default user that testcontainers provides
        "test", // override the generated catalog name with 'test'
        null,   // do not override the generated schema name
        // create a new schema from the schema name
        (catalogName, schemaName) -> format("CREATE SCHEMA %s", schemaName)
);
----

See the Javadoc for the link:{jdbidocs}/testing/junit5/tc/TestcontainersDatabaseInformation.html[TestcontainersDatabaseInformation^] class for further details.

The link:{jdbidocs}/testing/junit5/tc/JdbiTestcontainersExtension.html[JdbiTestcontainersExtension^] provides the link:{jdbidocs}/testing/junit5/tc/JdbiTestcontainersExtension.html#instance(org.jdbi.v3.testing.junit5.tc.TestcontainersDatabaseInformation,org.testcontainers.containers.JdbcDatabaseContainer)[instance(TestcontainersDatabaseInformation, JdbcDatabaseContainer)^] method which uses a custom database information object:

[source,java,indent=0]
----
@Testcontainers
class TestWithCustomContainer {
    @Container
    static JdbcDatabaseContainer<?> dbContainer = new PostgreSQLContainer<>(
       DockerImageName.parse("custom-image").asCompatibleSubstituteFor("postgres"));


    static final TestcontainersDatabaseInformation CUSTOM_DATABASE =
       TestcontainersDatabaseInformation.of( ... custom setup ...);

    @RegisterExtension
    JdbiExtension extension = JdbiTestcontainersExtension.instance(CUSTOM_DATABASE, dbContainer);

    // ... test code using the custom engine
}
----


== Third-Party Integration

[#google-guava]
=== Google Guava

This plugin adds support for the following types:

* `Optional<T>` - registers an argument and mapper. Supports link:{jdkdocs}/java.base/java/util/Optional.html[Optional^] for any
  wrapped type `T` for which a mapper / argument factory is registered.
* Most Guava collection and map types - see
 link:{jdbidocs}/guava/GuavaCollectors.html[GuavaCollectors^] for a complete
  list of supported types.

To use this plugin, add a Maven dependency:

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
    <groupId>org.jdbi</groupId>
    <artifactId>jdbi3-guava</artifactId>
</dependency>
----

Then install the plugin into the link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance:

[source,java,indent=0]
----
jdbi.installPlugin(new GuavaPlugin());
----

With the plugin installed, any supported Guava collection type can
be returned from a SQL object method:

[source,java,indent=0]
----
include::{sqlobjectexampledir}/TestGuavaCollectors.java[tags=returnTypes]
----


=== H2 Database

This plugin configures Jdbi to correctly handle `integer[]` and `uuid[]` data
types in an H2 database.

This plugin is included with the core jar (but may be extracted to separate
artifact in the future). Use it by installing the plugin into your link:{jdbidocs}/core/Jdbi.html[Jdbi^]
instance:

[source,java,indent=0]
----
jdbi.installPlugin(new H2DatabasePlugin());
----


[[jdbi3-json]]
=== JSON

The `jdbi3-json` module adds a link:{jdbidocs}/json/Json.html[@Json^] type qualifier that allows to store arbitrary Java objects as JSON data in your database.

The actual JSON (de)serialization code is not included. For that, you must install a backing plugin (see below).

[TIP]
Backing plugins will install the `JsonPlugin` for you.
You do *not* need to install it yourself or include the `jdbi3-json` dependency directly.

The feature has been tested with Postgres `json` columns
and `varchar` columns in H2 and Sqlite.


==== Jackson 2

This plugin provides JSON backing through Jackson 2.

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
  <groupId>org.jdbi</groupId>
  <artifactId>jdbi3-jackson2</artifactId>
</dependency>
----

[source,java,indent=0]
----
jdbi.installPlugin(new Jackson2Plugin());
// optionally configure your ObjectMapper (recommended)
jdbi.getConfig(Jackson2Config.class).setMapper(myObjectMapper);

// now with simple support for Json Views if you want to filter properties:
jdbi.getConfig(Jackson2Config.class).setView(ApiProperty.class);
----


==== Gson 2

This plugin provides JSON backing through Gson 2.

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
  <groupId>org.jdbi</groupId>
  <artifactId>jdbi3-gson2</artifactId>
</dependency>
----

[source,java,indent=0]
----
jdbi.installPlugin(new Gson2Plugin());
// optional
jdbi.getConfig(Gson2Config.class).setGson(myGson);
----


==== Moshi

This plugin provides JSON backing through Moshi.

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
    <groupId>org.jdbi</groupId>
    <artifactId>jdbi3-moshi</artifactId>
</dependency>
----

[source,java,indent=0]
----
jdbi.installPlugin(new MoshiPlugin());
// optional
jdbi.getConfig(MoshiConfig.class).setMoshi(myMoshi);
----


==== Operation

Any bound object qualified as link:{jdbidocs}/json/Json.html[@Json^]
will be converted by the link:{jdbidocs}/json/JsonConfig.html[registered^]
link:{jdbidocs}/json/JsonMapper.html[JsonMapper^] and _requalified_ as
link:{jdbidocs}/json/EncodedJson.html[@EncodedJson^] `String`.
A corresponding `@EncodedJson ArgumentFactory` will then be called to store the JSON data,
allowing special JSON handling for your database to be implemented.
If none are found, a factory for plain `String` will be used instead, to handle the JSON as plaintext.

Mapping works just the same way, but in reverse: an output type qualified as `@Json T` will be fetched from a
`@EncodedJson String` or `String` ColumnMapper, and then passed through the `JsonMapper`.

[TIP]
Our PostgresPlugin provides qualified factories that will
bind/map the `@EncodedJson String` to/from `json` or `jsonb`-typed columns.


==== Usage

[source,java,indent=0]
----
handle.execute("create table myjsons (id serial not null, value json not null)");
----

SqlObject:

[source,java,indent=0]
----
// any json-serializable type
class MyJson {}

// use @Json qualifier:
interface MyJsonDao {
    @SqlUpdate("INSERT INTO myjsons (json) VALUES(:value)")
    // on parameters
    int insert(@Json MyJson value);

    @SqlQuery("SELECT value FROM myjsons")
    // on result types
    @Json
    List<MyJson> select();
}

// also works on bean or property-mapped objects:
class MyBean {
    private final MyJson property;
    @Json
    public MyJson getProperty() { return ...; }
}
----

With the Fluent API, you provide a `QualifiedType<T>` any place you'd normally provide a `Class<T>` or `GenericType<T>`:

[source,java,indent=0]
----
QualifiedType<MyJson> qualifiedType = QualifiedType.of(MyJson.class).with(Json.class);

h.createUpdate("INSERT INTO myjsons(json) VALUES(:json)")
    .bindByType("json", new MyJson(), qualifiedType)
    .execute();

MyJson result = h.createQuery("SELECT json FROM myjsons")
    .mapTo(qualifiedType)
    .one();
----


=== Immutables

https://immutables.github.io/[Immutables^] is an annotation processor that generates
value types based on simple interface descriptions.  The value types naturally map very well
to property binding and row mapping.

[WARNING]
Immutables support is still experimental and does not yet support custom naming schemes.
We do support the configurable `get`, `is`, and `set` prefixes.

Just tell us about your types by installing the plugin and configuring your `Immutables` type:

`jdbi.getConfig(JdbiImmutables.class).registerImmutable(MyValueType.class)`

The configuration will both register appropriate link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^]&#8288;s as well as configure the new `bindPojo` (or `@BindPojo`) binders:

[source,java,indent=0]
----
include::{coreexampledir}/ImmutablesTest.java[tags=example]
----


=== Freebuilder
https://freebuilder.inferred.org/[Freebuilder^] is an annotation
processor that generates value types based on simple interface or abstract
class descriptions. Jdbi supports Freebuilder in much the same way that it
supports Immutables.

[WARNING]
Freebuilder support is still experimental and may not support all Freebuilder
implemented features. We do support both JavaBean style getters and setters as
well as unprefixed getters and setters.

Just tell us about your Freebuilder types by installing the plugin and
configuring your `Freebuilder` type:

`jdbi.getConfig(JdbiFreebuilder.class).registerFreebuilder(MyFreeBuilderType.class)`

The configuration will both register appropriate link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^]s as well as
configure the new `bindPojo` (or `@BindPojo`) binders:

[source,java,indent=0]
----
include::{coreexampledir}/FreeBuildersTest.java[tags=example]
----


=== JodaTime

This plugin adds support for using joda-time's `DateTime` type.

To use this plugin, add a Maven dependency:

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
    <groupId>org.jdbi</groupId>
    <artifactId>jdbi3-jodatime2</artifactId>
</dependency>
----

Then install the plugin into the link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance:

[source,java,indent=0]
----
jdbi.installPlugin(new JodaTimePlugin());
----


=== Google Guice

The Guice module adds support for configuring and injecting link:{jdbidocs}/core/Jdbi.html[Jdbi^] instances in applications and services that use the https://github.com/google/guice/wiki[Google Guice^] dependency injection framework.

Guice support for Jdbi is split into two module types:

* *A Jdbi definition module* extends the link:{jdbidocs}/guice/AbstractJdbiDefinitionModule.html[AbstractJdbiDefinitionModule^] class. Each of these modules creates a new link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance which is exposed into the Guice binding process using an annotation.
* *A Jdbi element configuration module* extends the link:{jdbidocs}/guice/AbstractJdbiConfigurationModule.html[AbstractJdbiConfigurationModule^]. These modules contribute elements that are referenced in Jdbi definition modules.

[NOTE]
Jdbi definition modules are by far more common. Element configuration modules are completely optional. They are most useful in larger projects.


==== JSR 330 vs. JEE 9+ annotations

For a long time, Java used the https://javax-inject.github.io/javax-inject/[JSR-330^] annotations in the `javax.inject` namespace to define dependency injections. The https://jakarta.ee/release/9/[Java Enterprise Edition 9^] specification updated the dependency injection specification to https://jakarta.ee/specifications/dependency-injection/2.0/[version 2.0^], which changed the namespace to `jakarta.inject`.

The `jdbi3-guice` module supports all Google Guice releases since 5.x including 6.x (which uses `javax.inject` annotations) and 7.x (which uses `jakarta.inject`).


==== Definition modules

Every link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance is defined in its own Guice module which extends the link:{jdbidocs}/guice/AbstractJdbiDefinitionModule.html[AbstractJdbiDefinitionModule^] base class.

The  annotation instance or class used on the constructor is used to bind the resulting Jdbi object:

[source,java,indent=0]
----
class GuiceJdbiModule extends AbstractJdbiDefinitionModule {

    public GuiceJdbiModule() {
        super(GuiceJdbi.class);
    }

    @Override
    protected void configureJdbi() {
        // bind a custom row mapper
        bindRowMapper().to(CustomRowMapper.class);

        // bind a custom column mapper
        bindColumnMapper().toInstance(new CustomColumnMapper());

        // bind a Codec
        bindCodec(String.class).to(Key.get(CustomStringCodec.class, Custom.class));

        // bind a custom array type
        bindArrayType(CustomArrayType.class).toInstance("custom_array");

        // bind a jdbi plugin
        bindPlugin().toInstance(new SqlObjectPlugin());

        // bind a customizer
        bindCustomizer().to(SpecialCustomizer.class);
    }
}

class Application {
    @Inject
    @GuiceJdbi
    private Jdbi jdbi;

    public static void main(String ... args) {
        Injector inj = Guice.createInjector(
            new GuiceJdbiModule(),
)           binder -> binder.bind(DataSource.class).annotatedWith(GuiceJdbi.class).toInstance(... data source instance ...);
        );
        inj.injectMembers(this);
    }
}
----

In this example, a new link:{jdbidocs}/core/Jdbi.html[Jdbi^] object is defined using specific mappers and other customizations. The link:{jdbidocs}/core/Jdbi.html[Jdbi^] object is exposed to Guice using the annotation passed on the module constructor (`GuiceJdbi` in the example). The link:{jdbidocs}/guice/AbstractJdbiDefinitionModule.html[AbstractJdbiDefinitionModule^] supports both annotation instances and classes, similar to Guice itself.

[NOTE]
A Jdbi definition module requires that a DataSource object is bound within Guice using the same annotation or annotation class as is passed into the module constructor. *Creating this data source is outside the scope of a Jdbi definition module!*

When implementing the link:{jdbidocs}/guice/AbstractJdbiDefinitionModule.html#jdbiBinder()[configureJdbi()^] method, a number of convenience methods are available as shown above. These methods return Guice LinkedBindingBuilder instances and allow the full range of bindings that guice supports (classes, instances, providers etc).

[%header, cols=3*]
.Supported bindings
|=====
| Method | Type of binding | Jdbi function

| link:{jdbidocs}/guice/JdbiBinder.html#bindRowMapper()[bindRowMapper()^]
.3+| link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper<?>^]
.3+| <<Row Mappers>>
| link:{jdbidocs}/guice/JdbiBinder.html#bindRowMapper(org.jdbi.v3.core.generic.GenericType)[bindRowMapper(GenericType<?>)^]
| link:{jdbidocs}/guice/JdbiBinder.html#bindRowMapper(java.lang.reflect.Type)[bindRowMapper(Type)^]

| link:{jdbidocs}/guice/JdbiBinder.html#bindColumnMapper()[bindColumnMapper()^]
.4+| link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper<?>^]
.4+| <<Column Mappers>>
| link:{jdbidocs}/guice/JdbiBinder.html#bindColumnMapper(org.jdbi.v3.core.qualifier.QualifiedType)[bindColumnMapper(QualifiedType<?>)^]
| link:{jdbidocs}/guice/JdbiBinder.html#bindColumnMapper(org.jdbi.v3.core.generic.GenericType)[bindColumnMapper(GenericType<?>)^]
| link:{jdbidocs}/guice/JdbiBinder.html#bindColumnMapper(java.lang.reflect.Type)[bindColumnMapper(Type)^]

| link:{jdbidocs}/guice/JdbiBinder.html#bindCodec(org.jdbi.v3.core.qualifier.QualifiedType)[bindCodec(QualifiedType<?>)^]
.3+| link:{jdbidocs}/core/codec/Codec.html[Codec<?>^]
.3+| <<Codecs>>
| link:{jdbidocs}/guice/JdbiBinder.html#bindCodec(org.jdbi.v3.core.generic.GenericType)[bindCodec(GenericType<?>)^]
| link:{jdbidocs}/guice/JdbiBinder.html#bindCodec(java.lang.reflect.Type)[bindCodec(Type)^]

| link:{jdbidocs}/guice/JdbiBinder.html#bindArrayType(java.lang.Class)[bindArrayType(Class<?>)^] | `String` | <<Registering array types>>

| link:{jdbidocs}/guice/JdbiBinder.html#bindPlugin()[bindPlugin()^]
| link:{jdbidocs}/core/spi/JdbiPlugin.html[JdbiPlugin^]
| <<Installing Plugins>>

| link:{jdbidocs}/guice/JdbiBinder.html#bindCustomizer()[bindCustomizer()^]
| link:{jdbidocs}/guice/GuiceJdbiCustomizer.html[GuiceJdbiCustomizer^]
| <<Jdbi customization using Guice>>
|=====

Each Jdbi definition module is completely independent and all definitions within the module only apply to the specific link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance.


==== Using Guice injection in Jdbi classes

The Jdbi related guice modules store the various related elements (mappers, codecs etc.) using https://github.com/google/guice/wiki/Multibindings[Multibindings^]. As a result, it is not possible to use injection directly when constructing mapper instances.

The following example *does not work*:

[source,java,indent=0]
----
class JdbiModule extends AbstractJdbiDefinitionModule {

    public JdbiModule() {
        super(Names.named("data"));
    }

    @Override
    protected void configureJdbi() {
        bindRowMapper().to(BrokenRowMapper.class);
        bindColumnMapper().to(CustomStringMapper.class);
    }
}

class CustomStringMapper implements ColumnMapper<String> {

    @Override
    public String map(ResultSet r, int columnNumber, StatementContext ctx) {
        long x = r.getLong(columnNumber);
        return (x > 1000) ? "Huge" : "Small";
    }
}

class BrokenRowMapper implements RowMapper<DataRow> {

    private final ColumnMapper<String> stringMapper;

    @Inject
    public BrokenRowMapper(CustomStringMapper stringMapper) {
        this.stringMapper = stringMapper;
    }

    @Override
    public DataRow map(ResultSet rs, StatementContext ctx) {
        return new DataRow(rs.getInt("intValue"),
                stringMapper.map(rs, "longValue", ctx));
    }
}
----

Guice will report an error that it cannot locate the `CustomStringMapper` instance. The Guice Jdbi integration manages mappers etc. as groups and the separate instances are not directly accessible for injection. The right way to compose mappers is using the Jdbi configuration (see <<JdbiConfig>>), which is configured through Guice:

[source,java,indent=0]
----
class JdbiModule extends AbstractJdbiDefinitionModule {

    public JdbiModule() {
        super(Names.named("data"));
    }

    @Override
    protected void configureJdbi() {
        bindRowMapper().to(WorkingRowMapper.class);
        bindColumnMapper(CustomStringMapper.TYPE).to(CustomStringMapper.class);
    }
}

class CustomStringMapper implements ColumnMapper<String> {

    public static QualifiedType<String> TYPE = QualifiedType.of(String.class).with(Names.named("data"));

    @Override
    public String map(ResultSet r, int columnNumber, StatementContext ctx) throws SQLException {
        long x = r.getLong(columnNumber);
        return (x > 1000) ? "Huge" : "Small";
    }
}

class WorkingRowMapper implements RowMapper<DataRow> {

    private ColumnMapper<String> stringMapper;

    @Override
    public void init(ConfigRegistry registry) {
        this.stringMapper = registry.get(ColumnMappers.class).findFor(CustomStringMapper.TYPE)
                .orElseThrow(IllegalStateException::new);
    }

    @Override
    public DataRow map(ResultSet rs, StatementContext ctx) throws SQLException {
        return new DataRow(rs.getInt("intValue"),
            stringMapper.map(rs, "longValue", ctx));
    }
}
----

This limitation *only* applies to bindings that are made in through the various `bindXXX()` methods in Jdbi specific modules. Any other binding is available for injection into Jdbi elements:

[source,java,indent=0]
----
class ThresholdMapper implements ColumnMapper<String> {

    public static QualifiedType<String> TYPE = QualifiedType.of(String.class).with(Threshold.class);

    private final long threshold;

    // Injection of a named constant here.
    @Inject
    ThresholdMapper(@Threshold long threshold) {
        this.threshold = threshold;
    }

    @Override
    public String map(ResultSet r, int columnNumber, StatementContext ctx) throws SQLException {
        long x = r.getLong(columnNumber);
        return (x > threshold) ? "Huge" : "Small";
    }
}

class JdbiModule extends AbstractJdbiDefinitionModule {

    public JdbiModule() {
        super(Data.class);
    }

    @Override
    protected void configureJdbi() {
        bindColumnMapper(CustomStringMapper.TYPE).to(CustomStringMapper.class);
    }
}

Injector inj = Guice.createInjector(
    new JdbiModule(),
    // define injected constant here
    binder -> binder.bindConstant().annotatedWith(Threshold.class).to(5000L);
)
----


==== Jdbi customization using Guice

Many Jdbi specific settings can be configured through the `bindXXX()` methods available on Jdbi modules (row mappers, column mappers, codecs, plugins etc.)

However, there are additional features that may not be available through these methods. For these use cases, the link:{jdbidocs}/guice/GuiceJdbiCustomizer.html[GuiceJdbiCustomizer^] interface can be used.

Instances that implement this interface can be added to Jdbi modules using the link:{jdbidocs}/guice/JdbiBinder.html#bindCustomizer()[bindCustomizer()^] method.

Every customizer will get the link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance passed at construction time and may modify any aspect before it gets exposed to other parts of the application.

[source,java,indent=0]
----
class GuiceCustomizationModule extends AbstractJdbiDefinitionModule {

    public GuiceCustomizationModule() {
        super(Custom.class);
    }

    @Override
    protected void configureJdbi() {
        bindCustomizer().to(MyCustomizer.class);
    }
}

class MyCustomizer implements GuiceJdbiCustomizer {

    @Override
    public void customize(Jdbi jdbi) {
        // set the logger to use Slf4j
        jdbi.setSqlLogger(new Slf4JSqlLogger());
    }
}
----

In combination with Jdbi configuration modules, these customizers allow easy enforcement of standard configurations for all Jdbi instances in larger projects.


==== Element configuration modules

[NOTE]
Element configuration modules are completely optional and should not be used when only a single Jdbi instance is required. They are intended to help with code organization in larger projects that have more complex needs.

All bindings in a Jdbi module that defines a link:{jdbidocs}/core/Jdbi.html[Jdbi^] object are local to that module. This is useful if all Jdbi related code can be grouped around the module. In larger projects, some parts of the code (and their Jdbi related elements such as row and column mappers) may be located in different part of the code base.

In larger projects, generic mappers should be available for multiple Jdbi instances. This leads often to a proliferation of small modules that only contain such generic code and is in turn imported into every code module that wants to use them.

To support modular code design, any part of a code base that wants to contribute Jdbi specific classes such as mappers to the overall system can use an element configuration module to expose these to all Jdbi instances in a project.

Jdbi element configuration modules extend link:{jdbidocs}/guice/AbstractJdbiConfigurationModule.html[AbstractJdbiConfigurationModule^] and can define mappers, plugins etc. similar to a Jdbi definition module. Anything that is registered in such a module is global and will be applied to all instances even if they are defined in another module.


[source,java,indent=0]
----
class DomainModule extends AbstractJdbiConfigurationModule {

    @Override
    protected void configureJdbi() {
        bindRowMapper().to(DomainMapper.class);
    }
}

class DomainMapper implements RowMapper<DomainObject> {

    private ColumnMapper<UUID> uuidMapper;

    @Override
    public void init(ConfigRegistry registry) {
        this.uuidMapper = registry.get(ColumnMappers.class).findFor(UUID.class)
                .orElseThrow(IllegalStateException::new);
    }

    @Override
    public DomainObject map(ResultSet rs, StatementContext ctx) throws SQLException {
        return new DomainObject(
            uuidMapper.map(rs, "id", ctx),
            rs.getString("name"),
            rs.getString("data"),
            rs.getInt("value"),
            rs.getBoolean("flag"));
    }
}
----

If the `DomainModule` is bound within Guice, then all configured link:{jdbidocs}/core/Jdbi.html[Jdbi^] instances will be able to map DomainObject instances without having to configure them explicitly as a row mapper.

Multiple modules extending link:{jdbidocs}/guice/AbstractJdbiConfigurationModule.html[AbstractJdbiConfigurationModule^] can be installed in a single injector; the resulting bindings will be aggregated.

[CAUTION]
It is not possible to install a configuration module from within the `configureJdbi` method of a definition module using the `install()` or `binder().install()` methods!
Definition modules are Guice private modules and anything defined within them will not be exposed to the general dependency tree. This is a limitation due to the way Guice works.


==== Advanced Topics


===== Exposing additional bindings

Each definition module that defines a link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance keeps all bindings private and exposes only the actual link:{jdbidocs}/core/Jdbi.html[Jdbi^] object itself. This allows the installation of multiple modules where each definition is completely independent. Sometimes it is useful to attach additional objects and expose them using the same annotations. The most common use cases are data access objects.

Consider a use case where two DataSource instances exist, one annotated as `Writer` and the other as `Reader`. Both are accessing databases with the same schema, and it makes sense to have two data access objects that are identical except that they are using the different data sources (this is often referred to as the "robot legs" problem of dependency injection).

[source,java,indent=0]
----
interface DatabaseAccess {
    @SqlUpdate("INSERT INTO data_table ....")
    int insert(...);

    @SqlQuery("SELECT * FROM data_table")
    Data select();
}
----

To bind two instances of this data access object and connect each to the appropriate Jdbi instance, add the binding to the Jdbi definition module and expose it with link:{jdbidocs}/guice/AbstractJdbiDefinitionModule.html#exposeBinding(java.lang.Class)[exposeBinding(Class<?>)^] or link:{jdbidocs}/guice/AbstractJdbiDefinitionModule.html#exposeBinding(com.google.inject.TypeLiteral)[exposeBinding(TypeLiteral<?>)^]:

[source,java,indent=0]
----
class DatabaseModule extends AbstractJdbiDefinitionModule {
    public DatabaseModule(Class<? extends Annotation> a) {
        super(a);
    }

    @Provides
    @Singleton
    DatabaseAccess createDatabaseAccess(Jdbi jdbi) {
        return jdbi.onDemand(DatabaseAccess.class);
    }

    @Override
    public void configureJdbi() {
        // ... bind mappers, plugins etc. ...

        exposeBinding(DatabaseAccess.class);
    }
}
----

Now install the module multiple times with different annotation classes:

[source,java,indent=0]
----
Injector injector = Guice.createInjector(
    // bind existing data sources
    binder -> binder.bind(DataSource.class).annotatedWith(Reader.class).toInstance(...);
    binder -> binder.bind(DataSource.class).annotatedWith(Writer.class).toInstance(...);

    new DatabaseModule(Reader.class),
    new DatabaseModule(Writer.class)
);

// fetch object directly from the injector
DatabaseAccess readerAccess = injector.getInstance(Key.get(DatabaseAccess.class, Reader.class));
DatabaseAccess writerAccess = injector.getInstance(Key.get(DatabaseAccess.class, Writer.class));
----


===== Importing external bindings

The main use case of guice is code modularization and code reuse. Jdbi definition modules can pull dependencies out of the global dependency definitions and using the `importBinding` and `importBindingLoosely` methods.

`importBinding` requires a dependency to exist and pulls it into the definition module. The dependency must be defined using the same annotation or annotation class as the definition module uses.

This example shows how to define an external dependency (`SpecialLogger`, annotated with `Store`) in a different module and then pull it into the definition module using `importBinding`:
[source,java,indent=0]
----

//
// This is logging code that can be located e.g. in a specific part of the code base that
// deals with all aspects of logging. The Logging module creates the binding for the special
// logger depending on the environment that the code has been deployed in.
class LoggingModule extends AbstractModule {

    private final boolean production;
    private final Class<? extends Annotation> annotation;

    LoggingModule(boolean production, Class<? extends Annotation> annotation) {
        this.production = production;
        this.annotation = annotation;
    }

    @Override
    public void configure() {
        if (production) {
            bind(SpecialLogger.class).annotatedWith(annotation).toInstance(new MaskingLogger());
        } else {
            bind(SpecialLogger.class).annotatedWith(annotation).toInstance(new DebugLogger());
        }
    }
}

//
// This is Jdbi code that deals with the data store. It can be located in a different part of the
// application. It requires the "SpecialLogger" dependency to be bound somewhere.
//
@Singleton
class JdbiSpecialLogging implements GuiceJdbiCustomizer {

    private final SpecialLogger logger;

    @Inject
    JdbiSpecialLogging(SpecialLogger logger) {
        this.logger = logger;
    }

    @Override
    public void customize(Jdbi jdbi) {
        jdbi.setSqlLogger(new SpecialSqlLogger(logger));
    }
}

class DatabaseModule extends AbstractJdbiDefinitionModule {
    public DatabaseModule(Class<? extends Annotation> a) {
        super(a);
    }

    @Override
    public void configureJdbi() {
        ... bind mappers, plugins etc. ...

        // pull the "SpecialLogger" annotated with Store into the module scope
        importBinding(SpecialLogger.class).in(Scopes.SINGLETON);
        bindCustomizer().to(JdbiSpecialLogging.class);
    }
}


Injector injector = Guice.createInjector(
    new LoggingModule(production, Store.class),
    new DatabaseModule(Store.class)
)
----

`importBinding` returns a binding builder, that allows different binding styles:

[source,java,indent=0]
----
class DatabaseModule extends AbstractJdbiDefinitionModule {
    @Override
    public void configureJdbi() {
         // simplest use case, pull in Foo.class using the same annotation
        importBinding(Foo.class);

         // supports everything that a ScopedBindingBuilder does
        importBinding(Foo.class).in(Scopes.SINGLETON);

         // supports "to()" to bind interfaces to implementation
        importBinding(Foo.class).to(FooImpl.class);

         // supports type literals
        importBinding(new TypeLiteral<Set<Foo>>() {}).to(FooSet.class);

        // supports binding into the various binder methods as well

        // pull SpecialCustomizer using the same annotation as the module and add it to the set of customizers
        importBinding(bindCustomizer(), SpecialCustomizer.class).in(Scopes.SINGLETON);

        // bind column mapper using a type literal
        importBinding(bindColumnMapper(), new TypeLiteral<Map<String, Object>>() {}).to(JsonMapper.class);
    }
}
----

Static bindings require that the dependency is always defined. However, it is often desirable to have optional bindings that do not need to exist. This is supported using the `importLooseBinding` mechanism.

[source,java,indent=0]
----
class DropwizardStoreModule extends AbstractModule {

    @Store
    @Provides
    @Singleton
    DropwizardJdbiSupport getDropwizardJdbiSupport(@Dropwizard DataSourcConfiguration configuration, @Dropwizard Environment environment) {
            return new DropwizardJdbiSupport("store", configuration, environment);
    }

    static class DropwizardJdbiSupport implements GuiceJdbiCustomizer {
        private final String name;
        private final Environment environment;
        private final DataSourceConfiguration<?> configuration;


    DropwizardJdbiSupport(String name, DataSourceConfiguration configuration, Environment environment) {
        this.name = name;
        this.configuration = configuration;
        this.environment = environment;
    }

    @Override
    public void customize(final Jdbi jdbi) {
        final String validationQuery = configuration.getValidationQuery();
        environment.healthChecks().register(name, new JdbiHealthCheck(
                environment.getHealthCheckExecutorService(),
                configuration.getValidationQueryTimeout().orElse(Duration.seconds(5)),
                jdbi,
                Optional.of(validationQuery)));
    }
}

class StoreJdbiModule extends AbstractJdbiDefinitionModule {
    @Override
    public void configureJdbi() {
        // ... other Jdbi code bindings for the store ...

        importBindingLoosely(bindCustomizer(), GuiceJdbiCustomizer.class)
                .withDefault(GuiceJdbiCustomizer.NOP)
                .to(DropwizardJdbiSupport.class);
    }
}

// production code (running in dropwizard framework)
Injector injector = Guice.createInjector(
    new DropwizardModule(),      // binds @Dropwizard stuff
    new DropwizardStoreModule(), // binds dropwizard support for store jdbi
    new StoreDataSourceModule(), // binds @Store DataSource
    new StoreJdbiModule()        // Store Jdbi code
);

// test code
Injector injector = Guice.createInjector(
    new StoreTestingDataSourceModule(), // testing datasource for store
    new StoreJdbiModule()               // store Jdbi code
);
----

In this example there is code specific to the dropwizard framework that would not work in unit tests (that are not run within the framework). This code is only bound in the production environment using the `DropwizardStoreModule` and not present in testing.

The `StoreJdbiModule` uses `importBindingLoosely` to pull in the `DropwizardJdbiSupport` binding using the `Store` annotation if it exists or uses a No-Op otherwise.

`importBindingLoosely` allows for full decoupling of optional dependencies without having to resort to conditionals or separate testing modules.

[source,java,indent=0]
----
class DatabaseModule extends AbstractJdbiDefinitionModule {
    @Override
    public void configureJdbi() {
         // simplest use case, pull in Foo.class using the same annotation
        importBindingLoosely(Foo.class);

         // supports everything that a ScopedBindingBuilder does
        importBindingLoosely(Foo.class).in(Scopes.SINGLETON);

         // supports "to()" to bind interfaces to implementation
        importBindingLoosely(Foo.class).to(FooImpl.class);

        // supports default value that is used if the binding
        // is not present
        importBindingLoosely(Foo.class)
            .withDefault(new Foo("default"));

         // supports type literals
        importBindingLoosely(new TypeLiteral<Set<Foo>>() {}).to(FooSet.class);

        // supports binding into the various binder methods as well

        // pull SpecialCustomizer using the same annotation as the module and add it to the set of customizers
        importBindingLoosely(bindCustomizer(), SpecialCustomizer.class).in(Scopes.SINGLETON);

        // bind column mapper using a type literal
        importBindingLoosely(bindColumnMapper(), new TypeLiteral<Map<String, Object>>() {}).to(JsonMapper.class);

        // full example
        importBindingLoosely(bindCustomizer(), GuiceJdbiCustomizer.class)
            .withDefault(GuiceJdbiCustomizer.NOP)
            .to(SpecialCustomizer.class)
            .asEagerSingleton();
    }
}
----


===== Custom element configuration modules

In larger projects, <<Element configuration modules>> help to organize the various Jdbi related elements. By default, all modules contribute their configuration to a single, global configuration that is used in all Jdbi definition modules.

Sometimes it is useful to create separate configurations that only affect a subset of Jdbi definitions. This can be done by using a custom annotation for both the Jdbi element configuration and the Jdbi definition modules:

[source,java,indent=0]
----
class CustomConfigurationModule extends AbstractJdbiConfigurationModule {

    CustomModule() {
        super(CustomConfiguration.class); // definition modules must use this annotation explictly
    }

    @Override
    public void configureJdbi() {
        bindColumnMapper().to(CustomColumnMapper.class);
        bindPlugin().to(SpecialDatabaseModule.class);
    }
}

class SpecialDatabaseModule extends AbstractJdbiDefinitionModule {

    SpecialDatabaseModule() {
        super(
            SpecialDatabase.class,     // The Jdbi instance is bound using this annotation class
            CustomConfiguration.class  // Use an explicit configuration
        );
    }

    @Override
    public void configureJdbi() {
        ...
    }
}
----

The Jdbi element bound with the `SpecialDatabase` annotation will have the `SpecialDatabaseModule` loaded and can use the `CustomColumnMapper`.


=== JPA

Using the JPA plugin is a great way to trick your boss into letting you try
Jdbi. "No problem boss, it already supports JPA annotations, easy-peasy!"

This plugin adds mapping support for a small subset of JPA entity annotations:

* Entity
* MappedSuperclass
* Column

To use this plugin, add a Maven dependency:

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
  <groupId>org.jdbi</groupId>
  <artifactId>jdbi3-jpa</artifactId>
</dependency>
----

Then install the plugin into the link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance:

[source,java,indent=0]
----
jdbi.installPlugin(new JpaPlugin());
----

Honestly though... just tear off the bandage and switch to Jdbi proper.


=== Kotlin

https://kotlinlang.org/[Kotlin^] support is provided by *jdbi3-kotlin* and
*jdbi3-kotlin-sqlobject* modules.

Kotlin API documentation:

* link:apidocs-kotlin/jdbi3-kotlin/index.html[jdbi3-kotlin^]
* link:apidocs-kotlin/jdbi3-kotlin-sqlobject/index.html[jdbi3-kotlin-sqlobject^]


==== ResultSet Mapping

The *jdbi3-kotlin* plugin adds mapping to Kotlin data classes. It
supports data classes where all fields are present in the constructor as well
as classes with writable properties. Any fields not present in the constructor
will be set after the constructor call. The mapper supports nullable types. It
also uses default parameter values in the constructor if the parameter type is
not nullable and the value absent in the result set.

To use this plugin, add a Maven dependency:

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
  <groupId>org.jdbi</groupId>
  <artifactId>jdbi3-kotlin</artifactId>
</dependency>
----

Ensure the Kotlin compiler's https://kotlinlang.org/docs/reference/using-maven.html#attributes-specific-for-jvm[JVM target version^] is set to at least 11:

[source,xml,indent=0,subs="specialchars"]
----
<kotlin.compiler.jvmTarget>11</kotlin.compiler.jvmTarget>
----

Then install the link:{kotlindocs}core.kotlin/-kotlin-plugin/[Kotlin Plugin^] into the link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance:

[source,kotlin]
----
jdbi.installPlugin(KotlinPlugin());
----

The Kotlin mapper also supports link:{jdbidocs}/core/mapper/reflect/ColumnName.html[@ColumnName^] annotation that allows to specify name for a property or parameter explicitly, as well as the link:{jdbidocs}/core/mapper/Nested.html[@Nested^] annotation that allows mapping nested Kotlin objects.

[NOTE]
Instead of using link:{jdbidocs}/sqlobject/customizer/BindBean.html[@BindBean^], `bindBean()`, and link:{jdbidocs}/sqlobject/config/RegisterBeanMapper.html[@RegisterBeanMapper^] use `@BindKotlin`, `bindKotlin()`, and `KotlinMapper`
for qualifiers on constrictor parameters, getter, setters, and setter parameters of Kotlin class.

[NOTE]
The link:{jdbidocs}/core/mapper/reflect/ColumnName.html[@ColumnName^] annotation only applies while mapping SQL data into Java objects.
When binding object properties (e.g. with `bindBean()`), bind the property name (`:id`) rather than the column name (`:user_id`).

If you load all Jdbi plugins via `Jdbi.installPlugins()` this plugin will be
discovered and registered automatically. Otherwise, you can attach it using
`Jdbi.installPlugin(KotlinPlugin())`.

An example from the test class:

[source,kotlin,indent=0]
----
include::{kotlinexampledir}/KotlinPluginTest.kt[tags=dataClass;testQuery]
----

There are two extensions to help:

* `<reified T : Any>ResultBearing.mapTo()`
* `<T : Any>ResultIterable<T>.useSequence(block: (Sequence<T>) -> Unit)`

Allowing code like:

[source,kotlin]
----
val qry = handle.createQuery("SELECT id, name FROM something WHERE id = :id")
val things = qry.bind("id", brian.id).mapTo<Thing>.list()
----

and for using a Sequence that is auto closed:

[source,kotlin]
----
qryAll.mapTo<Thing>.useSequence {
    it.forEach(::println)
}
----

==== Coroutine support

[NOTE]
Coroutine support is very much experimental and not yet proven. If you find a bug or see a problem, please file a https://github.com/jdbi/jdbi/issues[bug report].

Kotlin offers a https://kotlinlang.org/docs/coroutines-overview.html[coroutine extension^] to support asynchronous programming on the Kotlin platform.

Coroutines work similar to "green threads" where operations are mapped onto a thread pool and may be executed on multiple threads. This clashes with the internal model that Jdbi uses to manage Handles (which is by default local to each thread).

The Kotlin module offers support for coroutines with Jdbi. It allows handles to move across thread boundaries and
allows seamless use of handles in coroutines.

Coroutine support is disabled by default and is activated by passing the `enableCoroutineSupport = true` property to the constructor of the link:{kotlindocs}core.kotlin/-kotlin-plugin/[Kotlin Plugin^].

[source,kotlin]
----
val jdbi = Jdbi.create( ... )
    .installPlugin(KotlinPlugin(enableCoroutineSupport = true))

jdbi.inTransactionUnchecked { transactionHandle ->
    runBlocking(jdbi.inCoroutineContext()) { <1>
        withContext(Dispatchers.Default + jdbi.inCoroutineContext(transactionHandle)) { <2>
            launch () {
                jdbi.useHandleUnchecked { handle -> <3>
                    ...
                }
            }
        }

        launch(Dispatchers.Default) { <4>
            jdbi.useHandleUnchecked { handle -> <5>
                ...
            }
        }
    }
}
----

<1> calling the link:{kotlindocs}core.kotlin/in-coroutine-context.html[Jdbi#inCoroutineContext()^] extension method without a parameter disconnects the coroutine scope from any existing thread local elements.
<2> calling the link:{kotlindocs}core.kotlin/in-coroutine-context.html[Jdbi#inCoroutineContext()^] extension method with a handle object uses this handle for all coroutines in this scope.
<3> calling Jdbi methods within the coroutine scope will use the handle that was provided above.
<4> Launching a coroutine without an explicitly attached handle works as well, in this case, a new handle gets created
<5> The handle here is a newly created handle that only exists within the jdbi callback.

[WARNING]
Coroutines that are executed in parallel by different threads at the same time will get the same handle as they share the same coroutine context. While the Handle object can be shared by multiple threads (if the underlying connection object supports it), they are designed
to be used by "one thread at a time" so additional coordination is required in this case.

Coroutines are also supported for extension objects such as the <<SQL Objects, SQL Object extension>>:

[source,kotlin]
----
val jdbi = Jdbi.create( ... )
    .installPlugin(KotlinPlugin(enableCoroutineSupport = true))
    .installPlugin(SqlObjectPlugin())

data class Something(
    val id: Int,
    val name: String
)

@RegisterKotlinMapper(Something::class)
interface SomethingDao : SqlObject {
    @SqlUpdate("insert into something (id, name) values (:id, :name)")
    fun insert(@BindKotlin something: Something)

    @SqlQuery("select id, name from something where id=:id")
    fun findById(@Bind("id") id: Int): Something
}

jdbi.withExtensionUnchecked(SomethingDao::class) { dao ->
    runBlocking(Dispatchers.IO + jdbi.inCoroutineContext()) {
        coroutineScope {
            insertSomething(dao)

            val first = selectSomething(dao, 1)
            delay(1000L)
        }

        val second = selectSomething(dao, 2)
    }
}

private suspend fun insertSomething(dao: SomethingDao): Unit = coroutineScope {
    dao.insert(Something(1, "first name"))
    dao.insert(Something(2, "second name"))
}

private suspend fun selectSomething(dao: SomethingDao, id: Int): Something = coroutineScope {
    dao.findById(id)
}
----


==== SqlObject

The *jdbi3-kotlin-sqlobject* plugin adds automatic parameter binding by name
for Kotlin methods in SqlObjects as well as support for Kotlin default methods.

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
  <groupId>org.jdbi</groupId>
  <artifactId>jdbi3-kotlin-sqlobject</artifactId>
</dependency>
----

Then install the plugin into the link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance:

[source,kotlin]
----
jdbi.installPlugin(KotlinSqlObjectPlugin());
----

Parameter binding supports individual primitive types as well as Kotlin or
JavaBean style objects as a parameter (referenced in binding as
`:paramName.propertyName`). No annotations are needed.

If you load all Jdbi plugins via `Jdbi.installPlugins()` this plugin will be
discovered and registered automatically. Otherwise, you can attach the plugin
via: `Jdbi.installPlugin(KotlinSqlObjectPlugin())`.

An example from the test class:

[source,kotlin,indent=0]
----
include::{kotlinexampledir}/KotlinPluginTest.kt[tags=sqlObject;setUp;testDao]
----


==== Jackson JSON Processing

Jackson needs a specialized ObjectMapper instance in order to understand deserialization
of Kotlin types. Make sure to configure your Jackson plugin:

[source,kotlin]
----
import com.fasterxml.jackson.module.kotlin.jacksonObjectMapper
jdbi.getConfig(Jackson2Config::class.java).mapper = jacksonObjectMapper()
----


=== Lombok

Lombok is a tool for auto-generation of mutable and immutable data classes through annotations.

[source,java,indent=0]
----
@Data
public void DataClass {
    private Long id;
    private String name;
    // autogenerates default constructor, getters, setters, equals, hashCode, and toString
}

@Value
public void ValueClass {
    private long id;
    private String name;
    // autogenerates all-args constructor, getters, equals, hashCode, and toString
}
----

Classes annotated with `@Value` are immutable, classes annotated with `@Data` behave like standard, mutable Java Beans.

- Use `BeanMapper` or link:{jdbidocs}/sqlobject/config/RegisterBeanMapper.html[@RegisterBeanMapper^] to map `@Data` classes.
- Use `ConstructorMapper` or link:{jdbidocs}/sqlobject/config/RegisterConstructorMapper.html[@RegisterConstructorMapper^] to map `@Value`
  classes.
- Use `bindBean()` or `@BindBean` to bind `@Data` or `@Value` classes.

Lombok must be configured to propagate annotations from the source code into the generated classes. Since version 1.18.4, lombok
supports the `lombok.copyableAnnotations` setting in its config file. To support all Jdbi features, the following lines must be added:

[source,java,indent=0]
----
lombok.copyableAnnotations += org.jdbi.v3.core.mapper.reflect.ColumnName
lombok.copyableAnnotations += org.jdbi.v3.core.mapper.Nested
lombok.copyableAnnotations += org.jdbi.v3.core.mapper.PropagateNull
lombok.copyableAnnotations += org.jdbi.v3.core.annotation.JdbiProperty
lombok.copyableAnnotations += org.jdbi.v3.core.mapper.reflect.JdbiConstructor
----

Any additional annotation (such as the `@HStore` annotation for PostgreSQL support) can also be added:

[source,java,indent=0]
----
lombok.copyableAnnotations += org.jdbi.v3.postgres.HStore
----

When using any of the Json mappers (<<Jackson 2>>, <<Gson 2>> or <<Moshi>> ) with lombok, the link:{jdbidocs}/json/Json.html[@Json^] annotation must also be added to the lombok config file, otherwise Jdbi can not map json columns to lombok bean properties:

[source,java,indent=0]
----
lombok.copyableAnnotations += org.jdbi.v3.json.Json
----


=== Oracle 12

This module adds support for Oracle `RETURNING` DML expressions.

To use this feature, add a Maven dependency:

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
  <groupId>org.jdbi</groupId>
  <artifactId>jdbi3-oracle12</artifactId>
</dependency>
----

Then, use the `OracleReturning` class with an link:{jdbidocs}/core/statement/Update.html[Update^] or `PreparedBatch`
to get the returned DML.

// TODO: usage example


=== PostgreSQL

The *jdbi3-postgres* plugin provides enhanced integration with the
https://jdbc.postgresql.org/[PostgreSQL JDBC Driver^].

To use this feature, add a Maven dependency:

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
  <groupId>org.jdbi</groupId>
  <artifactId>jdbi3-postgres</artifactId>
</dependency>
----

Then install the plugin into the link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance.

[source,java,indent=0]
----
Jdbi jdbi = Jdbi.create("jdbc:postgresql://host:port/database")
                .installPlugin(new PostgresPlugin());
----

The plugin configures mappings for link:{jdkdocs}/java.base/java/time/package-summary.html[java.time^] types like
link:{jdkdocs}/java.base/java/time/Instant.html[Instant^] or link:{jdkdocs}/java.base/java/time/Duration.html[Duration^], link:{jdkdocs}/java.base/java/net/InetAddress.html[InetAddress^], link:{jdkdocs}/java.base/java/util/UUID.html[UUID^], typed enums, and <<postgres-hstore,hstore>>.

It also configures SQL array type support for `int`, `long`, `float`, `double`,
`String`, and `UUID`.

See the link:{jdbidocs}/postgres/package-summary.html[javadoc^] for an
exhaustive list.

TIP: Some Postgres operators, for example the `?` query operator, collide
with Jdbi or JDBC specific special characters.  In such cases, you may need to
escape operators to e.g. `??` or `\:`.


[#postgres-hstore]
==== hstore

The Postgres plugin provides an `hstore` to `Map<String, String>` column mapper
and vice versa argument factory:

[source,java,indent=0]
----
Map<String, String> accountAttributes = handle
    .select("SELECT attributes FROM account WHERE id = ?", userId)
    .mapTo(new GenericType<Map<String, String>>() {})
    .one();
----

With `@HStore` qualified type:

[source,java,indent=0]
----
QualifiedType<> HSTORE_MAP = QualifiedType.of(new GenericType<Map<String, String>>() {})
    .with(HStore.class);

Map<String, String> caps = handle.createUpdate("UPDATE account SET attributes = :hstore")
    .bindByType("hstore", mapOfStrings, HSTORE_MAP)
    .execute();
----

By default, SQL Object treats link:{jdkdocs}/java.base/java/util/Map.html[Map^] return types as a collection of `Map.Entry`
values. Use the link:{jdbidocs}/sqlobject/SingleValue.html[@SingleValue^] annotation to override this, so that the return
type is treated as a single value instead of a collection:

[source,java,indent=0]
----
public interface AccountDao {
    @SqlQuery("SELECT attributes FROM account WHERE id = ?")
    @SingleValue
    Map<String, String> getAccountAttributes(long accountId);
}
----

[NOTE]
The default variant to install the plugin adds unqualified mappings of raw link:{jdkdocs}/java.base/java/util/Map.html[Map^] types from and to the `hstore` Postgres data type. There are situations where this interferes with other mappings of maps. It is recommended to always use the variant with the `@HStore` qualified type.

To avoid binding the unqualified Argument and ColumnMapper bindings, install the plugin using the static factory method:

[source,java,indent=0]
----
Jdbi jdbi = Jdbi.create("jdbc:postgresql://host:port/database")
                .installPlugin(PostgresPlugin.noUnqualifiedHstoreBindings());
----


[#postgres-getgeneratedkeys]
==== @GetGeneratedKeys Annotation

In Postgres, link:{jdbidocs}/sqlobject/statement/GetGeneratedKeys.html[@GetGeneratedKeys^] can return the entire modified row if you request generated keys without naming any columns.

[source,java,indent=0]
----
public interface UserDao {
    @SqlUpdate("INSERT INTO users (id, name, created_on) VALUES (nextval('user_seq'), ?, now())")
    @GetGeneratedKeys
    @RegisterBeanMapper(User.class)
    User insert(String name);
}
----

If a database operation modifies multiple rows (e.g. an update that will modify
several rows), your method can return all the modified rows in a collection:

[source,java,indent=0]
----
public interface UserDao {
    @SqlUpdate("UPDATE users SET active = false WHERE id = any(?)")
    @GetGeneratedKeys
    @RegisterBeanMapper(User.class)
    List<User> deactivateUsers(long... userIds);
}
----


==== Large Objects

Postgres supports storing large character or binary data in separate storage from
table data.  Jdbi allows you to stream this data in and out of the database as part
of an enclosing transaction.  Operations for storing, reading, and a hook for deletions are provided.
The test case serves as a simple example:

[source,java,indent=0]
----

public void blobCrud(InputStream myStream) throws IOException {
    h.useTransaction(th -> {
        Lobject lob = th.attach(Lobject.class);
        lob.insert(1, myStream);
        readItBack = lob.readBlob(1);
        lob.deleteLob(1);
        assert lob.readBlob(1) == null;
    });
}

public interface Lobject {
    // CREATE TABLE lob (id int, lob oid
    @SqlUpdate("INSERT INTO lob (id, lob) VALUES (:id, :blob)")
    void insert(int id, InputStream blob);

    @SqlQuery("SELECT lob FROM lob WHERE id = :id")
    InputStream readBlob(int id);

    @SqlUpdate("DELETE FROM lob WHERE id = :id RETURNING lo_unlink(lob)")
    void deleteLob(int id);
}
----

Please refer to
https://jdbc.postgresql.org/documentation/head/binary-data.html[Pg-JDBC docs^]
for upstream driver documentation.


=== Spring 5

This module integrates Jdbi and Spring 5 (or Spring Boot), including JTA support.

To use *jdbi-spring5*, add a Maven dependency:

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
    <groupId>org.jdbi</groupId>
    <artifactId>jdbi3-spring5</artifactId>
</dependency>
----

==== XML-based configuration
For XML-based configurations the class link:{jdbidocs}/spring5/JdbiFactoryBean.html[JdbiFactoryBean^] is made available to set up a
link:{jdbidocs}/core/Jdbi.html[Jdbi^] singleton in a Spring 5 (or Spring Boot) application context.

Then configure the Jdbi factory bean in your Spring container, e.g.:

[source,xml,indent=0]
----
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:aop="http://www.springframework.org/schema/aop"
       xmlns:tx="http://www.springframework.org/schema/tx"
       xsi:schemaLocation="
       http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd
       http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.0.xsd
       http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.0.xsd">

  <!--1-->
  <bean id="db" class="org.springframework.jdbc.datasource.DriverManagerDataSource">
    <property name="url" value="jdbc:h2:mem:testing"/>
  </bean>

  <!--2-->
  <bean id="transactionManager"
    class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
    <property name="dataSource" ref="db"/>
  </bean>
  <tx:annotation-driven transaction-manager="transactionManager"/>

  <!--3-->
  <bean id="jdbi"
    class="org.jdbi.v3.spring5.JdbiFactoryBean">
    <property name="dataSource" ref="db"/>
  </bean>

  <!--4-->
  <bean id="service"
    class="com.example.service.MyService">
    <constructor-arg ref="jdbi"/>
  </bean>
</beans>
----

<1> The SQL data source that Jdbi will connect to. In this example we use an H2
    database, but it can be any JDBC-compatible database.
<2> Enable configuration of transactions via annotations.
<3> Configure link:{jdbidocs}/spring5/JdbiFactoryBean.html[JdbiFactoryBean^] using the data source configured earlier.
<4> Inject a link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance into a service class. Alternatively, use standard JSR-330 `@Inject` annotations on the target class instead of configuring it in your `beans.xml`.


===== Installing Plugins

Plugins may be automatically installed by scanning the classpath for
link:{jdkdocs}/java.base/java/util/ServiceLoader.html[ServiceLoader^] manifests.

[source,xml,indent=0]
----
<bean id="jdbi" class="org.jdbi.v3.spring5.JdbiFactoryBean">
  ...
  <property name="autoInstallPlugins" value="true"/>
</bean>
----

Plugins may also be installed explicitly:

[source,xml,indent=0]
----
<bean id="jdbi" class="org.jdbi.v3.spring5.JdbiFactoryBean">
  ...
  <property name="plugins">
    <list>
      <bean class="org.jdbi.v3.sqlobject.SqlObjectPlugin"/>
      <bean class="org.jdbi.v3.guava.GuavaPlugin"/>
    </list>
  </property>
</bean>
----

Not all plugins are automatically installable. In these situations, you can
auto-install some plugins and manually install the rest:

[source,xml,indent=0]
----
<bean id="jdbi" class="org.jdbi.v3.spring5.JdbiFactoryBean">
  ...
  <property name="autoInstallPlugins" value="true"/>
  <property name="plugins">
    <list>
      <bean class="org.jdbi.v3.core.h2.H2DatabasePlugin"/>
    </list>
  </property>
</bean>
----


===== Global Attributes

Global defined attributes may be configured on the factory bean:

[source,xml,indent=0]
----
<bean id="jdbi" class="org.jdbi.v3.spring5.JdbiFactoryBean">
  <property name="dataSource" ref="db"/>
  <property name="globalDefines">
    <map>
      <entry key="foo" value="bar"/>
    </map>
  </property>
</bean>
----

==== Annotation-based configuration
For annotation based configurations you can add the following method in a
`@Configuration` class:

[source,java,indent=0]
----
@Configuration
public class JdbiConfiguration {
    @Bean
    public Jdbi jdbi(DataSource ds) {
        ConnectionFactory cf = new SpringConnectionFactory(dataSource); // <1>
        final Jdbi jdbi = Jdbi.create(cf);
        /* additional configuration goes here */
        return jdbi;
    }
}
----
<1> This connection factory will enable <<spring5-jta, JTA support>>.

[#spring5-jta]
==== Synchronization between Jdbi and JTA
If you use Spring and databases, you will most likely also use the Java Transaction API (JTA)
to manage the transactions. The `JdbiUtil` utility can be used to obtain link:{jdbidocs}/core/Handle.html[Handles^]
synchronized with Spring's JTA, as can be seen in the following fragment:

[source,java,indent=0]
----
Handle handle = JdbiUtil.getHandle(jdbi); // <1>
try {
    /* Use the handle */
} finally {
    JdbiUtil.closeIfNeeded(handle); // <2>
}
----
<1> Creates or reuses a handle, optionally synchronizing it with the current transaction
<2> Closes the handle if it is not bound to a Spring transaction.

This utility will also make sure that the handle is released when it was bound to a Spring transaction
and that transaction is closed.

==== Jdbi Repositories
When using <<sql-objects, SQL objects>> it might be preferable to have them available for injection.
This can be realized using the `@EnableJdbiRepositories` annotation (generally placed on your main class).
This annotation will enable the detection of SQL objects annotated with `@JdbiRepository` and create a Spring
bean for each of them.
Beans created like this will also synchronize with JTA.

Example usage:

[source,java,indent=0]
----
@JdbiRepository
public interface UserDao {
    /* SQL Object functionality goes here */
}
----

[source,java,indent=0]
----
@Component
public class UserService {
    @Autowired
    private UserDao userDao;
}
----

=== SQLite
The *jdbi3-sqlite* plugin provides support for using the
https://github.com/xerial/sqlite-jdbc[SQLite JDBC Driver^]
with Jdbi.

The plugin configures mapping for the Java *URL* type which is not
supported by driver.

To use this plugin, first add a Maven dependency:

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
  <groupId>org.jdbi</groupId>
  <artifactId>jdbi3-sqlite</artifactId>
</dependency>
----

Then install the plugin into the link:{jdbidocs}/core/Jdbi.html[Jdbi^] instance.

[source,java,indent=0]
----
Jdbi jdbi = Jdbi.create("jdbc:sqlite:database")
                .installPlugin(new SQLitePlugin());
----


[#stringtemplate4]
=== StringTemplate 4

This module allows you to plug in the https://www.stringtemplate.org/[StringTemplate 4^] templating engine, in
place of the standard Jdbi templating engine.

To use module plugin, add a Maven dependency:

[source,xml,indent=0,subs="specialchars"]
----
<dependency>
  <groupId>org.jdbi</groupId>
  <artifactId>jdbi3-stringtemplate4</artifactId>
</dependency>
----

To use StringTemplate format in SQL statements, set the template engine to link:{jdbidocs}/stringtemplate4/StringTemplateEngine.html[StringTemplateEngine^].

Defined attributes are provided to the StringTemplate engine to render the SQL:

[source,java,indent=0]
----
String sortColumn = "name";
String sql = "SELECT id, name " +
             "FROM account " +
             "ORDER BY <if(sort)> <sortBy>, <endif> id";

List<Account> accounts = handle
    .createQuery(sql)
    .setTemplateEngine(new StringTemplateEngine())
    .define("sort", true)
    .define("sortBy", sortColumn)
    .mapTo(Account.class)
    .list();
----

Since StringTemplate by default uses the `<` character to mark ST expressions,
you might need to escape some SQL:

[source,java,indent=0]
----
String datePredicateSql = "<if(datePredicate)> <dateColumn> \\< :dateFilter <endif>";
----

Alternatively, SQL templates can be loaded from StringTemplate group files on  the classpath:

[source,stringtemplate]
.com/foo/AccountDao.sql.stg
----
group AccountDao;

selectAll(sort,sortBy) ::= <<
  SELECT id, name
  FROM account
  ORDER BY <if(sort)> <sortBy>, <endif> id
>>
----

[source,java,indent=0]
----
ST template = StringTemplateSqlLocator.findStringTemplate(
                  "com/foo/AccountDao.sql.stg", "selectAll");

String sql = template.add("sort", true)
                     .add("sortBy", sortColumn)
                     .render();
----

In SQL Objects, the `@UseStringTemplateEngine` annotation sets the
statement locator, similar to first example above.

[source,java,indent=0]
----
package com.foo;

public interface AccountDao {
    @SqlQuery("SELECT id, name " +
              "FROM account " +
              "ORDER BY <if(sort)> <sortBy>, <endif> id")
    @UseStringTemplateEngine
    List<Account> selectAll(@Define boolean sort,
                            @Define String sortBy);
}
----

Alternatively, the `@UseStringTemplateSqlLocator` annotation sets the statement
locator, and loads SQL from a StringTemplate group file on the classpath:

[source,java,indent=0]
----
package com.foo;

public interface AccountDao {
    @SqlQuery
    @UseStringTemplateSqlLocator
    List<Account> selectAll(@Define boolean sort,
                            @Define String sortBy);
}
----

In this example, since the fully qualified class name is `com.foo.AccountDao`,
SQL will be loaded from the file `com/foo/AccountDao.sql.stg` on the
classpath.

By default, the template in the group with the same name as the method will be
used. This can be overridden on the `@Sql___` annotation:

[source,java,indent=0]
----
package com.foo;

public interface AccountDao {
    @SqlQuery("listSorted")
    @UseStringTemplateSqlLocator
    List<Account> selectAll(@Define boolean sort,
                            @Define String sortBy);
}
----

In this example, the SQL template will still be loaded from the file
`com/foo/AccountDao.sql.stg` on the classpath, however the `listSorted`
template will be used, regardless of the method name.

There are some options for StringTemplateEngine on the
link:{jdbidocs}/stringtemplate4/StringTemplates.html[StringTemplates^] configuration class,
like whether missing attributes are considered an error or not.

=== Vavr

The Vavr Plugin offers deep integration of Jdbi with the Vavr functional library:

* Supports argument resolution of sever Vavr Value types such as
  `Option<T>`, `Either<L, T>`, `Lazy<T>`, `Try<T>` and `Validation<T>`.
  Given that for the wrapped type `T` a Mapper is registered.
* Return Vavr collection types from queries. Supported are `Seq<T>`, `Set<T>`,
  `Map<K, T>` and `Multimap<K, T>` as well as all subtypes thereof.
  It is possible to collect into a `Traversable<T>`, in this case a link:{jdkdocs}/java.base/java/util/List.html[List<T>^]
  will be returned.
  For all interface types a sensible default implementation will be used
  (e.q. link:{jdkdocs}/java.base/java/util/List.html[List<T>^] for `Seq<T>`). Furthermore ``Multimap<K, T>``s are backed by a `Seq<T>`
  as default value container.
* Columns can be mapped into Vavr's `Option<T>` type.
* Tuple projections for Jdbi! Yey! Vavr offers Tuples up to a maximum arity of 8.
  you can map your query results e.g. to `Tuple3<Integer, String, Long>`.
  If you select more columns than the arity of the projection the columns
  up to that index will be used.

To use the plugin, add a Maven dependency:

[source,xml,indent=0,indent=0,subs="specialchars"]
----
<dependency>
  <groupId>org.jdbi</groupId>
  <artifactId>jdbi3-vavr</artifactId>
</dependency>
----

[WARNING]
Vavr introduced binary incompatibilities between 0.10.x and 1.0.0-alpha. The Jdbi plugin only supports 0.9.x and 0.10.x and requires recompilation for vavr 1.0.0.

[source,java,indent=0]
----
jdbi.installPlugin(new VavrPlugin());
----

Here are some usage examples of the features listed above:

[source,java,indent=0]
----
String query = "SELECT * FROM users WHERE :name is null or name = :name";
Option<String> param = Option.of("eric");

// will fetch first user with given name or first user with any name (Option.none)
return handle
    .createQuery(query)
    .bind("name", param)
    .mapToBean(User.class)
    .findFirst();
----

where `param` may be one of `Option<T>`, `Either<L, T>`, `Lazy<T>`, `Try<T>`
or `Validation<T>`. Note that in the case of these types, the nested value must
be 'present' otherwise a `null` value is used (e.g. for `Either.Left` or
`Validation.Invalid`).

[source,java,indent=0]
----
handle.createQuery("SELECT name FROM users")
      .collectInto(new GenericType<Seq<String>>() {});
----

This works for all the collection types supported. For the nested value
row and column mappers already installed in Jdbi will be used.
Therefore, the following would work and can make sense if the column is nullable:

[source,java,indent=0]
----
handle.createQuery("SELECT middle_name FROM users") // nulls incoming!
      .collectInto(new GenericType<Seq<Option<String>>>() {});
----

The plugin will obey configured key and value columns for `Map<K, T>`
and `Multimap<K, T>` return types. In the next example we will key users
by their name, which is not necessarily unique.

[source,java,indent=0]
----
Multimap<String, User> usersByName = handle
    .createQuery("SELECT * FROM users")
    .setMapKeyColumn("name")
    .collectInto(new GenericType<Multimap<String, User>>() {});
----

Last but not least we can now project simple queries to Vavr tuples like that:

[source,java,indent=0]
----
// given a 'tuples' table with t1 int, t2 varchar, t3 varchar, ...
List<Tuple3<Integer, String, String>> tupleProjection = handle
    .createQuery("SELECT t1, t2, t3 FROM tuples")
    .mapTo(new GenericType<Tuple3<Integer, String, String>>() {})
    .list();
----

You can also project complex types into a tuple as long as a row mapper is
registered.

[source,java,indent=0]
----
// given that there are row mappers registered for both complex types
Tuple2<City, Address> tupleProjection = handle
    .createQuery("SELECT cityname, zipcode, street, housenumber FROM " +
                 "addresses WHERE user_id = 1")
    .mapTo(new GenericType<Tuple2<City, Address>>() {})
    .one();
----

If you want to mix complex types and simple ones we also got you covered.
Using the `TupleMappers` class you can configure your projections.(In fact,
you have to - read below!)

[source,java,indent=0]
----
handle.configure(TupleMappers.class, c -> c.setColumn(2, "street").setColumn(3, "housenumber"));

Tuple3<City, String, Integer> result = handle
    .createQuery("SELECT cityname, zipcode, street, housenumber " +
                 "FROM addresses WHERE user_id = 1")
    .mapTo(new GenericType<Tuple3<City, String, Integer>>() {})
    .one();
----

Bear in mind:

* The configuration of the columns is 1-based, since they reflect
  the tuples' values (which you would query by e.g. `._1`).
* Tuples are always mapped fully column-wise or fully via row mappers.
  If you want to mix row-mapped types and single-column mappings the
  `TupleMappers` must be configured properly i.e. all non row-mapped
  tuple indices must be provided with a column configuration!


== Cookbook

This section includes examples of various things you might like to do with Jdbi.


=== Simple Dependency Injection

Jdbi tries to be independent of using a dependency injection framework,
but it's straightforward to integrate yours.  Just do field injection on a simple custom config type:

[source,java,indent=0]
----
class InjectedDependencies implements JdbiConfig<InjectedDependencies> {
    @Inject
    SomeDependency dep;

    public InjectedDependencies() {}

    @Override
    public InjectedDependencies createCopy() {
        return this; // effectively immutable
    }
}

Jdbi jdbi = Jdbi.create(myDataSource);
myIoC.inject(jdbi.getConfig(InjectedDependencies.class));

// Then, in any component that needs to access it:
getHandle().getConfig(InjectedDependencies.class).dep
----


=== LIKE clauses with Parameters

Since JDBC (and therefore Jdbi) does not allow binding parameters into the middle of string literals,
you cannot interpolate bindings into `LIKE` clauses (`LIKE '%:param%'`).

Incorrect usage:

[source,java,indent=0]
----
handle.createQuery("SELECT name FROM things WHERE name like '%:search%'")
    .bind("search", "foo")
    .mapTo(String.class)
    .list()
----

This query would try to select `where name like '%:search%'` _literally_, without binding any arguments.
This is because JDBC drivers will not bind arguments _inside string literals_.

It never gets that far, though -- this query will throw an exception,
because we don't allow unused argument bindings by default.

The solution is to use SQL string concatenation:

[source,java,indent=0]
----
handle.createQuery("SELECT name FROM things WHERE name like '%' || :search || '%'")
    .bind("search", "foo")
    .mapTo(String.class)
    .list()
----

Now, `search` can be properly bound as a parameter to the statement, and it all works as desired.

[NOTE]
Check the string concatenation syntax of your database before doing this.

[#extension-framework]
== The Extension Framework

The Jdbi core provides a rich, programmatic interface for database operations. It is possible to extend this core by writing extensions that plug into the
Jdbi core framework and provide new functionality.

The Extension framework is generic and supports any type of extension that can be registered with the Jdbi core.

Jdbi provides the <<sql-objects,SQLObject plugin>>, which offers a declarative API by placing annotations on interface methods.


[#using-jdbi-extensions]
=== Using Jdbi extensions

_Extension types are usually java interface classes._ Any interface can be an extension type.

Jdbi offers multiple ways to obtain an extension type implementation:

- Calling either
link:{jdbidocs}/core/Jdbi.html#withExtension(java.lang.Class,org.jdbi.v3.core.extension.ExtensionCallback)[Jdbi#withExtension()^] or
link:{jdbidocs}/core/Jdbi.html#useExtension(java.lang.Class,org.jdbi.v3.core.extension.ExtensionConsumer)[Jdbi#useExtension()^] methods with an extension type will pass an extension type implementation to a callback that contains user code.
- The link:{jdbidocs}/core/Handle.html#attach(java.lang.Class)[Handle#attach()^] attaches an extension type implementation directly to an existing  link:{jdbidocs}/core/Handle.html[Handle^] object.
- Finally, the link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^] method creates an on-demand implementation of an extension type that is not limited to a callback.


This is an extension type for the <<sql-objects,SQL Object extension>> which uses annotations to identify functionality:

[source,java,indent=0]
----
include::{exampledir}/ExtensionFrameworkTest.java[tags=dao]
----

If any of the SQL method annotations (link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^],
link:{jdbidocs}/sqlobject/statement/SqlCall.html[@SqlCall^], link:{jdbidocs}/sqlobject/statement/SqlQuery.html[@SqlQuery^],
link:{jdbidocs}/sqlobject/statement/SqlScript.html[@SqlScript^] and link:{jdbidocs}/sqlobject/statement/SqlUpdate.html[@SqlUpdate^]) is present on either the
extension type itself or any extension type method, the SQL Object extension will be used.

The link:{jdbidocs}/core/Jdbi.html#withExtension(java.lang.Class,org.jdbi.v3.core.extension.ExtensionCallback)[Jdbi#withExtension()^] and
link:{jdbidocs}/core/Jdbi.html#useExtension(java.lang.Class,org.jdbi.v3.core.extension.ExtensionConsumer)[Jdbi#useExtension()^] methods are used to access
SQLObject functionality:

[source,java,indent=0]
----
include::{exampledir}/ExtensionFrameworkTest.java[tags=use]

include::{exampledir}/ExtensionFrameworkTest.java[tags=with]
----

If a handle has already been created, an extension type can be directly attached with the
link:{jdbidocs}/core/Handle.html#attach(java.lang.Class)[Handle#attach()^] method:

[source,java,indent=0]
----
include::{exampledir}/ExtensionFrameworkTest.java[tags=handle_attach]
----

The link:{jdbidocs}/core/Jdbi.html#withExtension(java.lang.Class,org.jdbi.v3.core.extension.ExtensionCallback)[Jdbi#withExtension()^], link:{jdbidocs}/core/Jdbi.html#useExtension(java.lang.Class,org.jdbi.v3.core.extension.ExtensionConsumer)[Jdbi#useExtension()^] and link:{jdbidocs}/core/Handle.html#attach(java.lang.Class)[Handle#attach()^] methods are the most common way to use extension type implementations.


[#on-demand-extension]
==== On-demand extensions

An extension type implementation can be acquired by calling the link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^] method which returns
an implementation of the extension type that will transparently create a new handle instance when a method on the extension type is called.

This is an example for an on-demand extension:

[source,java,indent=0]
----
include::{exampledir}/OnDemandExtensionTest.java[tags=use]

include::{exampledir}/OnDemandExtensionTest.java[tags=with]
----

[NOTE]
The link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^] uses a link:{jdkdocs}/java.base/java/lang/reflect/Proxy.html[Java proxy^] object to provide
the on-demand handle object. Java proxies only support Java interface classes as extension types and may not be compatible with
https://docs.oracle.com/en/graalvm/enterprise/21/docs/reference-manual/native-image/DynamicProxy/[GraalVM^] when creating native code.

[#extension-handle-lifecycle]
==== Handle lifecycle for extensions

The difference between the methods to acquire an extension type implementation is the handle (and database connection) lifecycle:

- link:{jdbidocs}/core/Jdbi.html#withExtension(java.lang.Class,org.jdbi.v3.core.extension.ExtensionCallback)[Jdbi#withExtension()^] and
link:{jdbidocs}/core/Jdbi.html#useExtension(java.lang.Class,org.jdbi.v3.core.extension.ExtensionConsumer)[Jdbi#useExtension()^] provides a managed handle object when the callback is entered and reuses it for any extension type method call as long as the code does not return from the callback.

- The link:{jdbidocs}/core/Handle.html#attach(java.lang.Class)[Handle#attach()^] does not manage the handle at all. Any extension type method call will use the handle that the object was attached to and be part of its lifecycle.

- The link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^] provides a managed handle object for every extension type method call. When the method call returns, the handle is closed.


=== How an extension works

_Any interface class can be an extension type._ There is nothing special to an extension type unless an extension requires some specific information
(e.g. annotations present or specific naming).

Extensions should document which information is needed for the extension framework to determine that a specific interface class represents an extension  type that they accept.

The extension type creation methods (link:{jdbidocs}/core/Jdbi.html#withExtension(java.lang.Class,org.jdbi.v3.core.extension.ExtensionCallback)[Jdbi#withExtension()^],
link:{jdbidocs}/core/Jdbi.html#useExtension(java.lang.Class,org.jdbi.v3.core.extension.ExtensionConsumer)[Jdbi#useExtension()^],
link:{jdbidocs}/core/Handle.html#attach(java.lang.Class)[Handle#attach()^] and link:{jdbidocs}/core/Jdbi.html#onDemand(java.lang.Class)[Jdbi#onDemand()^]) all take the extension type as a parameter and provide an implementation either to the caller or within a callback object.

The extension framework selects an link:{jdbidocs}/core/extension/ExtensionFactory.html[ExtensionFactory^] to handle the extension type and create an implementation. Extension factories must be registered ahead of time with the Jdbi core using the
link:{jdbidocs}/core/extension/Extensions.html#register(org.jdbi.v3.core.extension.ExtensionFactory)[Extensions#register()^] method.

The extension factory then creates an link:{jdbidocs}/core/extension/ExtensionMetadata.html[ExtensionMetadata^] object that contains information about each
method on the extension type:

- Which link:{jdbidocs}/core/extension/ExtensionHandler.html[ExtensionHandler^] to invoke for each method
- All link:{jdbidocs}/core/extension/ExtensionHandlerCustomizer.html[ExtensionHandlerCustomizer^] instances that change the behavior of the extension handler
- Per extension type and per extension type method specific link:{jdbidocs}/core/extension/ConfigCustomizer.html[ConfigCustomizer^] instances to apply when an extension handler is invoked

Extension metadata is created once for each extension type and then reused.

Jdbi usually returns a link:{jdkdocs}/java.base/java/lang/reflect/Proxy.html[Java proxy^] object to user code. Calling a method on that proxy will invoke per-method extension handlers. For each extension handler, objects specific to the invocation
(link:{jdbidocs}/core/Handle.html[Handle^], link:{jdbidocs}/core/config/ConfigRegistry.html[configuration^]) are managed separately .

[ditaa, round-corners=true, transparent=false]
----

                                                         +--------------------------+
User code --> [registers ExtensionFactory with Jdbi] --> | Extensions Config object |
   |                                                     +--------------------------+
   |
   |                                          +------------------+
   | ---> [calls Jdbi.use/withExtension] ---> | ExtensionFactory |
   |                                          +------------------+
   |                                                 |             +-------------------+             +------------------+
   |                                                 +---> creates | ExtensionMetadata | --> defines | ExtensionHandler |
   |                                                 |             +-------------------+             +------------------+
   |                                                 |                                                       ^
   |                                                 |                                                       |
   |                                                 |                                                       | matches
   |                                                 |                                                       |
   |                                                 |                                                       |
   |                                                 |             +-------------------+              +-------------------------+
   |                                                 +---> creates | Java proxy object | --> contains | ExtensionHandlerInvoker |
   | <------- [return to user code] <----------------------------- +-------------------+              +-------------------------+
   |
   |
   |
   |
   |                                        +-------------------+              +-------------------------+
   | --> [invoke extension type method] --> | Java proxy object | --> executes | ExtensionHandlerInvoker |
   |                                        +-------------------+              +-------------------------+
   |                                                                                       |
   |                                                                                       | invokes with Handle
   |                                                                                       | and Configuration
   |                                                                                       v
   |                                                                            +------------------+
   | <---- [ return result to user code] <------------------------------------- | ExtensionHandler |
                                                                                +------------------+

----

link:{jdbidocs}/core/extension/ExtensionHandler.html[ExtensionHandler^],
link:{jdbidocs}/core/extension/ExtensionHandlerCustomizer.html[ExtensionHandlerCustomizer^] and
link:{jdbidocs}/core/extension/ConfigCustomizer.html[ConfigCustomizer^] are the three main extension framework objects to implement:

- An link:{jdbidocs}/core/extension/ExtensionHandler.html[ExtensionHandler^] object is created by an
  link:{jdbidocs}/core/extension/ExtensionHandlerFactory.html[ExtensionHandlerFactory^], which can be registered either globally (with the
  link:{jdbidocs}/core/extension/Extensions.html[Extensions configuration^]) and then applied to all extensions types, or directly with an extension factory. It is also possible to specify extension handlers through annotations.
- link:{jdbidocs}/core/extension/ExtensionHandlerCustomizer.html[ExtensionHandlerCustomizer^] objects can modify the behavior of an extension handler. They are
  registered globally or provided by an extension factory. They can also be specified through annotations.
- link:{jdbidocs}/core/extension/ConfigCustomizer.html[ConfigCustomizer^] objects are created by a
  link:{jdbidocs}/core/extension/ConfigCustomizerFactory.html[ConfigCustomizerFactory^] and modify the configuration that is used when an extension handler is
  executed. Factory instances are registered globally or with an extension factory. Config customization
  can also be specified through annotations.


=== Extension framework SDK

[NOTE]
This chapter is intended for developers who want to write a new extension for Jdbi and need to understand the Extension framework details. This chapter is only
relevant if you plan to write an extension or implement specific extension objects.

This chapter lists all the classes that make up the extension framework, their function and how to use them when writing a new extension. Not all pieces are
needed for every extension.


==== Extension configuration

The link:{jdbidocs}/core/extension/Extensions.html[Extensions^] class is the configuration object for the extension framework. It contains a registry for
extension factories and global extension objects (link:{jdbidocs}/core/extension/ExtensionHandlerFactory.html[ExtensionHandlerFactory^],
link:{jdbidocs}/core/extension/ExtensionHandlerCustomizer.html[ExtensionHandlerCustomizer^] and
link:{jdbidocs}/core/extension/ConfigCustomizerFactory.html[ConfigCustomizerFactory^]).

Any extension object registered here will be applied to all extension types, independent of the extension factory which is ultimately chosen to process an
extension type.

By default, the following extension objects are globally registered and can not be removed. These are always processed last (after all user registered extension
objects):

- An extension handler factory for the link:{jdbidocs}/core/extension/annotation/UseExtensionHandler.html[@UseExtensionHandler^] annotation.
- An extension handler customizer for the link:{jdbidocs}/core/extension/annotation/UseExtensionHandlerCustomizer.html[@UseExtensionHandlerCustomizer^]
  annotation.
- A config customizer factory for the link:{jdbidocs}/core/extension/annotation/UseExtensionConfigurer.html[@UseExtensionConfigurer^] annotation.


[IMPORTANT]
Order matters with extension objects! For each extension object, the extension specific instances are applied first, then the globally registered ones.


==== The Extension factory

Extension factories are the core piece for any extension. An link:{jdbidocs}/core/extension/ExtensionFactory.html[ExtensionFactory^] object can provide all the
specific pieces that make up the extension functionality or delegate to annotations.

The only method that must be implemented in this interface is
link:{jdbidocs}/core/extension/ExtensionFactory.html#accepts(java.lang.Class)[ExtensionFactory#accepts()^]. If this method returns `true`, then the given
extension type is handled by this factory. E.g. the link:{jdbidocs}/sqlobject/SqlObjectFactory.html[SQL Object factory^] accepts any interface that has at least
one SQL annotation on the class itself or a method.

[WARNING]
Even though it is possible to implement all the functions of an extension with annotations, there still needs to be an extension factory that accepts the
extension type. Without such a factory, the extension framework will throw a
link:{jdbidocs}/core/extension/NoSuchExtensionException.html[NoSuchExtensionException^].


Any extension factory can provide specific extension objects (by returning instances of
link:{jdbidocs}/core/extension/ExtensionHandlerFactory.html[ExtensionHandlerFactory^],
link:{jdbidocs}/core/extension/ExtensionHandlerCustomizer.html[ExtensionHandlerCustomizer^] and
link:{jdbidocs}/core/extension/ConfigCustomizerFactory.html[ConfigCustomizerFactory^]) which are only applied when the factory has accepted an extension
type. The extension factory provides the
link:{jdbidocs}/core/extension/ExtensionFactory.html#getExtensionHandlerFactories(org.jdbi.v3.core.config.ConfigRegistry)[ExtensionFactory#getExtensionHandlerFactories()^],
link:{jdbidocs}/core/extension/ExtensionFactory.html#getExtensionHandlerCustomizers(org.jdbi.v3.core.config.ConfigRegistry)[ExtensionFactory#getExtensionHandlerCustomizers()^]
and
link:{jdbidocs}/core/extension/ExtensionFactory.html#getConfigCustomizerFactories(org.jdbi.v3.core.config.ConfigRegistry)[ExtensionFactory#getConfigCustomizerFactories()^]
getters that a factory can implement.  By default, each returns an empty collection.


===== Java Object methods

When the extension framework returns an implementation of an extension type, it usually returns a link:{jdkdocs}/java.base/java/lang/reflect/Proxy.html[Java proxy^]
object which will invoke an extension handler for every method on the extension type.

In addition to the methods defined by the extension type, the following methods also invoke extension handlers:

- link:{jdkdocs}/java.base/java/lang/Object.html#toString--[Object#toString()^] returns "Jdbi extension proxy for _<extension type>_"
- link:{jdkdocs}/java.base/java/lang/Object.html#equals-java.lang.Object-[Object#equals()^] and link:{jdkdocs}/java.base/java/lang/Object.html#hashCode--[Object#hashCode()^]
  implementations that ensure that each instance is only equal to itself.
- link:{jdkdocs}/java.base/java/lang/Object.html#finalize--[Object#finalize()^] has no effect.

All methods except `finalize()` can be overridden by the extension type (e.g. through an _interface default method_).


===== Non-virtual factories

Normally, a factory will use extension handlers to provide functionality when an extension type method is called and a
link:{jdkdocs}/java.base/java/lang/reflect/Proxy.html[Java proxy^] object is returned as an implementation of the extension type. This is a _virtual_
factory (because there is no actual object implementing the interface). Extension factories are by default virtual factories.

The <<sql-objects,SQL Object extension>> is an example of a virtual factory because it never provides an implementation for extension types but  dispatches any method calls to a specific handler to execute SQL operations.

The extension framework also supports _non-virtual_ factories. These factories produce a backing object that implements the extension type. A non-virtual factory will still return a proxy object to the caller but calling any method on the proxy object may call the corresponding method on the backing object through a special extension handler.

This is an example of a non-virtual factory that provides an implementation for a specific extension type:

[source,java,indent=0]
----
include::{exampledir}/NonVirtualExtensionFactoryTest.java[tags=non-virtual-factory]
----

<1> An extension factory declares itself non-virtual by returning the
link:{jdbidocs}/core/extension/ExtensionFactory.FactoryFlag.html#NO_VIRTUAL_FACTORY[`NON_VIRTUAL_FACTORY`^] flag on the
link:{jdbidocs}/core/extension/ExtensionFactory.html#getFactoryFlags()[ExtensionFactory#getFactoryFlags()^] method.

<2> The extension framework calls the
link:{jdbidocs}/core/extension/ExtensionFactory.html#attach(java.lang.Class,org.jdbi.v3.core.extension.HandleSupplier)[ExtensionFactory#attach()^] method with
the current extension type and a handle supplier. The factory is expected to return an instance of the extension type. Methods on the instance will be wrapped
in extension handlers and a proxy object is returned to the caller.


===== Extensions without Java proxy objects

A drawback of the standard extension factories is that returning a link:{jdkdocs}/java.base/java/lang/reflect/Proxy.html[Java proxy^] object limits factory functionality
and is incompatible with some use cases (e.g. https://docs.oracle.com/en/graalvm/enterprise/21/docs/reference-manual/native-image/DynamicProxy/[using GraalVM
for native compilation^]).

A factory can return the link:{jdbidocs}/core/extension/ExtensionFactory.FactoryFlag.html#DONT_USE_PROXY[`DONT_USE_PROXY`^] flag on the
link:{jdbidocs}/core/extension/ExtensionFactory.html#getFactoryFlags()[ExtensionFactory#getFactoryFlags()^] method to signal that the extension framework should
return the backing object _as-is_.

This is an example of a factory that supports abstract classes in addition to interfaces. Abstract classes are incompatible with java proxies, so the factory
must use the link:{jdbidocs}/core/extension/ExtensionFactory.FactoryFlag.html#DONT_USE_PROXY[`DONT_USE_PROXY`^] flag:

[source,java,indent=0]
----
include::{exampledir}/DontUseProxyExtensionFactoryTest.java[tags=abstract-class]

include::{exampledir}/DontUseProxyExtensionFactoryTest.java[tags=abstract-class-factory]
----

<1> An extension factory declares that it does not want to use the proxy mechanism by returning the
link:{jdbidocs}/core/extension/ExtensionFactory.FactoryFlag.html#DONT_USE_PROXY[`DONT_USE_PROXY`^] flag from the
link:{jdbidocs}/core/extension/ExtensionFactory.html#getFactoryFlags()[ExtensionFactory#getFactoryFlags()^] method. Using this flag bypasses all the extension
framework proxy mechanism and calls the
link:{jdbidocs}/core/extension/ExtensionFactory.html#attach(java.lang.Class,org.jdbi.v3.core.extension.HandleSupplier)[ExtensionFactory#attach()^] method
immediately.

<2> The extension factory creates an instance that must be compatible with the extension type. It can provide the current extension type and a handle supplier
if needed. Unlike a non-virtual factory, this instance is returned _as-is_ to the caller. Neither proxy object nor extension handlers are created.

Jdbi provides link:{jdbidocs}/generator/GenerateSqlObjectProcessor.html[an annotation processor^] that creates java implementations of extension types. In addition, it
provides link:{jdbidocs}/sqlobject/GeneratorSqlObjectFactory.html[an extension factory^] which does not use proxy objects and returns these as extension type implementations. Calling a method on the extension type will invoke the methods on the generated classes directly.


==== Extension handlers and their factories

link:{jdbidocs}/core/extension/ExtensionHandler.html[ExtensionHandler^] objects are the main place for extension functionality. Each method on an extension type
is mapped to an extension handler. Extension handlers are executed by calling the
link:{jdbidocs}/core/extension/ExtensionHandler.html#invoke(org.jdbi.v3.core.extension.HandleSupplier,java.lang.Object,java.lang.Object%2e%2e%2e)[ExtensionHandler#invoke()^]
method.

This is an example of an extension handler that provides a value whenever a method on the extension type is called:

[source,java,indent=0]
----
include::{exampledir}/ExtensionHandlerTest.java[tags=extension-handler]
----

<1> Invoking this handler returns a `Something` instance.

Extension handlers are not shared, so every extension type method maps onto a separate instance. The
link:{jdbidocs}/core/extension/ExtensionHandlerFactory.html[ExtensionHandlerFactory^] interface provides the
link:{jdbidocs}/core/extension/ExtensionHandlerFactory.html#accepts(java.lang.Class,java.lang.reflect.Method)[ExtensionHandlerFactory#accepts()^] method which
is called for each method that needs to be mapped. If a factory accepts a method, the
link:{jdbidocs}/core/extension/ExtensionHandlerFactory.html#createExtensionHandler(java.lang.Class,java.lang.reflect.Method)[ExtensionHandlerFactory#createExtensionHandler()^]
method is called, which should return an extension handler instance.

This is an example for an extension handler factory that returns an extension handler for methods named `getSomething`:

[source,java,indent=0]
----
include::{exampledir}/ExtensionHandlerTest.java[tags=extension-handler-factory]

include::{exampledir}/ExtensionHandlerTest.java[tags=extension-type]
----

<1> The extension handler factory tests that the method has the right name.

<2> If the factory accepts the method, it returns a new instance of the extension handler shown above.

The
link:{jdbidocs}/core/extension/ExtensionHandlerFactory.html#createExtensionHandler(java.lang.Class,java.lang.reflect.Method)[ExtensionHandlerFactory#createExtensionHandler()^]
method returns an link:{jdkdocs}/java.base/java/util/Optional.html[Optional<ExtensionHandler>^] object for backwards compatibility reasons. While it is legal for a
factory to accept a method on an extension type and then return an link:{jdkdocs}/java.base/java/util/Optional.html#empty--[Optional.empty()^] object, it is discouraged
in new code.

[NOTE]
The extension framework provides extension handlers for _interface default methods_ and synthetic methods.

An extension handler for a specific extension type can be either registered globally by adding a factory using the
link:{jdbidocs}/core/extension/Extensions.html#registerHandlerFactory(org.jdbi.v3.core.extension.ExtensionHandlerFactory)[Extensions#registerHandlerFactory()^]
method, or it can be returned on the
link:{jdbidocs}/core/extension/ExtensionFactory.html#getExtensionHandlerFactories(org.jdbi.v3.core.config.ConfigRegistry)[ExtensionFactory#getExtensionHandlerFactories()^]
method of the extension factory for the extension type. It can also be configured through an annotation.

This is the extension factory for the `ExtensionType` extension type defined above:

[source,java,indent=0]
----
include::{exampledir}/ExtensionHandlerTest.java[tags=extension-factory]
----

<1> The factory will accept the `ExtensionType` extension type.

<2> When processing the type, the `TestExtensionHandlerFactory` shown above will be used when creating the extension handlers.


==== Extension handler customizers

link:{jdbidocs}/core/extension/ExtensionHandlerCustomizer.html[ExtensionHandlerCustomizer^] objects can modify extension handler execution. They are
either registered globally with the
link:{jdbidocs}/core/extension/Extensions.html#registerHandlerCustomizer(org.jdbi.v3.core.extension.ExtensionHandlerCustomizer)[Extensions#registerHandlerCustomizer()^]
and will augment any extension handler, or they can be provided by an extension factory by implementing the
link:{jdbidocs}/core/extension/ExtensionFactory.html#getConfigCustomizerFactories(org.jdbi.v3.core.config.ConfigRegistry)[ExtensionFactory#getConfigCustomizerFactories()^]
method.

Here is an example for an extension handler customizer that logs every method handler invocation. It gets registered as a global extension handler customizer
with the link:{jdbidocs}/core/extension/Extensions.html[Extensions configuration object^] and will then log every method invocation on an extension type.

[source,java,indent=0]
----
include::{exampledir}/ExtensionHandlerCustomizerTest.java[tags=register-global]

include::{exampledir}/ExtensionHandlerCustomizerTest.java[tags=extension-handler-customizer]
----

<1> Register as a global link:{jdbidocs}/core/extension/ExtensionHandlerCustomizer.html[ExtensionHandlerCustomizer^] instance to log every method invocation.

[NOTE]
This is example code. Jdbi actually offers better logging facilities with link:{jdbidocs}/core/statement/SqlLogger.html[SqlLogger^] and the
link:{jdbidocs}/core/statement/SqlStatements.html#setSqlLogger(org.jdbi.v3.core.statement.SqlLogger)[SqlStatements#setSqlLogger()^] method.

link:{jdbidocs}/core/extension/ExtensionHandlerCustomizer.html[ExtensionHandlerCustomizer^] instances usually wrap or replace an existing extension
handler. They must be stateless and can only modify or operate on the link:{jdbidocs}/core/extension/ExtensionHandler.html[ExtensionHandler^] object
that was passed into the link:{jdbidocs}/core/extension/ExtensionHandlerCustomizer.html#customize(org.jdbi.v3.core.extension.ExtensionHandler,java.lang.Class,java.lang.reflect.Method)[ExtensionHandlerCustomizer#customize()^]
method.


==== Config customizers and their factories

link:{jdbidocs}/core/extension/ConfigCustomizer.html[ConfigCustomizer^] instances modify the link:{jdbidocs}/core/config/ConfigRegistry.html[configuration
registry^] object which is used when an extension type method is invoked. This configuration object is passed to all extension handler customizers and the
extension handler itself.

Config customizer instances are created by link:{jdbidocs}/core/extension/ConfigCustomizerFactory.html[ConfigCustomizerFactory^] instances which decide whether
to provide a config customizer for every method on an extension type by implementing the
link:{jdbidocs}/core/extension/ConfigCustomizerFactory.html#forExtensionType(java.lang.Class)[ConfigCustomizerFactory#forExtensionType()^] method, or it can
implement
link:{jdbidocs}/core/extension/ConfigCustomizerFactory.html#forExtensionMethod(java.lang.Class,java.lang.reflect.Method)[ConfigCustomizerFactory#forExtensionMethod()^]
for per-method selection.


This is an example for a global configuration customizer that registers a specific <<RowMappers registry, row mapper>> for all methods on every extension type.

[source,java,indent=0]
----
include::{exampledir}/ExtensionConfigCustomizerTest.java[tags=register-global]

include::{exampledir}/ExtensionConfigCustomizerTest.java[tags=config-customizer]
----

<1> Register a global config customizer. It will be applied to all extension types.

<2> Register the `SomethingMapper` to the every extension handler for every extension type.

[#extension-framework-annotations]
=== Annotations

A Jdbi extension like the <<sql-objects, SQL Object extension>> uses annotations on the extension types. It is possible to implement a large part of the
functionality directly as annotation related objects without having to provide extension objects through an extension factory.

The extension framework offers _meta-annotations_ to configure link:{jdbidocs}/core/extension/ExtensionHandler.html[ExtensionHandler^] and
link:{jdbidocs}/core/extension/ExtensionHandlerCustomizer.html[ExtensionHandlerCustomizer^] instances directly and another _meta-annotation_ to define
link:{jdbidocs}/core/extension/ExtensionConfigurer.html[ExtensionConfigurer^] instances which allows configuration modification similar to
link:{jdbidocs}/core/extension/ConfigCustomizer.html[ConfigCustomizer^]).

Meta-annotations are used to annotate other annotation classes for processing by the extension framework.


==== Extension handler annotation

The link:{jdbidocs}/core/extension/annotation/UseExtensionHandler.html[@UseExtensionHandler^] meta-annotation marks any other annotation as defining an
extension handler.

These annotations must be placed on a method in an extension type, therefore annotations that are marked with the meta-annotation should use the
link:{jdkdocs}/java.base/java/lang/annotation/Target.html[@Target({ElementType.METHOD})^] annotation to limit their scope.

The extension framework processes all annotations that use this meta-annotation. It will instantiate the extension handler by locating

- a constructor that takes both the extension type and a method object
- a constructor that takes only the extension type
- a no-argument constructor

If none of those can be found, an exception will be thrown.

When using this meta-annotation, the link:{jdbidocs}/core/extension/annotation/UseExtensionHandler.html#id()[UseExtensionHandler#id()^] method must return an id
value that is specific for the extension factory that should process the annotation. This allows multiple extensions that use annotations to co-exist.

This is an example of an annotation that provides the handler for the `getSomething` method on an extension type:

[source,java,indent=0]
----
include::{exampledir}/ExtensionHandlerAnnotationTest.java[tags=register-factory]

include::{exampledir}/ExtensionHandlerAnnotationTest.java[tags=annotation-code]
----

<1> An extension factory that implements only the link:{jdbidocs}/core/extension/ExtensionFactory.html#accepts(java.lang.Class)[ExtensionFactory#accepts()^] method can be written as a lambda.

<2> The factory accepts this extension type if it has at least one method that is annotated with the
link:{jdbidocs}/core/extension/annotation/UseExtensionHandler.html[@UseExtensionHandler^] meta-annotation.

<3> Ensure that the annotation uses the `test` id value.

<4> The `@SomethingAnnotation` provides the extension handler. Any method with this annotation will use the same extension handler.

<5> The custom annotation targets only methods.

<6> The `test` id value ensures that the registered factory will accept the extension type. Any extension type must be accepted by a factory, otherwise the
extension framework will reject the extension type.

<7> The annotation provides the extension handler class. An instance of this class is created by the extension framework directly without an extension handler
factory.

[IMPORTANT]
Even though multiple extensions can can be used at the same time, they can not share an extension type.  Every extension type will only get extension handlers
associated with a single factory. It is not possible to have an extension type where methods are processed by extension handlers that are annotated with
annotations that use different id values. Any extension handler must be provided either by annotations that match the id value of the
link:{jdbidocs}/core/extension/ExtensionFactory.html[ExtensionFactory^] or an extension handler factory.

All SQL method annotations in the <<sql-objects,Jdbi SQL Object>> extension (link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^],
link:{jdbidocs}/sqlobject/statement/SqlCall.html[@SqlCall^], link:{jdbidocs}/sqlobject/statement/SqlQuery.html[@SqlQuery^],
link:{jdbidocs}/sqlobject/statement/SqlScript.html[@SqlScript^] and link:{jdbidocs}/sqlobject/statement/SqlUpdate.html[@SqlUpdate^]) are marked with this
meta-annotation.


==== Extension handler customizer annotation

The link:{jdbidocs}/core/extension/annotation/UseExtensionHandlerCustomizer.html[@UseExtensionHandlerCustomizer^] meta-annotation marks any other annotation
as defining an extension handler customizer.

An example in the <<sql-objects,SQL object extension>> is the link:{jdbidocs}/sqlobject/transaction/Transaction.html[@Transaction^] annotation which allows
wrapping multiple SQL operations into a database transaction.

Extension handler customizers either apply to all methods in an extension type by adding an annotation to the extension type, or to specific methods by adding
the annotation to a method:

[source,java,indent=0]
----
include::{exampledir}/ExtensionHandlerCustomizerAnnotationTest.java[tags=annotation]

include::{exampledir}/ExtensionHandlerCustomizerAnnotationTest.java[tags=extension-types]
----

<1> An annotation that uses the link:{jdbidocs}/core/extension/annotation/UseExtensionHandlerCustomizer.html[@UseExtensionHandlerCustomizer^] annotation can
be placed on a method or the extension type itself.

<2> The extension handler customizer is only applied to an annotated method.

<3> The extension handler customizer is applied to all methods on the extension type.

The extension framework processes all annotations that use this meta-annotation. It will instantiate the extension handler customizer by locating

- a constructor that takes both the extension type and a method object
- a constructor that takes only the extension type
- a no-argument constructor

If none of those can be found, an exception will be thrown.

This is an example for an annotation that provides a handler customizer which logs method entry and exit for any extension handler:

[source,java,indent=0]
----
include::{exampledir}/ExtensionHandlerCustomizerAnnotationTest.java[tags=extension-handler-customizer]
----

Extension handler customizer objects are not tied to a specific extension factory. This is an example where <<sql-objects,SQL Object>> method annotations are
used with the custom logging annotation:

[source,java,indent=0]
----
include::{exampledir}/ExtensionHandlerCustomizerAnnotationTest.java[tags=mixed-annotation]
----


===== Specifying extension handler customization order

When multiple extension customizers are used on the same extension type method, the order in which they are applied is undefined. If a specific order is
required (e.g. because one customization depends on another), the
link:{jdbidocs}/core/extension/annotation/ExtensionHandlerCustomizationOrder.html[@ExtensionHandlerCustomizationOrder^] annotation may be used to enforce a
specific order.

Listing the annotation classes orders the extension customizers from outermost to innermost (outermost is called first). Any unlisted annotation will still be
applied but its position is undefined. It is recommended to list all applicable annotation classes when specifying the order.

[source,java,indent=0]
----
interface OrderedCustomizers {
    @Bar
    @Foo
    @ExtensionHandlerCustomizationOrder({Foo.class, Bar.class}) // <1>
    void execute();
}
----

<1> The annotation ensures that the `Foo` extension customizer is called first, then the `Bar` extension customizer. Otherwise, the order is undefined.


==== Extension handler configurer annotation

The link:{jdbidocs}/core/extension/annotation/UseExtensionConfigurer.html[@UseExtensionConfigurer^] meta-annotation marks any other annotation as defining an
extension configurer.

Similar to extension handler customizers, configurers either apply to all methods in an extension type by adding an annotation to the extension type, or to
specific methods by adding the annotation to a method.

The meta-annotation provides an implementation of the link:{jdbidocs}/core/extension/ExtensionConfigurer.html[ExtensionConfigurer^].

- the
  link:{jdbidocs}/core/extension/ExtensionConfigurer.html#configureForType(org.jdbi.v3.core.config.ConfigRegistry,java.lang.annotation.Annotation,java.lang.Class)[ExtensionConfigurer#configureForType()^]
  is called if the anntation is placed on the extension type
- method provides and
link:{jdbidocs}/core/extension/ExtensionConfigurer.html#configureForMethod(org.jdbi.v3.core.config.ConfigRegistry,java.lang.annotation.Annotation,java.lang.Class,java.lang.reflect.Method)[ExtensionConfigurer#configureForMethod()^]
is called when the annotation is placed on an extension type method

These methods are the equivalent of
link:{jdbidocs}/core/extension/ConfigCustomizerFactory.html#forExtensionType(java.lang.Class)[ConfigCustomizerFactory#forExtensionType()^] and
link:{jdbidocs}/core/extension/ConfigCustomizerFactory.html#forExtensionMethod(java.lang.Class,java.lang.reflect.Method)[ConfigCustomizerFactory#forExtensionMethod()^].

The extension framework processes all annotations that use this meta-annotation.

It will instantiate the extension configurer by locating

- a constructor that takes the annotation, the extension type, and a method object
- a constructor that takes the annotation and the extension type
- a constructor that takes the annotation only
- a no-argument constructor

If none can be found, an exception will be thrown.

This is an example of an extension configurer annotation that adds a specific <<Row Mappers, row mapper>>:

[source,java,indent=0]
----
include::{exampledir}/ExtensionConfigurerAnnotationTest.java[tags=annotation]

include::{exampledir}/ExtensionConfigurerAnnotationTest.java[tags=dao]

include::{exampledir}/ExtensionConfigurerAnnotationTest.java[tags=extension-configurer]
----

<1> define the extension configurer class in the annotation

<2> add the custom annotation to a method in a SQL Object extension type

<3> The implementation extends link:{jdbidocs}/core/extension/SimpleExtensionConfigurer.html[SimpleExtensionConfigurer^] as it should behave the same when used
on an extension type or an extension type method.

Similar to extension handler customizer objects, extension configurers are also not tied to a specific extension factory.  In the example above, a custom
extension configurer is used in combination with the <<sql-objects,SQL Object extension>> annotations.

[TIP]
If an extension configurer should behave the same way independent of its position, the implementation should extend
link:{jdbidocs}/core/extension/SimpleExtensionConfigurer.html[SimpleExtensionConfigurer^] and implement the
link:{jdbidocs}/core/extension/SimpleExtensionConfigurer.html#configure(org.jdbi.v3.core.config.ConfigRegistry,java.lang.annotation.Annotation,java.lang.Class)[SimpleExtensionConfigurer#configure()^]
method.

The <<sql-objects,SQL Object extension>> implements all per-method and per-class registration of specific objects
(e.g. link:{jdbidocs}/sqlobject/config/RegisterColumnMapper.html[@RegisterColumnMapper^] or
link:{jdbidocs}/sqlobject/config/RegisterRowMapper.html[@RegisterRowMapper^]) through extension configurer objects which in turn create config customizer
instances.


=== Extension metadata

[NOTE]
Interacting directly with the link:{jdbidocs}/core/extension/ExtensionMetadata.html[ExtensionMetadata^] and
link:{jdbidocs}/core/extension/ExtensionMetadata.ExtensionHandlerInvoker.html[ExtensionHandlerInvoker^] is an advanced use case when writing specific extension
code. For most extensions, all metadata interactions are handled by the framework and don't require anything special.

For every extension type that is processed by the framework, an link:{jdbidocs}/core/extension/ExtensionMetadata.html[ExtensionMetadata^] object is created. It
collects all the information that is required to create the link:{jdkdocs}/java.base/java/lang/reflect/Proxy.html[java proxy^] object:

- extension handlers for each extension type method including optional extension handler customizers.
- instance config customizers which are applied to every method
- method specific config customizers

Extension metadata is created using a builder when an extension type is processed for the first time. It is possible for an
link:{jdbidocs}/core/extension/ExtensionFactory.html[ExtensionFactory^] to participate in the metadata creation. E.g. the <<sql-objects,SQL Object extension>>
uses this to add extension handlers for the link:{jdbidocs}/sqlobject/SqlObject.html[SqlObject^] interface methods.

If an extension factory wants to participate in the metadata creation, it needs to implement the
link:{jdbidocs}/core/extension/ExtensionFactory.html#buildExtensionMetaData(org.jdbi.v3.core.extension.ExtensionMetadata.Builder)[ExtensionFactory#buildExtensionMetadata()^]
method which is called with the extension metadata builder right before the actual metadata object is created. See the
link:{jdbidocs}/core/extension/ExtensionMetadata.Builder.html[ExtensionMetadata.Builder^] documentation for all available methods.

Metadata for an extension type can be retrieved from the link:{jdbidocs}/core/extension/Extensions.html[Extensions configuration object^] by calling the
link:{jdbidocs}/core/extension/Extensions.html#findMetadata(java.lang.Class,org.jdbi.v3.core.extension.ExtensionFactory)[Extensions#findMetadata()^].

A metadata object can create link:{jdbidocs}/core/extension/ExtensionMetadata.ExtensionHandlerInvoker.html[ExtensionHandlerInvoker^] instances for all methods
on the extension type that is represents. An extension handler invoker binds the actual extension handler instance to a specific configuration object (and the
config customizers applied to that configuration object).

The main use case is within an extension type implementation class as it requires a link:{jdbidocs}/core/extension/HandleSupplier.html[HandlerSupplier^]
instance, which is only available through the
link:{jdbidocs}/core/extension/ExtensionFactory.html#attach(java.lang.Class,org.jdbi.v3.core.extension.HandleSupplier)[ExtensionFactory#attach()^] method. By
creating extension handler invokers and metadata manually, an implementation can sidestep all the proxy logic and directly wire up method invocation or redirect
invocations between methods. The <<generator,jdbi SQL object generator>> uses this mechanism to create implementation classes that do not need the java proxy
logic (which is problematic with https://docs.oracle.com/en/graalvm/enterprise/21/docs/reference-manual/native-image/DynamicProxy/[GraalVM^]).

This is an example of creating and calling an extension handler invoker directly:

[source,java,indent=0]
----
include::{exampledir}/ExtensionMetadataTest.java[tags=extension]
----

<1> The `getIdOne` method takes no parameters and returns a constant `Something` object

<2> The extension factory retrieves the metadata for the `ExtensionType` class. This call is usually done by the extension framework but can be done manually
when implementing the
link:{jdbidocs}/core/extension/ExtensionFactory.html#attach(java.lang.Class,org.jdbi.v3.core.extension.HandleSupplier)[ExtensionFactory#attach()^].

<3> The extension factory returns an implementation of the extension type.

<4> The extension factory requests that the framework returns the implementation as is and not wrap it into extension handlers.

<5> The extension factory adds an extension handler factory that provides the actual implementation.

<6> The extension handler factory only accepts the `getSomething` method, it does *not* create an extension handler for `getIdOne`.

<7> The extension type uses the metadata object to create an extension handler invoker for the `getSomething` method. This is handled by the custom extension
handler factory.

<8> The `getIdOne` method now invokes the extension handler for the `getSomething` method and passes constant values to the
link:{jdbidocs}/core/extension/ExtensionMetadata.ExtensionHandlerInvoker.html#invoke(java.lang.Object%2E%2E%2E)[ExtensionHandlerInvoker#invoke()^] method.


== Advanced Topics


=== High Availability

Jdbi can be combined with connection pools and high-availability features in your database driver.
We've used https://github.com/brettwooldridge/HikariCP[HikariCP^] in combination
with the https://jdbc.postgresql.org/documentation/head/connect.html[PgJDBC connection load balancing^]
features with good success.

[source,java,indent=0]
----
PGSimpleDataSource ds = new PGSimpleDataSource();
ds.setServerName("host1,host2,host3");
ds.setLoadBalanceHosts(true);

HikariConfig hc = new HikariConfig();
hc.setDataSource(ds);
hc.setMaximumPoolSize(6);

Jdbi jdbi = Jdbi.create(new HikariDataSource(hc)).installPlugin(new PostgresPlugin());
----

Each Jdbi may be backed by a pool of any number of hosts, but the connections should all be alike.
Exactly which parameters must stay the same and which may vary depends on your database and driver.

If you want to have two separate pools, for example a read-only set that connects to read replicas
and a smaller pool of writers that go only to a single host, you currently should have separate
link:{jdbidocs}/core/Jdbi.html[Jdbi^] instances each pointed at a separate `DataSource`.


[#compiling_with_parameter_names]
=== Compiling with Parameter Names

By default, the Java compiler does not write parameter names of constructors and
methods to class files. At runtime, using reflection to find  parameter names
will return values like "arg0", "arg1", etc.

Out of the box, Jdbi uses annotations to name parameters, e.g.:

* `ConstructorMapper` uses the `@ConstructorProperties` annotation.
* SQL Object method arguments use the link:{jdbidocs}/sqlobject/customizer/Bind.html[@Bind^] annotation.

[source,java,indent=0]
----
@SqlUpdate("INSERT INTO users (id, name) VALUES (:id, :name)")
void insert(@Bind("id") long id, @Bind("name") String name);
----

If you compile your code with the `-parameters` compiler flag, then the need for
these annotations is removed -- Jdbi automatically uses the method parameter name:

[source,java,indent=0]
----
@SqlUpdate("INSERT INTO users (id, name) VALUES (:id, :name)")
void insert(long id, String name);
----


==== Maven Setup

Configure the `maven-compiler-plugin` in your POM:

[source,xml,indent=0]
----
<plugin>
  <groupId>org.apache.maven.plugins</groupId>
  <artifactId>maven-compiler-plugin</artifactId>
  <configuration>
    <compilerArgs>
      <arg>-parameters</arg>
    </compilerArgs>
  </configuration>
</plugin>
----


==== IntelliJ IDEA setup

* File -> Settings
* Build, Execution, Deployment -> Compiler -> Java Compiler
* Additional command-line parameters: `-parameters`
* Click Apply, then OK.
* Build -> Rebuild Project


==== Eclipse Setup

* Window -> Preferences
* Java -> Compiler
* Under "Classfile Generation," check the option "Store information about
  method parameters (usable via reflection)."


=== Working with Generic Types

Jdbi provides utility classes to make it easier to work with Java generic types.


==== GenericType

link:{jdbidocs}/core/generic/GenericType.html[GenericType^] represents a generic
type signature that can be passed around in a type-safe way.

Create a generic type reference by instantiating an anonymous inner class:

[source,java,indent=0]
----
new GenericType<Optional<String>>() {}
----

This type reference can be passed to any Jdbi method that accepts a
`GenericType<T>`, e.g.:

[source,java,indent=0]
----
List<Optional<String>> middleNames = handle
    .select("SELECT middle_name FROM contacts")
    .mapTo(new GenericType<Optional<String>>() {})
    .list();
----

The `GenericType.getType()` returns the raw
link:{jdkdocs}/java.base/java/lang/reflect/Type.html[java.lang.reflect.Type^] object used
to represent generics in Java.


==== The GenericTypes helper

link:{jdbidocs}/core/generic/GenericTypes.html[GenericTypes^] provides methods
for working with Java generic types signatures.

All methods in `GenericTypes` operate in terms of `java.lang.reflect.Type`.

The `getErasedType(Type)` method accepts a `Type` and returns the raw `Class`
for that type, with any generic parameters erased:

[source,java,indent=0]
----
Type listOfInteger = new GenericType<List<Integer>>() {}.getType();
GenericTypes.getErasedType(listOfInteger); // => List.class

GenericTypes.getErasedType(String.class); // => String.class
----

The `resolveType(Type, Type)` method takes a generic type, and a context type in
which to resolve it.

For example, given the type variable `T` from `Optional<T>`:

[source,java,indent=0]
----
Type t = Optional.class.getTypeParameters()[0];
----

And given the context type `Optional<String>`:

[source,java,indent=0]
----
Type optionalOfString = new GenericType<Optional<String>>() {}.getType();
----

The `resolveType()` method answers the question: "what is type T, in the context
of type Optional<String>?"

[source,java,indent=0]
----
GenericTypes.resolveType(t, optionalOfString);
// => String.class
----

This scenario of resolving the first type parameter of some generic supertype is
so common that we made a separate method for it:

[source,java,indent=0]
----
GenericTypes.findGenericParameter(optionalOfString, Optional.class);
// => Optional.of(String.class)

Type listOfInteger = new GenericType<List<Integer>>() {}.getType();
GenericTypes.findGenericParameter(listOfInteger, Collection.class);
// => Optional.of(Integer.class)
----

Note that this method will return link:{jdkdocs}/java.base/java/util/Optional.html#empty--[Optional.empty()^] if the type parameter
cannot be resolved, or the types have nothing to do with each other:

[source,java,indent=0]
----
GenericTypes.findGenericParameter(optionalOfString, List.class);
// => Optional.empty();
----


=== NamedArgumentFinder

The link:{jdbidocs}/core/argument/NamedArgumentFinder[NamedArgumentFinder^]
interface, as its name suggests, finds arguments by name from some source.
Typically, a single `NamedArgumentFinder` instance will provide arguments for
several names.

In cases where neither `bindBean()`, `bindFields()`, `bindMethods()`, nor
`bindMap()` are a good fit, you can implement your own `NamedArgumentFinder` and
bind that, instead of extracting and binding each argument individually.

[source,java,indent=0]
----
Cache cache = ... // e.g. Guava Cache
NamedArgumentFinder cacheFinder = (name, ctx) ->
    Optional.ofNullable(cache.getIfPresent(name))
            .map(value -> ctx.findArgumentFor(Object.class, value));

stmt.bindNamedArgumentFinder(cacheFinder);
----

[TIP]
Under the hood, the
link:{jdbidocs}/core/statement/SqlStatement.html#bindBean-java.lang.Object-[SqlStatement.bindBean()^],
link:{jdbidocs}/core/statement/SqlStatement.html#bindMethods-java.lang.Object-[SqlStatement.bindMethods()^],
link:{jdbidocs}/core/statement/SqlStatement.html#bindFields-java.lang.Object-[SqlStatement.bindFields()^],
and
link:{jdbidocs}/core/statement/SqlStatement.html#bindMap-java.util.Map-[SqlStatement.bindMap()^]
methods are just creating and binding custom implementations of
`NamedArgumentFinder` for beans, methods, fields, and maps, respectively.


=== JdbiConfig

Configuration is managed by the
link:{jdbidocs}/core/config/ConfigRegistry.html[ConfigRegistry^] class.
Each Jdbi object that represents a distinct database context (for
example, link:{jdbidocs}/core/Jdbi.html[Jdbi^] itself, a
link:{jdbidocs}/core/Handle.html[Handle^] instance, or an attached
link:{jdbidocs}/sqlobject/SqlObject.html[SqlObject^] class) has a
separate config registry instance.

A context implements the
link:{jdbidocs}/core/config/Configurable.html[Configurable^] interface
which allows modification of its configuration as well as retrieving
the current context's configuration for use by Jdbi core or
extensions.

When a new context is created, it inherits a copy of its parent
configuration at the time of creation - further modifications to the
original will not affect already created configuration contexts.
Configuration context copies happen when creating a
link:{jdbidocs}/core/Handle.html[Handle^] from
link:{jdbidocs}/core/Jdbi.html[Jdbi^], when opening a
link:{jdbidocs}/core/statement/SqlStatement.html[SqlStatement^] from
the Handle, and when attaching or creating an on-demand extension such
as link:{jdbidocs}/sqlobject/SqlObject.html[SqlObject^].

The configuration itself is stored in implementations of the
link:{jdbidocs}/core/config/JdbiConfig.html[JdbiConfig^] interface.
Each implementation must adhere to the contract of the interface; in
particular it must have a public no-argument constructor that provides
useful defaults and an implementation of the
link:{jdbidocs}/core/config/JdbiConfig.html#createCopy()[JdbiConfig#createCopy^]
method that is invoked when a configuration registry is cloned.

Configuration should be set on a context before that context is used,
and not changed later. Some configuration classes may be thread-safe but most are
not. Configuration objects should be implemented so that they are cheap to copy,
for example the base ones use copy-on-write collections.

Many of Jdbi's core features, for example argument or mapper
registries, are simply implementations of
link:{jdbidocs}/core/config/JdbiConfig.html[JdbiConfig^] that store the
registered mappings for later use during query execution.

[source,java,indent=0]
----
include::{exampledir}/ExampleConfig.java[tags=exampleConfig]
----


==== Creating a custom JdbiConfig type

* Create a public class that implements JdbiConfig.
* Add a public, no-argument constructor
* Add a private, copy constructor.
* Implement `createCopy()` to call the copy constructor.
* Add config properties, and provide sane defaults for each property.
* Ensure that all config properties get copied to the new instance in the copy
  constructor.
* Override `setConfig(ConfigRegistry)` if your config class wants to be able to
  use other config classes in the registry. E.g. RowMappers registry delegates
  to ColumnMappers registry, if it does not have a mapper registered for a given
  type.
* Use that configuration object from other classes that are interested in it.
** e.g. BeanMapper, FieldMapper, and ConstructorMapper all use the
   ReflectionMappers config class to keep common configuration.


=== JdbiPlugin

JdbiPlugin can be used to bundle bulk configuration.
Plugins may be installed explicitly via `Jdbi.installPlugin(JdbiPlugin)`, or
may be installed automagically from the classpath using the ServiceLoader mechanism
via `installPlugins()`.

Jars may provide a file in `META-INF/services/org.jdbi.v3.core.spi.JdbiPlugin`
containing the fully qualified class name of your plugin.

In general, Jdbi's separate artifacts each provide a single relevant plugin (e.g. `jdbi3-sqlite`),
and such modules will be auto-loadable. Modules that provide no (e.g. `jdbi3-commons-text`)
or multiple (e.g. `jdbi3-core`) plugins typically will not be.

[TIP]
The developers encourage you to install plugins explicitly.  Code with declared dependencies
on the module it uses is more robust to refactoring and provides useful data
for static analysis tools about what code is or is not used.

////
=== JdbiCollectors

TODO:

* Implement and register a CollectorFactory to add support for new container
  types
* JdbiCollectors registry
* Use GenericTypes utility class to help with generics.
* Last-registered factory which supporting a given container type wins.
////


=== StatementContext

The link:{jdbidocs}/core/statement/StatementContext.html[StatementContext^] class holds the state for all <<Statement types, statements>>. It is a stateful object that should not be shared between threads. It may be used by different threads as long as this happens sequentially.

The statement context object is passed into most user extension points, e.g. link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^], link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper^], or link:{jdbidocs}/core/collector/CollectorFactory.html[CollectorFactory^].

The link:{jdbidocs}/core/statement/StatementContext.html[StatementContext^] is not intended to be extended and extension points should use it to get access to other parts of the system (especially the config registry). They rarely need to make changes to it.

////
=== SQL interpolation

Jdbi configuration supports the concept of defined attributes. These are
distinct from statement bound parameters, and may be used to modify the actual
SQL statements that is executed.

[CAUTION]
Be careful using this feature! This can become a vector for SQL injection
attacks if you fail to
https://xkcd.com/327/[sanitize your database inputs^].

TODO:

* Add an angle-bracked marker to your SQL statement, e.g. `<foo>`. Whatever
  value is defined for `foo` will be substituted into the SQL statement.
* SqlStatement.define / @Define
* SqlStatement.defineList / @DefineList
* SqlStatement.bindList / @BindList
* SqlStatement.bindBeanList / @BindBeanList
* usage examples:
** `INSERT INTO <table> (<columns>) VALUES (<values>)`
** `SELECT <columns> FROM <table> WHERE <conditions> ORDER BY <order>`
////


=== TemplateEngine

Jdbi uses a link:{jdbidocs}/core/statement/TemplateEngine.html[TemplateEngine^]
implementation to render templates into SQL. Template engines take a SQL
template string and the `StatementContext` as input, and produce a parseable
SQL string as output.

Out of the box, Jdbi is configured to use link:{jdbidocs}/core/statement/DefinedAttributeTemplateEngine.html[DefinedAttributeTemplateEngine^], which replaces angle-bracked tokens like `<name>` in SQL statements with
the string value of the named attribute:

[source,java,indent=0]
----
String tableName = "customers";
Class<?> entityClass = Customer.class;

handle.createQuery("SELECT <columns> FROM <table>")
      .define("table", "customers")
      .defineList("columns", "id", "name")
      .mapToMap()
      .list() // => "SELECT id, name FROM customers"
----

[NOTE]
The `defineList` method defines a list of elements as the comma-separated
splice of String values of the individual elements. In the above example,
the `columns` attribute is defined as `"id, name"`.

Jdbi supports custom template engines through the link:{jdbidocs}/core/statement/TemplateEngine.html[TemplateEngine^]
interface. By calling link:{jdbidocs}/core/config/Configurable.html#setTemplateEngine(org.jdbi.v3.core.statement.TemplateEngine)[Configurable#setTemplateEngine()^] method on the link:{jdbidocs}/core/Jdbi.html[Jdbi^], link:{jdbidocs}/core/Handle.html[Handle^], or any SQL statement like link:{jdbidocs}/core/statement/Update.html[Update^] or link:{jdbidocs}/core/statement/Query.html[Query^], the template engine used to render SQL can be changed:

[source,java,indent=0]
----
TemplateEngine templateEngine = (template, ctx) -> {
  ...
};

jdbi.setTemplateEngine(templateEngine);
----

[TIP]
Jdbi also provides link:{jdbidocs}/stringtemplate4/StringTemplateEngine.html[StringTemplateEngine^],
which renders templates using the https://www.stringtemplate.org/[StringTemplate library^]. See <<stringtemplate4,StringTemplate 4>>.

Template engines interact with the SQL template caching. A template engine may implement the link:{jdbidocs}/core/statement/TemplateEngine.html#parse(java.lang.String,org.jdbi.v3.core.config.ConfigRegistry)[TemplateEngine#parse()^] methods to create an intermediary representation of a template that can be used to render a template faster. The output of this method will be cached. Depending on the implementation, defined attributes may be resolved at parse time and not at render time.

The most commonly used template engines (link:{jdbidocs}/core/statement/DefinedAttributeTemplateEngine.html[DefinedAttributeTemplateEngine^] and link:{jdbidocs}/stringtemplate4/StringTemplateEngine.html[StringTemplateEngine^] do *not* support caching).


=== SqlParser

After the SQL template has been rendered, Jdbi uses a link:{jdbidocs}/core/statement/SqlParser.html[SqlParser^] to parse out any named parameters from the SQL statement. This Produces a link:{jdbidocs}/core/statement/ParsedSql.html[ParsedSql^] object, which
contains all the information Jdbi needs to bind parameters and execute the SQL statement.

Out of the box, Jdbi is configured to use link:{jdbidocs}/core/statement/ColonPrefixSqlParser.html[ColonPrefixSqlParser^], which
recognizes colon-prefixed named parameters, e.g. `:name`.

[source,java,indent=0]
----
handle.createUpdate("INSERT INTO characters (id, name) VALUES (:id, :name)")
      .bind("id", 1)
      .bind("name", "Dolores Abernathy")
      .execute();
----

Jdbi also provides link:{jdbidocs}/core/statement/HashPrefixSqlParser.html[HashPrefixSqlParser^], which recognizes hash-prefixed
parameters, e.g. `#hashtag`. Other custom parsers implement the link:{jdbidocs}/core/statement/SqlParser.html[SqlParser^]
interface.

By calling link:{jdbidocs}/core/config/Configurable.html#setSqlParser(org.jdbi.v3.core.statement.SqlParser)[Configurable#setSqlParser()^] method on the link:{jdbidocs}/core/Jdbi.html[Jdbi^], link:{jdbidocs}/core/Handle.html[Handle^], or any SQL statement like link:{jdbidocs}/core/statement/Update.html[Update^] or link:{jdbidocs}/core/statement/Query.html[Query^], the parser used to define named arguments can be changed:

[source,java,indent=0]
----
handle.setSqlParser(new HashPrefixSqlParser())
      .createUpdate("INSERT INTO characters (id, name) VALUES (#id, #name)")
      .bind("id", 2)
      .bind("name", "Teddy Flood")
      .execute();
----

The default parsers recognize any Java identifier character and the dot (`.`) as a valid characters in a parameter or attribute name. Even some strange cases like emoji are allowed, although the Jdbi authors encourage appropriate discretion 🧐.

[NOTE]
The default parsers try to ignore parameter-like constructions inside of string literals,
since JDBC drivers wouldn't let you bind parameters there anyway.


=== SqlLogger

The link:{jdbidocs}/core/statement/SqlLogger.html[SqlLogger^] interface
is called before and after executing each statement,
and given the current `StatementContext`, to log any relevant information desired:
mainly the query in various compilation stages,
attributes and bindings, and important timestamps.

There's a simple link:{jdbidocs}/core/statement/Slf4JSqlLogger.html[Slf4JSqlLogger^]
implementation that logs all executed statements for debugging.


=== ResultProducer

A *ResultProducer* takes a lazily supplied link:{jdkdocs}/java.sql/java/sql/PreparedStatement.html[PreparedStatement^] and
produces a result.  The most common producer path, *execute()*,
retrieves the link:{jdkdocs}/java.sql/java/sql/ResultSet.html[ResultSet^] over the query results and then uses a
*ResultSetScanner* or higher level mapper to produce results.

An example alternate use is to just return the number of rows modified,
as in an UPDATE or INSERT statement:

[source,java,indent=0]
----
public static ResultProducer<Integer> returningUpdateCount() {
    return (statementSupplier, ctx) -> {
        try {
            return statementSupplier.get().getUpdateCount();
        } finally {
            ctx.close();
        }
    };
}
----

If you acquire the lazy statement, you are responsible for ensuring
that the context is closed eventually to release database resources.

Most users will not need to implement the *ResultProducer* interface.


[#generator]
=== Jdbi SQL object code generator

Jdbi includes an experimental SqlObject code generator.  If you
include the `jdbi3-generator` artifact as an annotation processor and
annotate your SqlObject definitions with `@GenerateSqlObject`, the
generator will produce an implementing class and avoids using
link:{jdkdocs}/java.base/java/lang/reflect/Proxy.html[Java proxy^] instances.
This may be useful for `graal-native` compilation.


=== HandleCallbackDecorator

Jdbi allows specifying a decorator that can be applied to all callbacks passed to
link:{jdbidocs}/core/Jdbi.html#useHandle(org.jdbi.v3.core.HandleConsumer)[useHandle^],
link:{jdbidocs}/core/Jdbi.html#withHandle(org.jdbi.v3.core.HandleCallback)[withHandle^],
link:{jdbidocs}/core/Jdbi.html#useTransaction(org.jdbi.v3.core.HandleConsumer)[useTransaction^],
or link:{jdbidocs}/core/Jdbi.html#inTransaction(org.jdbi.v3.core.HandleCallback)[inTransaction^].
This is for use-cases where you need to perform an action on all callbacks used in
Jdbi. For instance, you might want to have global retries whether a transaction is used
or not. Jdbi already provides retry handlers for transactions, but you might want to retry auto-commit
(non-transaction) queries as well. E.g.

[source,java,indent=0]
----
public class ExampleJdbiPlugin
        implements JdbiPlugin, HandleCallbackDecorator
{
    @Override
    public void customizeJdbi(Jdbi jdbi)
    {
        jdbi.setHandleCallbackDecorator(this);
    }

    @Override
    public <R, X extends Exception> HandleCallback<R, X> decorate(HandleCallback<R, X> callback)
    {
        return handle -> {
            try {
                if (handle.getConnection().getAutoCommit()) {
                    // do retries for auto-commit
                    return withRetry(handle, callback);
                }
            }
            catch (SQLException e) {
                throw new ConnectionException(e);
            }

            // all others get standard behavior
            return callback.withHandle(handle);
        };
    }

    private <R, X extends Exception> R withRetry(Handle handle, HandleCallback<R, X> callback)
            throws X
    {
        while (true) {
            try {
                return callback.withHandle(handle);
            }
            catch (Exception last) {
                // custom auto-commit retry behavior goes here
            }
        }
    }
}
----


== Appendix


=== Best Practices

* Test your SQL Objects (DAOs) against real databases when possible.
  Jdbi tries to be defensive and fail eagerly when you hold it wrong.

* Use the `-parameters` compiler flag to avoid all those
  `@Bind("foo") String foo` redundant qualifiers in SQL Object method
  parameters.  See <<Compiling with Parameter Names>>.
* Use a profiler! The true root cause of performance problems can often be a
  surprise. Measure first, _then_ tune for performance. And then measure again
  to be sure it made a difference.
* Don't forget to bring a towel!


=== API Reference

* link:apidocs/index.html[Javadoc^]
* link:apidocs-kotlin/jdbi3-kotlin/index.html[jdbi3-kotlin^]
* link:apidocs-kotlin/jdbi3-kotlin-sqlobject/index.html[jdbi3-kotlin-sqlobject^]


=== Related Projects

https://github.com/opentable/otj-pg-embedded[Embedded Postgres^]
makes testing against a real database quick and easy.

https://github.com/arteam/dropwizard-jdbi3[dropwizard-jdbi3^]
provides integration with DropWizard.

https://github.com/arteam/metrics-jdbi3[metrics-jdbi3^]
instruments using DropWizard-Metrics to emit statement timing statistics.

Do you know of a project related to Jdbi? Send us an issue, and we'll add a link
here!


=== Upgrading from v2 to v3

Already using Jdbi v2?

Here's a quick summary of differences to help you upgrade:

General:

* Maven artifacts renamed and split out:
  * Old: `org.jdbi:jdbi`
  * New: `org.jdbi:jdbi3-core`, `org.jdbi:jdbi3-sqlobject`, etc.
* Root package renamed: `org.skife.jdbi.v2` -> `org.jdbi.v3`

Core API:

* `DBI`, `IDBI` -> link:{jdbidocs}/core/Jdbi.html[Jdbi^]
** Instantiate with `Jdbi.create()` factory methods instead of constructors.
* `DBIException` -> `JdbiException`
* `Handle.select(String, ...)` now returns a link:{jdbidocs}/core/statement/Query.html[Query^] for further method
  chaining, instead of a link:{jdkdocs}/java.base/java/util/List.html[List<Map<String, Object>>^]. Call
  `Handle.select(sql, ...).mapToMap().list()` for the same effect as v2.
* `Handle.insert()` and `Handle.update()` have been coalesced into
  `Handle.execute()`.
* `ArgumentFactory` is no longer generic.
* `AbstractArgumentFactory` is a generic implementation of `ArgumentFactory`
  for factories that handle a single argument type.
* Argument and mapper factories now operate in terms of
  `java.lang.reflect.Type` instead of `java.lang.Class`. This allows Jdbi to
  handle arguments and mappers for generic types.
* Argument and mapper factories now have a single `build()` method that returns
  an link:{jdkdocs}/java.base/java/util/Optional.html[Optional^], instead of separate `accepts()` and `build()` methods.
* `ResultSetMapper` -> link:{jdbidocs}/core/mapper/RowMapper.html[RowMapper^]. The row index parameter was also removed
  from `RowMapper`--the current row number can be retrieved directly from the
  `ResultSet`.
* `ResultColumnMapper` -> link:{jdbidocs}/core/mapper/ColumnMapper.html[ColumnMapper^]
* `ResultSetMapperFactory` -> link:{jdbidocs}/core/mapper/RowMapperFactory.html[RowMapperFactory^]
* `ResultColumnMapperFactory` -> link:{jdbidocs}/core/mapper/ColumnMapperFactory.html[ColumnMapperFactory^]
* link:{jdbidocs}/core/statement/Query.html[Query^] no longer maps to `Map<String, Object>` by default. Call
  `Query.mapToMap()`, `.mapToBean(type)`, `.map(mapper)` or `.mapTo(type)`.
* `ResultBearing<T>` was refactored into link:{jdbidocs}/core/result/ResultBearing.html[ResultBearing^] (no generic parameter)
  and `ResultIterable<T>`. Call `.mapTo(type)` to get a `ResultIterable<T>`.
* `TransactionConsumer` and `TransactionCallback` only take a link:{jdbidocs}/core/Handle.html[Handle^] now--the
  `TransactionStatus` argument is removed. Just rollback the handle now.
* `TransactionStatus` class removed.
* `CallbackFailedException` class removed. The functional interfaces like
  `HandleConsumer`, `HandleCallback`, `TransactionCallback`, etc. can now throw
  any exception type. Methods like `Jdbi.inTransaction` that take these
  callbacks use exception transparency to throw only the exception thrown by
  the callback. If your callback throws no checked exceptions, you don't need
  a try/catch block.
* `StatementLocator` interface removed from core. All core statements expect to
  receive the actual SQL string now. A similar concept, `SqlLocator` was added
  but is specific to SQL Object.
* `StatementRewriter` refactored into link:{jdbidocs}/core/statement/TemplateEngine.html[TemplateEngine^], and link:{jdbidocs}/core/statement/SqlParser.html[SqlParser^].
* StringTemplate no longer required to process `<name>`-style tokens in SQL.
* Custom SqlParser implementations must now provide a way to transform raw
  parameter names to names that will be properly parsed out as named params.

SQL Object API:

* SQL Object support is not installed by default. It must be added as a
  separate dependency, and the plugin installed into the link:{jdbidocs}/core/Jdbi.html[Jdbi^] object:

[source,java,indent=0]
----
Jdbi jdbi = Jdbi.create(...);
jdbi.installPlugin(new SqlObjectPlugin());
----

* SQL Object types in v3 must be public interfaces--no classes. Method return
  types must likewise be public. This is due to SQL Object implementation
  switching from CGLIB to `java.lang.reflect.Proxy`, which only supports
  interfaces.
* `GetHandle` -> `SqlObject`
* `SqlLocator` replaces `StatementLocator`, and only applies to SQL Objects.
* `@RegisterMapper` divided into link:{jdbidocs}/sqlobject/config/RegisterRowMapper.html[@RegisterRowMapper^] and
  link:{jdbidocs}/sqlobject/config/RegisterColumnMapper.html[@RegisterColumnMapper^].
* link:{jdbidocs}/sqlobject/customizer/Bind.html[@Bind^] annotations on SQL Object method parameters can be made optional,
  by compiling your code with the `-parameters` compiler flag enabled.
* `@BindIn` -> link:{jdbidocs}/sqlobject/customizer/BindList.html[@BindList^], and no longer requires StringTemplate
* On-demand SQL objects don't play well with methods that return `Iterable`
  or `FluentIterable`. On-demand objects strictly close the handle after each
  method call, and no longer "hold the door open" for you to finish consuming
  the interable as they did in v2. This forecloses a major source of connection
  leaks.
* SQL Objects are no longer closeable -- they are either on-demand, or their
  lifecycle is tied to the lifecycle of the link:{jdbidocs}/core/Handle.html[Handle^] they are attached to.
* `@BindAnnotation` meta-annotation removed. Use
  `@SqlStatementCustomizingAnnotation` instead.
 * `@SingleValueResult` -> link:{jdbidocs}/sqlobject/SingleValue.html[@SingleValue^]. The annotation may be used for method
  return types, or on link:{jdbidocs}/sqlobject/statement/SqlBatch.html[@SqlBatch^] parameters.

////

== Leftover snippets

[source,java,indent=0]
----
include::{exampledir}/SqlObjectTest.java[tags=defn]
----

Given a type *Something* that has *int id* and *String name* properties, we
define an interface, *SomethingDao*, that provides simple create and read
operations for a table.

Annotations at the class and method level control the binding of arguments and
mapping to results. For example, `@RegisterRowMapper` mirrors
`Handle.registerRowMapper`.

You produce results as single instances or container types like link:{jdkdocs}/java.base/java/util/Optional.html[Optional^] or
`List`, same as `Query.mapTo`.

[source,java,indent=0]
----
include::{exampledir}/SqlObjectTest.java[tags=find-by-id]
----

=== Row Mappers

[source,java,indent=0]
----
include::{exampledir}/FiveMinuteTourTest.java[tags=defineCustomMapper]

include::{exampledir}/FiveMinuteTourTest.java[tags=useCustomMapper]
----

Registering a `RowMapper` with the `Handle` or the `Jdbi` (before the handle is created) allows you to map to the data type without having to specify the
mapper type everywhere:

[source,java,indent=0]
----
include::{exampledir}/FiveMinuteTourTest.java[tags=registerCustomMapper]
----

////
